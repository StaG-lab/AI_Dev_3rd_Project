{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 00:16:08,634] A new study created in memory with name: no-name-66cc9591-61c2-4480-b605-23d618a36bb3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n",
      "í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: 2786\n",
      "í´ë˜ìŠ¤ ìˆ˜: 7 -> ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']\n",
      "ì‚¬ì „ í›ˆë ¨ëœ EmoNet ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ (Fine-tuning)...\n",
      "'emonet' ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„ ì™„ë£Œ!\n",
      "ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\n",
      "ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\n",
      "Epoch 1/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.3715 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.1940 Acc: 0.6875\n",
      "Train Loss: 1.3166 Acc: 0.6635\n",
      "Val Loss: 1.3299 Acc: 0.7127 Macro-F1: 0.5061\n",
      "  -> Val Loss ê°œì„ ë¨! (1.3299) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 2/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.3329 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.2094 Acc: 0.7031\n",
      "Train Loss: 1.3021 Acc: 0.6846\n",
      "Val Loss: 1.3250 Acc: 0.7164 Macro-F1: 0.5074\n",
      "  -> Val Loss ê°œì„ ë¨! (1.3250) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 3/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2890 Acc: 0.6406\n",
      "  [Batch 43/43] Train Loss: 1.2328 Acc: 0.6562\n",
      "Train Loss: 1.2909 Acc: 0.6668\n",
      "Val Loss: 1.3001 Acc: 0.7127 Macro-F1: 0.5057\n",
      "  -> Val Loss ê°œì„ ë¨! (1.3001) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 4/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2412 Acc: 0.6406\n",
      "  [Batch 43/43] Train Loss: 1.1320 Acc: 0.7656\n",
      "Train Loss: 1.2809 Acc: 0.6940\n",
      "Val Loss: 1.3286 Acc: 0.7164 Macro-F1: 0.5089\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/10\n",
      "Epoch 5/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.4144 Acc: 0.5938\n",
      "  [Batch 43/43] Train Loss: 1.1854 Acc: 0.7031\n",
      "Train Loss: 1.2970 Acc: 0.6864\n",
      "Val Loss: 1.3054 Acc: 0.7215 Macro-F1: 0.5119\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 2/10\n",
      "--------------------------------------------------\n",
      "Training complete in 2m 35s\n",
      "Saved Epoch: 3\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 1.2909\n",
      "Saved Train Acc: 0.6668\n",
      "Saved Val Loss: 1.3001\n",
      "Saved Val Acc: 0.7127\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 1.2809\n",
      "Best Train Acc: 0.6940\n",
      "Best Val Loss: 1.3001\n",
      "Best Val Acc: 0.7215\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 00:18:48 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/23 00:18:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ./infrastructure/models/weights/checkpoints/emonet_1_percent_trained_metrics.json\n",
      "ğŸƒ View run abundant-stag-438 at: http://127.0.0.1:5000/#/experiments/957529077469630842/runs/26fb18654f394386bc6053a10c3cc6b9\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/957529077469630842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 00:18:51,548] Trial 0 finished with value: 1.3001 and parameters: {'lr': 1.7344282965791717e-05, 'optimizer': 'Adam', 'scheduler': 'StepLR'}. Best is trial 0 with value: 1.3001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n",
      "í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: 2786\n",
      "í´ë˜ìŠ¤ ìˆ˜: 7 -> ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']\n",
      "ì‚¬ì „ í›ˆë ¨ëœ EmoNet ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ (Fine-tuning)...\n",
      "'emonet' ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„ ì™„ë£Œ!\n",
      "ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\n",
      "ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\n",
      "Epoch 1/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.3397 Acc: 0.7344\n",
      "  [Batch 43/43] Train Loss: 1.3417 Acc: 0.5938\n",
      "Train Loss: 1.2926 Acc: 0.6741\n",
      "Val Loss: 1.2938 Acc: 0.7127 Macro-F1: 0.5047\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2938) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 2/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.4194 Acc: 0.6406\n",
      "  [Batch 43/43] Train Loss: 1.3807 Acc: 0.6250\n",
      "Train Loss: 1.2868 Acc: 0.6770\n",
      "Val Loss: 1.3017 Acc: 0.7152 Macro-F1: 0.5071\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/10\n",
      "Epoch 3/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.3128 Acc: 0.6719\n",
      "  [Batch 43/43] Train Loss: 1.3723 Acc: 0.6094\n",
      "Train Loss: 1.2601 Acc: 0.6868\n",
      "Val Loss: 1.2857 Acc: 0.7164 Macro-F1: 0.5091\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2857) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 4/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.3879 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.1386 Acc: 0.7500\n",
      "Train Loss: 1.2718 Acc: 0.6900\n",
      "Val Loss: 1.2870 Acc: 0.7177 Macro-F1: 0.5059\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/10\n",
      "Epoch 5/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2386 Acc: 0.7344\n",
      "  [Batch 43/43] Train Loss: 1.4042 Acc: 0.6719\n",
      "Train Loss: 1.2647 Acc: 0.6951\n",
      "Val Loss: 1.2863 Acc: 0.7202 Macro-F1: 0.5105\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 2/10\n",
      "--------------------------------------------------\n",
      "Training complete in 2m 34s\n",
      "Saved Epoch: 3\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 1.2601\n",
      "Saved Train Acc: 0.6868\n",
      "Saved Val Loss: 1.2857\n",
      "Saved Val Acc: 0.7164\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 1.2601\n",
      "Best Train Acc: 0.6951\n",
      "Best Val Loss: 1.2857\n",
      "Best Val Acc: 0.7202\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 00:21:26 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/23 00:21:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ./infrastructure/models/weights/checkpoints/emonet_1_percent_trained_metrics.json\n",
      "ğŸƒ View run amazing-crane-94 at: http://127.0.0.1:5000/#/experiments/957529077469630842/runs/d0aa2336111d4e638107b05333ba576d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/957529077469630842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 00:21:29,311] Trial 1 finished with value: 1.2857 and parameters: {'lr': 9.581959774694653e-05, 'optimizer': 'AdamW', 'scheduler': 'CosineAnnealingLR'}. Best is trial 1 with value: 1.2857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n",
      "í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: 2786\n",
      "í´ë˜ìŠ¤ ìˆ˜: 7 -> ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']\n",
      "ì‚¬ì „ í›ˆë ¨ëœ EmoNet ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ (Fine-tuning)...\n",
      "'emonet' ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„ ì™„ë£Œ!\n",
      "ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\n",
      "ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\n",
      "Epoch 1/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.4777 Acc: 0.6250\n",
      "  [Batch 43/43] Train Loss: 1.2752 Acc: 0.6719\n",
      "Train Loss: 1.2868 Acc: 0.6824\n",
      "Val Loss: 1.2812 Acc: 0.7177 Macro-F1: 0.5077\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2812) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 2/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2048 Acc: 0.6719\n",
      "  [Batch 43/43] Train Loss: 1.1294 Acc: 0.7812\n",
      "Train Loss: 1.2663 Acc: 0.6850\n",
      "Val Loss: 1.2722 Acc: 0.7240 Macro-F1: 0.5122\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2722) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 3/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2084 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.1707 Acc: 0.7344\n",
      "Train Loss: 1.2628 Acc: 0.6871\n",
      "Val Loss: 1.2670 Acc: 0.7189 Macro-F1: 0.5099\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2670) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 4/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.3351 Acc: 0.6250\n",
      "  [Batch 43/43] Train Loss: 1.3903 Acc: 0.5938\n",
      "Train Loss: 1.2831 Acc: 0.6624\n",
      "Val Loss: 1.2740 Acc: 0.7227 Macro-F1: 0.5125\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/10\n",
      "Epoch 5/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2485 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.3736 Acc: 0.5938\n",
      "Train Loss: 1.2757 Acc: 0.6802\n",
      "Val Loss: 1.2894 Acc: 0.7265 Macro-F1: 0.5151\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 2/10\n",
      "--------------------------------------------------\n",
      "Training complete in 2m 36s\n",
      "Saved Epoch: 3\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 1.2628\n",
      "Saved Train Acc: 0.6871\n",
      "Saved Val Loss: 1.2670\n",
      "Saved Val Acc: 0.7189\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 1.2628\n",
      "Best Train Acc: 0.6871\n",
      "Best Val Loss: 1.2670\n",
      "Best Val Acc: 0.7265\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 00:24:06 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/23 00:24:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ./infrastructure/models/weights/checkpoints/emonet_1_percent_trained_metrics.json\n",
      "ğŸƒ View run gaudy-gnu-654 at: http://127.0.0.1:5000/#/experiments/957529077469630842/runs/e533e55266e040bf99274fedbe11356c\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/957529077469630842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 00:24:09,022] Trial 2 finished with value: 1.267 and parameters: {'lr': 2.718633567097351e-05, 'optimizer': 'AdamW', 'scheduler': 'CosineAnnealingLR'}. Best is trial 2 with value: 1.267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n",
      "í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: 2786\n",
      "í´ë˜ìŠ¤ ìˆ˜: 7 -> ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']\n",
      "ì‚¬ì „ í›ˆë ¨ëœ EmoNet ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ (Fine-tuning)...\n",
      "'emonet' ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„ ì™„ë£Œ!\n",
      "ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\n",
      "ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\n",
      "Epoch 1/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2837 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.4080 Acc: 0.5625\n",
      "Train Loss: 1.2384 Acc: 0.6995\n",
      "Val Loss: 1.2605 Acc: 0.7177 Macro-F1: 0.5067\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2605) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 2/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2297 Acc: 0.6719\n",
      "  [Batch 43/43] Train Loss: 1.1426 Acc: 0.7344\n",
      "Train Loss: 1.2547 Acc: 0.6926\n",
      "Val Loss: 1.2664 Acc: 0.7189 Macro-F1: 0.5090\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/10\n",
      "Epoch 3/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2998 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.4944 Acc: 0.5000\n",
      "Train Loss: 1.2551 Acc: 0.6828\n",
      "Val Loss: 1.2588 Acc: 0.7265 Macro-F1: 0.5139\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2588) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 4/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2935 Acc: 0.6250\n",
      "  [Batch 43/43] Train Loss: 1.3306 Acc: 0.6406\n",
      "Train Loss: 1.2716 Acc: 0.6791\n",
      "Val Loss: 1.2638 Acc: 0.7227 Macro-F1: 0.5091\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/10\n",
      "Epoch 5/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.4094 Acc: 0.6406\n",
      "  [Batch 43/43] Train Loss: 1.2358 Acc: 0.6719\n",
      "Train Loss: 1.2678 Acc: 0.6777\n",
      "Val Loss: 1.2693 Acc: 0.7265 Macro-F1: 0.5146\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 2/10\n",
      "--------------------------------------------------\n",
      "Training complete in 2m 34s\n",
      "Saved Epoch: 3\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 1.2551\n",
      "Saved Train Acc: 0.6828\n",
      "Saved Val Loss: 1.2588\n",
      "Saved Val Acc: 0.7265\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 1.2384\n",
      "Best Train Acc: 0.6995\n",
      "Best Val Loss: 1.2588\n",
      "Best Val Acc: 0.7265\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 00:26:44 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/23 00:26:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ./infrastructure/models/weights/checkpoints/emonet_1_percent_trained_metrics.json\n",
      "ğŸƒ View run amusing-dove-411 at: http://127.0.0.1:5000/#/experiments/957529077469630842/runs/26d845df603444eeab359526589d1054\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/957529077469630842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 00:26:46,820] Trial 3 finished with value: 1.2588 and parameters: {'lr': 1.375132657581059e-05, 'optimizer': 'Adam', 'scheduler': 'ReduceLROnPlateau'}. Best is trial 3 with value: 1.2588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n",
      "í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: 2786\n",
      "í´ë˜ìŠ¤ ìˆ˜: 7 -> ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']\n",
      "ì‚¬ì „ í›ˆë ¨ëœ EmoNet ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ (Fine-tuning)...\n",
      "'emonet' ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„ ì™„ë£Œ!\n",
      "ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\n",
      "ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\n",
      "Epoch 1/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.1486 Acc: 0.7344\n",
      "  [Batch 43/43] Train Loss: 1.2705 Acc: 0.6875\n",
      "Train Loss: 1.2527 Acc: 0.6908\n",
      "Val Loss: 1.2545 Acc: 0.7265 Macro-F1: 0.5165\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2545) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 2/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2730 Acc: 0.6875\n",
      "  [Batch 43/43] Train Loss: 1.2258 Acc: 0.7031\n",
      "Train Loss: 1.2538 Acc: 0.6951\n",
      "Val Loss: 1.2469 Acc: 0.7189 Macro-F1: 0.5038\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2469) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 3/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2732 Acc: 0.6406\n",
      "  [Batch 43/43] Train Loss: 1.2728 Acc: 0.7031\n",
      "Train Loss: 1.2409 Acc: 0.7017\n",
      "Val Loss: 1.2418 Acc: 0.7302 Macro-F1: 0.5142\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2418) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 4/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.2563 Acc: 0.6562\n",
      "  [Batch 43/43] Train Loss: 1.2946 Acc: 0.6250\n",
      "Train Loss: 1.2419 Acc: 0.6846\n",
      "Val Loss: 1.2343 Acc: 0.7327 Macro-F1: 0.5177\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2343) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 5/5\n",
      "----------\n",
      "  [Batch 20/43] Train Loss: 1.1246 Acc: 0.7656\n",
      "  [Batch 43/43] Train Loss: 1.1892 Acc: 0.6562\n",
      "Train Loss: 1.2377 Acc: 0.6799\n",
      "Val Loss: 1.2301 Acc: 0.7340 Macro-F1: 0.5211\n",
      "  -> Val Loss ê°œì„ ë¨! (1.2301) ëª¨ë¸ ì €ì¥.\n",
      "--------------------------------------------------\n",
      "Training complete in 2m 31s\n",
      "Saved Epoch: 5\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 1.2377\n",
      "Saved Train Acc: 0.6799\n",
      "Saved Val Loss: 1.2301\n",
      "Saved Val Acc: 0.7340\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 1.2377\n",
      "Best Train Acc: 0.7017\n",
      "Best Val Loss: 1.2301\n",
      "Best Val Acc: 0.7340\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/23 00:29:18 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/23 00:29:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ./infrastructure/models/weights/checkpoints/emonet_1_percent_trained_metrics.json\n",
      "ğŸƒ View run welcoming-fish-385 at: http://127.0.0.1:5000/#/experiments/957529077469630842/runs/11132a1dd7a448c1910caa353951045d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/957529077469630842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 00:29:21,598] Trial 4 finished with value: 1.2301 and parameters: {'lr': 7.470764901176699e-05, 'optimizer': 'AdamW', 'scheduler': 'ReduceLROnPlateau'}. Best is trial 4 with value: 1.2301.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter optimization finished.\n",
      "Best trial:\n",
      "  Value (Best Val Loss): 1.2301\n",
      "  Params: \n",
      "    lr: 7.470764901176699e-05\n",
      "    optimizer: AdamW\n",
      "    scheduler: ReduceLROnPlateau\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "import optuna\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Optunaê°€ ìµœì í™”í•  ëª©í‘œ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # MLflow ì‹¤í—˜ ì‹œì‘\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # --- 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì•ˆ ---\n",
    "        # Optunaê°€ ì´ ë²”ìœ„ ë‚´ì—ì„œ ìµœì ì˜ ê°’ì„ ì°¾ì•„ ì œì•ˆí•©ë‹ˆë‹¤.\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\"])\n",
    "        scheduler_name = trial.suggest_categorical(\"scheduler\", [\"StepLR\", \"CosineAnnealingLR\", \"ReduceLROnPlateau\"])\n",
    "        \n",
    "        # MLflowì— ì œì•ˆëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë¡\n",
    "        mlflow.log_params(trial.params)\n",
    "        \n",
    "        # --- 2. ë°ì´í„° ë° ëª¨ë¸ ì¤€ë¹„ ---\n",
    "        \n",
    "        # CUDA ì„±ëŠ¥ í”Œë˜ê·¸ ìµœì í™”\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        # TF32 í…ì„œ ì½”ì–´ ì‚¬ìš©ì„ í—ˆìš©í•˜ì—¬ Ampere ì•„í‚¤í…ì²˜ ì´ìƒ GPUì—ì„œ ì—°ì‚° ì†ë„ í–¥ìƒ\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "        #MODEL_NAME = 'resnet18'            \n",
    "        #MODEL_NAME = 'resnet50' \n",
    "        #MODEL_NAME = 'mobilenet_v3_small'  \n",
    "        #MODEL_NAME = 'shufflenet_v2'       \n",
    "        #MODEL_NAME = 'efficientnet_v2_s'   \n",
    "        #MODEL_NAME = 'squeezenet'          \n",
    "        #MODEL_NAME = 'emotionnet'  # ê°ì • ì¸ì‹ ì „ìš© ëª¨ë¸\n",
    "        MODEL_NAME = 'emonet'       # ê²½ëŸ‰í™”ëœ ê°ì • ì¸ì‹ ëª¨ë¸\n",
    "        \n",
    "        sampling_percent = \"1\"\n",
    "\n",
    "        MISCLASSIFIED_DIR = Path(f\"./datasets/misclassified_images/{MODEL_NAME}_{sampling_percent}\") # ì˜¤ë‹µ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ ì •ì˜\n",
    "        DATA_DIR = Path(f\"./datasets/KECV_{sampling_percent}\")\n",
    "        # ëŒ€ì‰¬ë³´ë“œì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì„ í‘œì‹œ, ìƒì„¸í™”ë©´ì˜ Tagsì™€ Parametersì— ê¸°ë¡\n",
    "        mlflow.log_param(\"dataset_path\", str(DATA_DIR))\n",
    "        mlflow.set_tag(\"dataset_description\", \"í…ŒìŠ¤íŠ¸ìš© 1% ë°ì´í„°\")\n",
    "        NUM_CLASSES = 7  # ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']\n",
    "        BATCH_SIZE = 64  # ë°°ì¹˜ í¬ê¸°ë¥¼ ëŠ˜ë ¤ GPU ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”\n",
    "        LEARNING_RATE = 0.001\n",
    "        NUM_EPOCHS = 5\n",
    "        EARLY_STOPPING_PATIENCE = 10 # 10ë²ˆ ì—°ì† ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ\n",
    "        STEPS_PER_EPOCH = None # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì—í­ë‹¹ ë°°ì¹˜ ìˆ˜ë¥¼ ì œí•œí•˜ë ¤ë©´ ìˆ«ìë¡œ ë³€ê²½ (ì˜ˆ: 100)\n",
    "        train_transform = None\n",
    "        val_transform = None\n",
    "        #scheduler_name = 'CosineAnnealingLR'  # CosineAnnealingLRë¡œ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "        \n",
    "        if MODEL_NAME == 'emotionnet':\n",
    "            # 48x48 í¬ê¸°, í‘ë°±(Grayscale), ì •ê·œí™”\n",
    "            # RandomResizedCrop + TrivialAugmentWide (ê°•ë ¥í•œ ë°ì´í„° ì¦ê°• ë°©ë²•)\n",
    "            train_transform = transforms.Compose([\n",
    "                #transforms.Resize((48, 48)),\n",
    "                # ì›ë³¸ ì´ë¯¸ì§€ì˜ 80% ~ 100% ì‚¬ì´ë¥¼ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ 48x48 í¬ê¸°ë¡œ ë§Œë“¦\n",
    "                transforms.RandomResizedCrop(size=48, scale=(0.8, 1.0)),\n",
    "                # ì˜ë¼ë‚¸ ì´ë¯¸ì§€ì— ìµœì ì˜ ì¦ê°• ì •ì±…ì„ ìë™ìœ¼ë¡œ ì ìš©\n",
    "                transforms.TrivialAugmentWide(),\n",
    "                # í‘ë°±ìœ¼ë¡œ ë³€í™˜\n",
    "                transforms.Grayscale(num_output_channels=1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5]) # í‘ë°± ì´ë¯¸ì§€ ì •ê·œí™”\n",
    "            ])\n",
    "            val_transform = transforms.Compose([\n",
    "                transforms.Resize((48, 48)),\n",
    "                transforms.Grayscale(num_output_channels=1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5]) # í‘ë°± ì´ë¯¸ì§€ëŠ” ì±„ë„ì´ 1ê°œ\n",
    "            ])\n",
    "\n",
    "        elif MODEL_NAME == 'emonet':\n",
    "            # ë°ì´í„° ì¦ê°•ì„ í¬í•¨í•œ í›ˆë ¨ìš© Transform ì •ì˜\n",
    "            train_transform = transforms.Compose([\n",
    "                #transforms.Resize((256, 256)),\n",
    "                transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "                transforms.TrivialAugmentWide(), \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            # ì¦ê°•ì´ ì—†ëŠ” ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© Transform ì •ì˜\n",
    "            val_transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "        else:\n",
    "            # ë°ì´í„° ì¦ê°•ì„ í¬í•¨í•œ í›ˆë ¨ìš© Transform ì •ì˜\n",
    "            train_transform = transforms.Compose([\n",
    "                #transforms.Resize((224, 224)),\n",
    "                transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "                transforms.TrivialAugmentWide(), \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "            ])\n",
    "            # ì¦ê°•ì´ ì—†ëŠ” ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© Transform ì •ì˜\n",
    "            val_transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "            ])\n",
    "            \n",
    "        # í›ˆë ¨ìš©ê³¼ ê²€ì¦ìš© ë°ì´í„°ì…‹ì„ ê°ê° ìƒì„±.\n",
    "        train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "        val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "        # DataLoader I/O íŠœë‹\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True,\n",
    "            # CPU ì½”ì–´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ GPU ë©”ëª¨ë¦¬ë¡œ ì˜¬ë¦¬ëŠ” ì‘ì—…ì„ ë³‘ë ¬ ì²˜ë¦¬\n",
    "            num_workers=min(8, os.cpu_count()), \n",
    "            pin_memory=True, # GPUë¡œì˜ ë°ì´í„° ì „ì†¡ ì†ë„ í–¥ìƒ\n",
    "            persistent_workers=True, # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ê³„ì† ìœ ì§€í•˜ì—¬ ì˜¤ë²„í—¤ë“œ ê°ì†Œ\n",
    "            prefetch_factor=2, # ê° ì›Œì»¤ê°€ ë¯¸ë¦¬ ë¡œë“œí•  ë°°ì¹˜ ìˆ˜\n",
    "            drop_last=True # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ë°°ì¹˜ ì‚¬ì´ì¦ˆë³´ë‹¤ ì‘ì„ ê²½ìš° ë²„ë ¤ì„œ ì—°ì‚° ì¼ê´€ì„± ìœ ì§€\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=False,\n",
    "            num_workers=min(8, os.cpu_count()),\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            prefetch_factor=2\n",
    "        )\n",
    "\n",
    "        NUM_CLASSES = len(train_dataset.classes)\n",
    "        \n",
    "        print(\"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "        print(f\"í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: {len(train_dataset)}\")\n",
    "        print(f\"í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "        # ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„\n",
    "        model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "        if scheduler_name == 'StepLR':\n",
    "            scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        elif scheduler_name == 'ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "        else:\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        print(f\"'{MODEL_NAME}' ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "        \n",
    "        CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_trained.pth'\n",
    "        if os.path.exists(CHECKPOINT_PATH):\n",
    "            print(\"ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\")\n",
    "            checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(\"ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\")\n",
    "        else:\n",
    "            print(\"ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        \n",
    "    \n",
    "        # --- 3. ëª¨ë¸ í›ˆë ¨ ---\n",
    "        # trainerê°€ ì´ì œ ìµœê³  ì ìˆ˜(best_metrics)ë§Œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •í–ˆë‹¤ê³  ê°€ì •\n",
    "        #best_metrics = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, DEVICE, num_epochs=NUM_EPOCHS)\n",
    "        trained_model, saved_metrics = train_model(model, \n",
    "                                    train_loader, \n",
    "                                    val_loader, \n",
    "                                    criterion, \n",
    "                                    optimizer, \n",
    "                                    scheduler,\n",
    "                                    DEVICE, \n",
    "                                    num_epochs=NUM_EPOCHS,\n",
    "                                    patience=EARLY_STOPPING_PATIENCE,\n",
    "                                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                                    misclassified_dir=MISCLASSIFIED_DIR\n",
    "                                    )\n",
    "        \n",
    "        # --- 4. MLflowì— ê²°ê³¼ ê¸°ë¡ ---\n",
    "        # ìµœê³  ê²€ì¦ ì†ì‹¤ê³¼ ì •í™•ë„, F1 Score ë“±ì„ ê¸°ë¡\n",
    "        mlflow.log_metrics({\n",
    "            \"best_train_loss\": float(saved_metrics['train_loss']),\n",
    "            \"best_train_accuracy\": float(saved_metrics['train_accuracy']),\n",
    "            \"best_val_loss\": float(saved_metrics['val_loss']),\n",
    "            \"best_val_accuracy\": float(saved_metrics['val_accuracy']),\n",
    "            \"best_macro_f1\": float(saved_metrics['macro_f1_score']),\n",
    "        })\n",
    "        \n",
    "        # í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥ (ì˜µì…˜)\n",
    "        CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_trained.pth'\n",
    "        torch.save(trained_model.state_dict(), CHECKPOINT_PATH)\n",
    "        \n",
    "        # MLflowì— ëª¨ë¸ ì €ì¥\n",
    "        #input_example = np.random.rand(1, 3, 256, 256)\n",
    "        #mlflow.pytorch.log_model(trained_model, name=\"EMONET_1P\", input_example=input_example, pip_requirements=\"pip_requirements.txt\")\n",
    "        mlflow.pytorch.log_model(trained_model, name=\"EMONET_1P\", pip_requirements=\"pip_requirements.txt\")\n",
    "        print(\"í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        # ìµœê³  ì„±ëŠ¥ ì‹œì ì˜ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥\n",
    "        METRICS_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained_metrics.json'\n",
    "        with open(METRICS_PATH, 'a', encoding='utf-8') as f:\n",
    "            json.dump(saved_metrics, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {METRICS_PATH}\")\n",
    "                \n",
    "        # --- 5. Optunaì— ëª©í‘œê°’ ë°˜í™˜ ---\n",
    "        # ìš°ë¦¬ëŠ” ê²€ì¦ ì†ì‹¤(val_loss)ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨\n",
    "        return float(saved_metrics['val_loss'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #ì½”ë“œ ì‹¤í–‰ ì „ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰\n",
    "    # mlflow ui\n",
    "    # ìœ„ì˜ ëª…ë ¹ì–´ë§Œ ë¨¼ì €í•´ë³´ê³  ì—ëŸ¬ MlflowException: When an mlflow-artifacts URI was supplied, the tracking URI must be a valid http or https URI ê°€ ë°œìƒí•˜ë©´ ì•„ë˜ ëª…ë ¹ì–´ ì‹¤í–‰.\n",
    "    # mlflow server --host 127.0.0.1 --port 5000\n",
    "    \n",
    "    # MLflow ì¶”ì  ì„œë²„ URI ì„¤ì •\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    \n",
    "    # MLflow ì‹¤í—˜ ì´ë¦„ ì„¤ì •, ëŒ€ì‰¬ë³´ë“œì—ì„œ í›ˆë ¨ì„ êµ¬ë¶„í•˜ì—¬ ë³´ê¸°ìœ„í•´ ì‚¬ìš©.\n",
    "    mlflow.set_experiment(\"Emotion Classification Tuning\")\n",
    "\n",
    "    # Optuna Study ìƒì„±: 'minimize' ë°©í–¥ìœ¼ë¡œ objective í•¨ìˆ˜ë¥¼ ìµœì í™”\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    \n",
    "    # 100ë²ˆì˜ ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜(Trial) ì‹¤í–‰\n",
    "    study.optimize(objective, n_trials=5)\n",
    "    \n",
    "    print(\"Hyperparameter optimization finished.\")\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    \n",
    "    print(f\"  Value (Best Val Loss): {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì–‘ì„ ëŠ˜ë ¤ë„ ì„±ëŠ¥ì´ íŠ¹ì • ìˆ˜ì¤€ì—ì„œ ë‹¤ì‹œ ì •ì²´ëœë‹¤ë©´, íŒŒì¸íŠœë‹ ì„¸ë¶„í™”ë¥¼ ì ìš©í•˜ì—¬ ëª¨ë¸ì˜ í•™ìŠµ íš¨ìœ¨ì„ ê·¹ëŒ€í™”\n",
    "# ìƒˆë¡œ í•™ìŠµì‹œí‚¬ íŒŒë¼ë¯¸í„°ì™€ ë¯¸ì„¸ ì¡°ì •í•  íŒŒë¼ë¯¸í„°ë¥¼ ë¶„ë¦¬\n",
    "new_classifier_params = model.emo_fc_3.parameters()\n",
    "pretrained_params = [p for name, p in model.named_parameters() if 'emo_fc_3' not in name]\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': pretrained_params, 'lr': LEARNING_RATE * 0.1}, # ê¸°ì¡´ ë¶€ë¶„ì€ 10ë¶„ì˜ 1ë¡œ ë¯¸ì„¸ ì¡°ì •\n",
    "    {'params': new_classifier_params, 'lr': LEARNING_RATE}      # ìƒˆ ë¶€ë¶„ì€ ì›ë˜ í•™ìŠµë¥ ë¡œ í•™ìŠµ\n",
    "], weight_decay=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feellog-project (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
