{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39942da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 21:00:20,230] A new study created in memory with name: no-name-d7bb6861-3b08-4e60-80b2-6e7d51d2c13a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 2.0737 Acc: 0.0000\n",
      "  [Batch 1870/1870] Train Loss: 1.7358 Acc: 0.2857\n",
      "Train Loss: 1.6944 Acc: 0.4188\n",
      "Val Loss: 1.6668 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6668) 모델 저장.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.1591 Acc: 0.7500\n",
      "  [Batch 1870/1870] Train Loss: 1.4253 Acc: 0.5714\n",
      "Train Loss: 1.6458 Acc: 0.4324\n",
      "Val Loss: 1.6391 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6391) 모델 저장.\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7404 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 2.2370 Acc: 0.1429\n",
      "Train Loss: 1.6412 Acc: 0.4324\n",
      "Val Loss: 1.6452 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/5\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.6329 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.4260 Acc: 0.5714\n",
      "Train Loss: 1.6430 Acc: 0.4324\n",
      "Val Loss: 1.6319 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6319) 모델 저장.\n",
      "Epoch 5/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7423 Acc: 0.2500\n",
      "  [Batch 1870/1870] Train Loss: 1.7676 Acc: 0.4286\n",
      "Train Loss: 1.6410 Acc: 0.4324\n",
      "Val Loss: 1.6327 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/5\n",
      "Epoch 6/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.3448 Acc: 0.6250\n",
      "  [Batch 1870/1870] Train Loss: 1.2467 Acc: 0.7143\n",
      "Train Loss: 1.6425 Acc: 0.4317\n",
      "Val Loss: 1.6421 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/5\n",
      "Epoch 7/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7580 Acc: 0.2500\n",
      "  [Batch 1870/1870] Train Loss: 1.7785 Acc: 0.4286\n",
      "Train Loss: 1.6383 Acc: 0.4324\n",
      "Val Loss: 1.6312 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6312) 모델 저장.\n",
      "Epoch 8/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.5959 Acc: 0.5000\n",
      "  [Batch 1870/1870] Train Loss: 1.3924 Acc: 0.5714\n",
      "Train Loss: 1.6371 Acc: 0.4324\n",
      "Val Loss: 1.6357 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/5\n",
      "Epoch 9/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.9589 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.2959 Acc: 0.5714\n",
      "Train Loss: 1.6402 Acc: 0.4321\n",
      "Val Loss: 1.6364 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/5\n",
      "Epoch 10/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.4398 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 2.1870 Acc: 0.1429\n",
      "Train Loss: 1.6566 Acc: 0.4282\n",
      "Val Loss: 1.6351 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/5\n",
      "Epoch 11/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 2.2117 Acc: 0.2500\n",
      "  [Batch 1870/1870] Train Loss: 1.3607 Acc: 0.5714\n",
      "Train Loss: 1.6362 Acc: 0.4324\n",
      "Val Loss: 1.6307 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6307) 모델 저장.\n",
      "Epoch 12/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.4973 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.2522 Acc: 0.7143\n",
      "Train Loss: 1.6362 Acc: 0.4324\n",
      "Val Loss: 1.6313 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/5\n",
      "Epoch 13/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.6025 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.6634 Acc: 0.4286\n",
      "Train Loss: 1.6564 Acc: 0.4276\n",
      "Val Loss: 1.6487 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/5\n",
      "Epoch 14/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.6084 Acc: 0.5000\n",
      "  [Batch 1870/1870] Train Loss: 1.5136 Acc: 0.4286\n",
      "Train Loss: 1.6410 Acc: 0.4322\n",
      "Val Loss: 1.6488 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/5\n",
      "Epoch 15/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7850 Acc: 0.5000\n",
      "  [Batch 1870/1870] Train Loss: 1.6591 Acc: 0.4286\n",
      "Train Loss: 1.6379 Acc: 0.4322\n",
      "Val Loss: 1.6322 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/5\n",
      "Epoch 16/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.4448 Acc: 0.6250\n",
      "  [Batch 1870/1870] Train Loss: 1.6384 Acc: 0.4286\n",
      "Train Loss: 1.6337 Acc: 0.4324\n",
      "Val Loss: 1.6318 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/5\n",
      "\n",
      "Early stopping! 5 에폭 동안 성능 개선이 없었습니다.\n",
      "--------------------------------------------------\n",
      "Training complete in 191m 38s\n",
      "Saved Epoch: 11\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 1.6362\n",
      "Saved Train Acc: 0.4324\n",
      "Saved Val Loss: 1.6307\n",
      "Saved Val Acc: 0.4324\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 1.6362\n",
      "Best Train Acc: 0.4324\n",
      "Best Val Loss: 1.6307\n",
      "Best Val Acc: 0.4324\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 00:12:01,138] Trial 0 finished with value: 0.4324 and parameters: {'lr': 0.0006796187214702883, 'optimizer': 'AdamW', 'scheduler': 'CosineAnnealingLR', 'batch_size': 8, 'accumulation_steps': 3}. Best is trial 0 with value: 0.4324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련된 모델 가중치가 저장되었습니다.\n",
      "상세 분석 결과가 저장되었습니다: infrastructure/models/weights/checkpoints/hubert-base_50_percent_trained_metrics_20250824_001159.json\n",
      "🏃 View run colorful-lamb-118 at: http://127.0.0.1:5003/#/experiments/971624972587108480/runs/35fed3acc28f495f9150e077398eaf22\n",
      "🧪 View experiment at: http://127.0.0.1:5003/#/experiments/971624972587108480\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트를 불러옵니다...\n",
      "체크포인트(모델 가중치) 로드 완료!\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 2.3232 Acc: 0.0000\n",
      "  [Batch 3740/3740] Train Loss: 2.4303 Acc: 0.0000\n",
      "Train Loss: 1.6320 Acc: 0.4324\n",
      "Val Loss: 1.6309 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6309) 모델 저장.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 1.9036 Acc: 0.2500\n",
      "  [Batch 3740/3740] Train Loss: 1.5828 Acc: 0.3333\n",
      "Train Loss: 1.6311 Acc: 0.4323\n",
      "Val Loss: 1.6307 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6307) 모델 저장.\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 1.9386 Acc: 0.2500\n",
      "  [Batch 3740/3740] Train Loss: 2.0365 Acc: 0.0000\n",
      "Train Loss: 1.6315 Acc: 0.4319\n",
      "Val Loss: 1.6307 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss 개선됨! (1.6307) 모델 저장.\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 1.2489 Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-24 00:55:59,500] Trial 1 failed with parameters: {'lr': 1.3067644672977184e-05, 'optimizer': 'AdamW', 'scheduler': 'CosineAnnealingLR', 'batch_size': 4, 'accumulation_steps': 3} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_765512/2772290466.py\", line 155, in objective\n",
      "    trained_model, saved_metrics = train_model(model,\n",
      "  File \"/root/feellog_02/core/training/trainer.py\", line 102, in train_model\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/torch/_tensor.py\", line 648, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 353, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/graph.py\", line 824, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-24 00:55:59,504] Trial 1 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run awesome-wren-751 at: http://127.0.0.1:5003/#/experiments/971624972587108480/runs/ac40582e492a42f986f99ad6b3dea335\n",
      "🧪 View experiment at: http://127.0.0.1:5003/#/experiments/971624972587108480\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 210\u001b[0m\n\u001b[1;32m    207\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVoice Emotion Classification Tuning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# n번의 다른 조합으로 실험\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[2], line 155\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m trained_model, saved_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEARLY_STOPPING_PATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# MLflow에 결과 기록 ---\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# 최고 검증 손실과 정확도, F1 Score 등을 기록\u001b[39;00m\n\u001b[1;32m    168\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metrics({\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_train_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(saved_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_train_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(saved_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_macro_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(saved_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro_f1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    174\u001b[0m })\n",
      "File \u001b[0;32m~/feellog_02/core/training/trainer.py:102\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, patience, log_interval, steps_per_epoch, misclassified_dir, start_epoch, accumulation_steps)\u001b[0m\n\u001b[1;32m     99\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    100\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\n\u001b[0;32m--> 102\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Update every N steps\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)  \u001b[38;5;66;03m# Or optimizer.step() without AMP\u001b[39;00m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ./train_audio.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification, DataCollatorWithPadding\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import audiomentations as A\n",
    "\n",
    "from core.data.audio_dataset import AudioDataset\n",
    "from core.training.trainer import train_model\n",
    "from core.data.DataCollatorForAudio import DataCollatorForAudio\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 라벨에 따라 다른 증강을 적용하는 래퍼(wrapper) 클래스\n",
    "class ClassAwareAugment:\n",
    "    def __init__(self, minority_classes, strong_augment, weak_augment):\n",
    "        self.minority_classes = minority_classes\n",
    "        self.strong_augment = strong_augment\n",
    "        self.weak_augment = weak_augment\n",
    "\n",
    "    def __call__(self, samples: np.ndarray, sample_rate: int, emotion: str):\n",
    "        if emotion in self.minority_classes:\n",
    "            return self.strong_augment(samples=samples, sample_rate=sample_rate)\n",
    "        else:\n",
    "            return self.weak_augment(samples=samples, sample_rate=sample_rate)\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Optuna가 최적화할 목표 함수\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        # --- 하이퍼파라미터 및 모델 제안 ---\n",
    "        #model_id = \"team-lucid/hubert-large-korean\"\n",
    "        #model_name = \"hubert-large\"\n",
    "\n",
    "        #model_id = \"team-lucid/hubert-base-korean\"\n",
    "        #model_name = \"hubert-base\"\n",
    "        #model_name = \"wav2vec2\"\n",
    "        #model_name = trial.suggest_categorical(\"model_name\", [\"wav2vec2\", \"hubert-large\"])\n",
    "        \n",
    "        '''\n",
    "        # Optuna가 이 범위 내에서 최적의 값을 찾아 제안합니다.\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\"])\n",
    "        scheduler_name = trial.suggest_categorical(\"scheduler\", [\"StepLR\", \"CosineAnnealingLR\", \"ReduceLROnPlateau\"])\n",
    "        BATCH_SIZE = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "        accumulation_steps = trial.suggest_int(\"accumulation_steps\", 1, 4)\n",
    "        mlflow.log_params(trial.params)\n",
    "        '''\n",
    "        \n",
    "        model_name = trial.suggest_categorical(\"model_name\", [\"hubert-base\"])\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\"])\n",
    "        \n",
    "        # '머리' 부분 학습률 대비 '몸통' 부분 학습률의 비율을 Optuna가 찾도록 함\n",
    "        # 예: lr=1e-4, backbone_lr_scale=0.1 이면, 몸통의 학습률은 1e-5가 됨\n",
    "        backbone_lr_scale = trial.suggest_float(\"backbone_lr_scale\", 0.01, 0.5, log=True)\n",
    "        \n",
    "        mlflow.log_params(trial.params)\n",
    "        \n",
    "        # CUDA 성능 플래그 최적화\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        # TF32 텐서 코어 사용을 허용하여 Ampere 아키텍처 이상 GPU에서 연산 속도 향상\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        \n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "        # --- 데이터 준비 ---\n",
    "        sampling_percent = 50\n",
    "        mlflow.log_param(\"sampling_percent\", sampling_percent)\n",
    "        mlflow.set_tag(\"dataset_description\", f\"{sampling_percent} 데이터셋으로 훈련\")\n",
    "        \n",
    "        NUM_EPOCHS = 100\n",
    "        EARLY_STOPPING_PATIENCE = 5\n",
    "\n",
    "        # --- 데이터 준비 ---\n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        DATA_DIR = Path(f\"./datasets/audio_sampling_sets/dataset_{sampling_percent}_percent\")\n",
    "        \n",
    "        # 소수/다수 클래스 정의 (분석 결과 기반)\n",
    "        minority_classes = ['surprise', 'disgust', 'fear']\n",
    "        \n",
    "        # 소수 클래스에 적용할 강력한 증강 파이프라인\n",
    "        strong_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "            A.TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            A.PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        ])\n",
    "\n",
    "        # 다수 클래스에 적용할 약한 증강 파이프라인 (또는 A.Compose([])로 비워둘 수 있음)\n",
    "        weak_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.005, p=0.2),\n",
    "        ])\n",
    "\n",
    "        # 차등 증강 적용기 생성\n",
    "        train_augmenter = ClassAwareAugment(\n",
    "            minority_classes=minority_classes,\n",
    "            strong_augment=strong_augment,\n",
    "            weak_augment=weak_augment\n",
    "        )\n",
    "\n",
    "        # 훈련셋에는 차등 증강 적용, 검증셋에는 미적용\n",
    "        train_dataset = AudioDataset(metadata_path=DATA_DIR / \"train.csv\", audio_dir=DATA_DIR / \"train\", transform=train_augmenter)\n",
    "        val_dataset = AudioDataset(metadata_path=DATA_DIR / \"val.csv\", audio_dir=DATA_DIR / \"val\", transform=None)\n",
    "\n",
    "        # --- 모델 및 Feature Extractor 로드 ---\n",
    "        if model_name == \"wav2vec2\":\n",
    "            model_id = \"inseong00/wav2vec2-large-xlsr-korean-autumn\"\n",
    "        elif model_name == \"hubert-large\":\n",
    "            model_id = \"team-lucid/hubert-large-korean\"\n",
    "        elif model_name == \"hubert-base\":\n",
    "            model_id = \"team-lucid/hubert-base-korean\"\n",
    "        else:\n",
    "            raise ValueError(\"지원하지 않는 모델 이름입니다.\")\n",
    "            \n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "        \n",
    "        model = AutoModelForAudioClassification.from_pretrained(\n",
    "            model_id,\n",
    "            num_labels=len(train_dataset.classes),\n",
    "            label2id=train_dataset.class_to_idx,\n",
    "            id2label=train_dataset.idx_to_class,\n",
    "            ignore_mismatched_sizes=True # 사전 훈련된 모델의 분류층과 크기가 달라도 에러 없이 로드\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        # 파라미터 그룹 분리 ---\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith(\"hubert.\"):\n",
    "                backbone_params.append(param)\n",
    "            else:\n",
    "                classifier_params.append(param)\n",
    "        \n",
    "        # 차등 학습률을 적용하여 옵티마이저 생성 ---\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': backbone_params, 'lr': lr * backbone_lr_scale},\n",
    "            {'params': classifier_params, 'lr': lr}\n",
    "        ]\n",
    "        \n",
    "        optimizer = getattr(optim, optimizer_name)(optimizer_grouped_parameters)\n",
    "\n",
    "        # --- 클래스 가중치 계산 ---\n",
    "        # 훈련 데이터셋의 라벨 분포를 기반으로 가중치 계산\n",
    "        class_names = train_dataset.classes\n",
    "        labels = [train_dataset.class_to_idx[emotion] for emotion in train_dataset.df['emotion']]\n",
    "        \n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "        \n",
    "        print(f\"클래스 가중치 적용: { {name: f'{w:.2f}' for name, w in zip(class_names, class_weights)} }\")\n",
    "        \n",
    "        # 데이터 콜레이터 및 로더\n",
    "        # 새로 만든 DataCollator 클래스를 사용\n",
    "        data_collator = DataCollatorForAudio(feature_extractor=feature_extractor, padding=True)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator, num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # 손실 함수에 클래스 가중치 적용\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "        checkpoint_dir = Path(\"./infrastructure/models/weights/checkpoints\")\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "        CHECKPOINT_PATH = checkpoint_dir / f'{model_name}_{sampling_percent}_trained.pth'\n",
    "        if CHECKPOINT_PATH.exists():\n",
    "            print(\"체크포인트를 불러옵니다...\")\n",
    "            checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(\"체크포인트(모델 가중치) 로드 완료!\")\n",
    "        else:\n",
    "            print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "        \n",
    "        trained_model, saved_metrics = train_model(model, \n",
    "                                                   train_loader, \n",
    "                                                   val_loader, \n",
    "                                                   criterion, \n",
    "                                                   optimizer, \n",
    "                                                   scheduler, \n",
    "                                                   DEVICE, \n",
    "                                                   num_epochs=NUM_EPOCHS, \n",
    "                                                   patience=EARLY_STOPPING_PATIENCE,\n",
    "                                                   accumulation_steps=accumulation_steps)\n",
    "\n",
    "        # MLflow에 결과 기록 ---\n",
    "        # 최고 검증 손실과 정확도, F1 Score 등을 기록\n",
    "        mlflow.log_metrics({\n",
    "            \"best_train_loss\": float(saved_metrics['train_loss']),\n",
    "            \"best_train_accuracy\": float(saved_metrics['train_accuracy']),\n",
    "            \"best_val_loss\": float(saved_metrics['val_loss']),\n",
    "            \"best_val_accuracy\": float(saved_metrics['val_accuracy']),\n",
    "            \"best_macro_f1\": float(saved_metrics['macro_f1_score']),\n",
    "        })\n",
    "        \n",
    "        # 훈련된 모델 저장\n",
    "        torch.save(trained_model.state_dict(), CHECKPOINT_PATH)\n",
    "        \n",
    "        # MLflow에 모델 저장\n",
    "        now_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        trained_model_save = checkpoint_dir / f'{model_name}_{sampling_percent}_trained_{now_date}.pth'\n",
    "        torch.save(trained_model.state_dict(), trained_model_save)\n",
    "        mlflow.log_artifact(trained_model_save, artifact_path=\"model\")\n",
    "        print(\"훈련된 모델 가중치가 저장되었습니다.\")\n",
    "\n",
    "        # 최고 성능 시점의 상세 분석 결과를 JSON으로 저장\n",
    "        METRICS_PATH = checkpoint_dir / f'{model_name}_{sampling_percent}_percent_trained_metrics_{now_date}.json'\n",
    "        with open(METRICS_PATH, 'a', encoding='utf-8') as f:\n",
    "            json.dump(saved_metrics, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"상세 분석 결과가 저장되었습니다: {METRICS_PATH}\")\n",
    "        mlflow.log_artifact(METRICS_PATH, artifact_path=\"metrics\")\n",
    "                \n",
    "        # --- 5. Optuna에 목표값 반환 ---\n",
    "        # 우리는 검증 손실(val_loss)을 최소화하는 것을 목표로 함\n",
    "        return float(saved_metrics['val_accuracy']) # Optuna는 최대화를 목표로 함\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #코드 실행 전 아래 명령어를 터미널에서 실행\n",
    "    # mlflow ui\n",
    "    # 위의 명령어만 먼저해보고 에러 MlflowException: When an mlflow-artifacts URI was supplied, the tracking URI must be a valid http or https URI 가 발생하면 아래 명령어 실행.\n",
    "    # mlflow server --host 127.0.0.1 --port 5001\n",
    "    \n",
    "    # MLflow 추적 서버 URI 설정\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5003\")\n",
    "    \n",
    "    # MLflow 실험 이름 설정, 대쉬보드에서 훈련을 구분하여 보기위해 사용.\n",
    "    mlflow.set_experiment(\"Voice Emotion Classification Tuning\")\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=5) # n번의 다른 조합으로 실험\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value (Best Val Accuracy): {trial.value}\")\n",
    "    print(f\"  Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249d9a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트(모델 가중치) 로드 완료!\n",
      "odict_keys(['hubert.masked_spec_embed', 'hubert.feature_extractor.conv_layers.0.conv.weight', 'hubert.feature_extractor.conv_layers.0.layer_norm.weight', 'hubert.feature_extractor.conv_layers.0.layer_norm.bias', 'hubert.feature_extractor.conv_layers.1.conv.weight', 'hubert.feature_extractor.conv_layers.2.conv.weight', 'hubert.feature_extractor.conv_layers.3.conv.weight', 'hubert.feature_extractor.conv_layers.4.conv.weight', 'hubert.feature_extractor.conv_layers.5.conv.weight', 'hubert.feature_extractor.conv_layers.6.conv.weight', 'hubert.feature_projection.layer_norm.weight', 'hubert.feature_projection.layer_norm.bias', 'hubert.feature_projection.projection.weight', 'hubert.feature_projection.projection.bias', 'hubert.encoder.pos_conv_embed.conv.bias', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'hubert.encoder.layer_norm.weight', 'hubert.encoder.layer_norm.bias', 'hubert.encoder.layers.0.attention.k_proj.weight', 'hubert.encoder.layers.0.attention.k_proj.bias', 'hubert.encoder.layers.0.attention.v_proj.weight', 'hubert.encoder.layers.0.attention.v_proj.bias', 'hubert.encoder.layers.0.attention.q_proj.weight', 'hubert.encoder.layers.0.attention.q_proj.bias', 'hubert.encoder.layers.0.attention.out_proj.weight', 'hubert.encoder.layers.0.attention.out_proj.bias', 'hubert.encoder.layers.0.layer_norm.weight', 'hubert.encoder.layers.0.layer_norm.bias', 'hubert.encoder.layers.0.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.0.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.0.feed_forward.output_dense.weight', 'hubert.encoder.layers.0.feed_forward.output_dense.bias', 'hubert.encoder.layers.0.final_layer_norm.weight', 'hubert.encoder.layers.0.final_layer_norm.bias', 'hubert.encoder.layers.1.attention.k_proj.weight', 'hubert.encoder.layers.1.attention.k_proj.bias', 'hubert.encoder.layers.1.attention.v_proj.weight', 'hubert.encoder.layers.1.attention.v_proj.bias', 'hubert.encoder.layers.1.attention.q_proj.weight', 'hubert.encoder.layers.1.attention.q_proj.bias', 'hubert.encoder.layers.1.attention.out_proj.weight', 'hubert.encoder.layers.1.attention.out_proj.bias', 'hubert.encoder.layers.1.layer_norm.weight', 'hubert.encoder.layers.1.layer_norm.bias', 'hubert.encoder.layers.1.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.1.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.1.feed_forward.output_dense.weight', 'hubert.encoder.layers.1.feed_forward.output_dense.bias', 'hubert.encoder.layers.1.final_layer_norm.weight', 'hubert.encoder.layers.1.final_layer_norm.bias', 'hubert.encoder.layers.2.attention.k_proj.weight', 'hubert.encoder.layers.2.attention.k_proj.bias', 'hubert.encoder.layers.2.attention.v_proj.weight', 'hubert.encoder.layers.2.attention.v_proj.bias', 'hubert.encoder.layers.2.attention.q_proj.weight', 'hubert.encoder.layers.2.attention.q_proj.bias', 'hubert.encoder.layers.2.attention.out_proj.weight', 'hubert.encoder.layers.2.attention.out_proj.bias', 'hubert.encoder.layers.2.layer_norm.weight', 'hubert.encoder.layers.2.layer_norm.bias', 'hubert.encoder.layers.2.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.2.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.2.feed_forward.output_dense.weight', 'hubert.encoder.layers.2.feed_forward.output_dense.bias', 'hubert.encoder.layers.2.final_layer_norm.weight', 'hubert.encoder.layers.2.final_layer_norm.bias', 'hubert.encoder.layers.3.attention.k_proj.weight', 'hubert.encoder.layers.3.attention.k_proj.bias', 'hubert.encoder.layers.3.attention.v_proj.weight', 'hubert.encoder.layers.3.attention.v_proj.bias', 'hubert.encoder.layers.3.attention.q_proj.weight', 'hubert.encoder.layers.3.attention.q_proj.bias', 'hubert.encoder.layers.3.attention.out_proj.weight', 'hubert.encoder.layers.3.attention.out_proj.bias', 'hubert.encoder.layers.3.layer_norm.weight', 'hubert.encoder.layers.3.layer_norm.bias', 'hubert.encoder.layers.3.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.3.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.3.feed_forward.output_dense.weight', 'hubert.encoder.layers.3.feed_forward.output_dense.bias', 'hubert.encoder.layers.3.final_layer_norm.weight', 'hubert.encoder.layers.3.final_layer_norm.bias', 'hubert.encoder.layers.4.attention.k_proj.weight', 'hubert.encoder.layers.4.attention.k_proj.bias', 'hubert.encoder.layers.4.attention.v_proj.weight', 'hubert.encoder.layers.4.attention.v_proj.bias', 'hubert.encoder.layers.4.attention.q_proj.weight', 'hubert.encoder.layers.4.attention.q_proj.bias', 'hubert.encoder.layers.4.attention.out_proj.weight', 'hubert.encoder.layers.4.attention.out_proj.bias', 'hubert.encoder.layers.4.layer_norm.weight', 'hubert.encoder.layers.4.layer_norm.bias', 'hubert.encoder.layers.4.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.4.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.4.feed_forward.output_dense.weight', 'hubert.encoder.layers.4.feed_forward.output_dense.bias', 'hubert.encoder.layers.4.final_layer_norm.weight', 'hubert.encoder.layers.4.final_layer_norm.bias', 'hubert.encoder.layers.5.attention.k_proj.weight', 'hubert.encoder.layers.5.attention.k_proj.bias', 'hubert.encoder.layers.5.attention.v_proj.weight', 'hubert.encoder.layers.5.attention.v_proj.bias', 'hubert.encoder.layers.5.attention.q_proj.weight', 'hubert.encoder.layers.5.attention.q_proj.bias', 'hubert.encoder.layers.5.attention.out_proj.weight', 'hubert.encoder.layers.5.attention.out_proj.bias', 'hubert.encoder.layers.5.layer_norm.weight', 'hubert.encoder.layers.5.layer_norm.bias', 'hubert.encoder.layers.5.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.5.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.5.feed_forward.output_dense.weight', 'hubert.encoder.layers.5.feed_forward.output_dense.bias', 'hubert.encoder.layers.5.final_layer_norm.weight', 'hubert.encoder.layers.5.final_layer_norm.bias', 'hubert.encoder.layers.6.attention.k_proj.weight', 'hubert.encoder.layers.6.attention.k_proj.bias', 'hubert.encoder.layers.6.attention.v_proj.weight', 'hubert.encoder.layers.6.attention.v_proj.bias', 'hubert.encoder.layers.6.attention.q_proj.weight', 'hubert.encoder.layers.6.attention.q_proj.bias', 'hubert.encoder.layers.6.attention.out_proj.weight', 'hubert.encoder.layers.6.attention.out_proj.bias', 'hubert.encoder.layers.6.layer_norm.weight', 'hubert.encoder.layers.6.layer_norm.bias', 'hubert.encoder.layers.6.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.6.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.6.feed_forward.output_dense.weight', 'hubert.encoder.layers.6.feed_forward.output_dense.bias', 'hubert.encoder.layers.6.final_layer_norm.weight', 'hubert.encoder.layers.6.final_layer_norm.bias', 'hubert.encoder.layers.7.attention.k_proj.weight', 'hubert.encoder.layers.7.attention.k_proj.bias', 'hubert.encoder.layers.7.attention.v_proj.weight', 'hubert.encoder.layers.7.attention.v_proj.bias', 'hubert.encoder.layers.7.attention.q_proj.weight', 'hubert.encoder.layers.7.attention.q_proj.bias', 'hubert.encoder.layers.7.attention.out_proj.weight', 'hubert.encoder.layers.7.attention.out_proj.bias', 'hubert.encoder.layers.7.layer_norm.weight', 'hubert.encoder.layers.7.layer_norm.bias', 'hubert.encoder.layers.7.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.7.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.7.feed_forward.output_dense.weight', 'hubert.encoder.layers.7.feed_forward.output_dense.bias', 'hubert.encoder.layers.7.final_layer_norm.weight', 'hubert.encoder.layers.7.final_layer_norm.bias', 'hubert.encoder.layers.8.attention.k_proj.weight', 'hubert.encoder.layers.8.attention.k_proj.bias', 'hubert.encoder.layers.8.attention.v_proj.weight', 'hubert.encoder.layers.8.attention.v_proj.bias', 'hubert.encoder.layers.8.attention.q_proj.weight', 'hubert.encoder.layers.8.attention.q_proj.bias', 'hubert.encoder.layers.8.attention.out_proj.weight', 'hubert.encoder.layers.8.attention.out_proj.bias', 'hubert.encoder.layers.8.layer_norm.weight', 'hubert.encoder.layers.8.layer_norm.bias', 'hubert.encoder.layers.8.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.8.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.8.feed_forward.output_dense.weight', 'hubert.encoder.layers.8.feed_forward.output_dense.bias', 'hubert.encoder.layers.8.final_layer_norm.weight', 'hubert.encoder.layers.8.final_layer_norm.bias', 'hubert.encoder.layers.9.attention.k_proj.weight', 'hubert.encoder.layers.9.attention.k_proj.bias', 'hubert.encoder.layers.9.attention.v_proj.weight', 'hubert.encoder.layers.9.attention.v_proj.bias', 'hubert.encoder.layers.9.attention.q_proj.weight', 'hubert.encoder.layers.9.attention.q_proj.bias', 'hubert.encoder.layers.9.attention.out_proj.weight', 'hubert.encoder.layers.9.attention.out_proj.bias', 'hubert.encoder.layers.9.layer_norm.weight', 'hubert.encoder.layers.9.layer_norm.bias', 'hubert.encoder.layers.9.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.9.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.9.feed_forward.output_dense.weight', 'hubert.encoder.layers.9.feed_forward.output_dense.bias', 'hubert.encoder.layers.9.final_layer_norm.weight', 'hubert.encoder.layers.9.final_layer_norm.bias', 'hubert.encoder.layers.10.attention.k_proj.weight', 'hubert.encoder.layers.10.attention.k_proj.bias', 'hubert.encoder.layers.10.attention.v_proj.weight', 'hubert.encoder.layers.10.attention.v_proj.bias', 'hubert.encoder.layers.10.attention.q_proj.weight', 'hubert.encoder.layers.10.attention.q_proj.bias', 'hubert.encoder.layers.10.attention.out_proj.weight', 'hubert.encoder.layers.10.attention.out_proj.bias', 'hubert.encoder.layers.10.layer_norm.weight', 'hubert.encoder.layers.10.layer_norm.bias', 'hubert.encoder.layers.10.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.10.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.10.feed_forward.output_dense.weight', 'hubert.encoder.layers.10.feed_forward.output_dense.bias', 'hubert.encoder.layers.10.final_layer_norm.weight', 'hubert.encoder.layers.10.final_layer_norm.bias', 'hubert.encoder.layers.11.attention.k_proj.weight', 'hubert.encoder.layers.11.attention.k_proj.bias', 'hubert.encoder.layers.11.attention.v_proj.weight', 'hubert.encoder.layers.11.attention.v_proj.bias', 'hubert.encoder.layers.11.attention.q_proj.weight', 'hubert.encoder.layers.11.attention.q_proj.bias', 'hubert.encoder.layers.11.attention.out_proj.weight', 'hubert.encoder.layers.11.attention.out_proj.bias', 'hubert.encoder.layers.11.layer_norm.weight', 'hubert.encoder.layers.11.layer_norm.bias', 'hubert.encoder.layers.11.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.11.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.11.feed_forward.output_dense.weight', 'hubert.encoder.layers.11.feed_forward.output_dense.bias', 'hubert.encoder.layers.11.final_layer_norm.weight', 'hubert.encoder.layers.11.final_layer_norm.bias', 'projector.weight', 'projector.bias', 'classifier.weight', 'classifier.bias'])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "<generator object Module.parameters at 0x76a8a781ff90>\n"
     ]
    }
   ],
   "source": [
    "model_id = \"team-lucid/hubert-base-korean\"\n",
    "model_name = \"hubert-base\"\n",
    "sampling_percent = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = Path(f\"./datasets/audio_sampling_sets/dataset_{sampling_percent}_percent\")\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "train_dataset = AudioDataset(metadata_path=DATA_DIR / \"train.csv\", audio_dir=DATA_DIR / \"train\")        \n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(train_dataset.classes),\n",
    "    label2id=train_dataset.class_to_idx,\n",
    "    id2label=train_dataset.idx_to_class,\n",
    "    ignore_mismatched_sizes=True # 사전 훈련된 모델의 분류층과 크기가 달라도 에러 없이 로드\n",
    ").to(DEVICE)      \n",
    "  \n",
    "checkpoint = torch.load(Path('./infrastructure/models/weights/checkpoints/hubert-base_50_trained.pth'))\n",
    "model.load_state_dict(checkpoint)\n",
    "print(\"체크포인트(모델 가중치) 로드 완료!\")\n",
    "print(model.state_dict().keys())\n",
    "print(\"-\"*50)\n",
    "print(\"-\"*50)\n",
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62ab0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   1756 MiB |   1756 MiB |   1756 MiB | 496128 B   |\n",
      "|       from large pool |   1753 MiB |   1753 MiB |   1753 MiB |      0 B   |\n",
      "|       from small pool |      2 MiB |      2 MiB |      2 MiB | 496128 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   1756 MiB |   1756 MiB |   1756 MiB | 496128 B   |\n",
      "|       from large pool |   1753 MiB |   1753 MiB |   1753 MiB |      0 B   |\n",
      "|       from small pool |      2 MiB |      2 MiB |      2 MiB | 496128 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   1754 MiB |   1754 MiB |   1754 MiB | 386140 B   |\n",
      "|       from large pool |   1751 MiB |   1751 MiB |   1751 MiB |      0 B   |\n",
      "|       from small pool |      2 MiB |      2 MiB |      2 MiB | 386140 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   1824 MiB |   1824 MiB |   1824 MiB |      0 B   |\n",
      "|       from large pool |   1820 MiB |   1820 MiB |   1820 MiB |      0 B   |\n",
      "|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  69557 KiB |  83231 KiB | 527056 KiB | 457499 KiB |\n",
      "|       from large pool |  68048 KiB |  82944 KiB | 523264 KiB | 455216 KiB |\n",
      "|       from small pool |   1509 KiB |   2028 KiB |   3792 KiB |   2283 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     435    |     436    |     652    |     217    |\n",
      "|       from large pool |     163    |     163    |     163    |       0    |\n",
      "|       from small pool |     272    |     273    |     489    |     217    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     435    |     436    |     652    |     217    |\n",
      "|       from large pool |     163    |     163    |     163    |       0    |\n",
      "|       from small pool |     272    |     273    |     489    |     217    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      44    |      44    |      44    |       0    |\n",
      "|       from large pool |      42    |      42    |      42    |       0    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      36    |      36    |      40    |       4    |\n",
      "|       from large pool |      34    |      34    |      38    |       4    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e965a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 23:55:24,266] Using an existing study with name 'audio-finetune-study-v1' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 가중치 적용: {'angry': '0.75', 'disgust': '2.09', 'fear': '2.00', 'happiness': '1.35', 'neutral': '1.47', 'sadness': '0.33', 'surprise': '4.11'}\n",
      "\n",
      "--- Trial 24, 파인튜닝 1단계 시작: 커스텀 헤드 훈련 ---\n",
      "Epoch 1/15\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-24 23:55:26,647] Trial 24 failed with parameters: {'model_name': 'hubert-base', 'lr': 1.5676995571651015e-05, 'backbone_lr_scale': 0.06049605839374828, 'batch_size': 8, 'accumulation_steps': 4} because of the following error: TypeError(\"unsupported operand type(s) for /: 'NoneType' and 'int'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_960283/1930072545.py\", line 237, in objective\n",
      "    train_model(\n",
      "  File \"/root/feellog_02/core/training/trainer.py\", line 104, in train_model\n",
      "    loss = loss / accumulation_steps\n",
      "TypeError: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "[W 2025-08-24 23:55:26,649] Trial 24 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run trial_24_20250824_235524 at: http://127.0.0.1:5003/#/experiments/200841879867459833/runs/6f2a922b4770404882f7c60c97f35897\n",
      "🧪 View experiment at: http://127.0.0.1:5003/#/experiments/200841879867459833\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 332\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# storage와 study_name을 지정하고, load_if_exists=True로 설정\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# 기존 연구가 있으면 불러오고, 없으면 새로 생성\u001b[39;00m\n\u001b[1;32m    325\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    326\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mSTUDY_NAME,\n\u001b[1;32m    327\u001b[0m     storage\u001b[38;5;241m=\u001b[39mSTORAGE_NAME,\n\u001b[1;32m    328\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    329\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    330\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# n번의 다른 조합으로 실험\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Hyperparameter Optimization Finished ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal trials in this study: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[2], line 237\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# 1단계는 간단한 스케줄러 사용\u001b[39;00m\n\u001b[1;32m    236\u001b[0m scheduler_head \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mLinearLR(optimizer_head, start_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, end_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, total_iters\u001b[38;5;241m=\u001b[39mHEAD_TUNE_EPOCHS)\n\u001b[0;32m--> 237\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEAD_TUNE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACCUMULATION_STEPS\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# =================================================================\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# === 2단계: 전체 모델 미세 조정 ===\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# =================================================================\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 파인튜닝 2단계 시작: 전체 모델 미세 조정 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/feellog_02/core/training/trainer.py:104\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, patience, log_interval, steps_per_epoch, misclassified_dir, start_epoch, accumulation_steps)\u001b[0m\n\u001b[1;32m    101\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    102\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\n\u001b[0;32m--> 104\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\n\u001b[1;32m    106\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# accumulation_steps 마다 모델 업데이트\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoFeatureExtractor, AutoModel \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import audiomentations as A\n",
    "\n",
    "from core.data.audio_dataset import AudioDataset\n",
    "from core.training.trainer import train_model\n",
    "from core.data.DataCollatorForAudio import DataCollatorForAudio\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 라벨에 따라 다른 증강을 적용하는 래퍼(wrapper) 클래스\n",
    "class ClassAwareAugment:\n",
    "    def __init__(self, minority_classes, strong_augment, weak_augment):\n",
    "        self.minority_classes = minority_classes\n",
    "        self.strong_augment = strong_augment\n",
    "        self.weak_augment = weak_augment\n",
    "\n",
    "    def __call__(self, samples: np.ndarray, sample_rate: int, emotion: str):\n",
    "        if emotion in self.minority_classes:\n",
    "            return self.strong_augment(samples=samples, sample_rate=sample_rate)\n",
    "        else:\n",
    "            return self.weak_augment(samples=samples, sample_rate=sample_rate)\n",
    "\n",
    "# 어텐션 풀링을 수행하는 헤드\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        # 각 시간 단계의 \"중요도\"를 학습하기 위한 레이어\n",
    "        self.attention_weights = nn.Linear(input_size, 1)\n",
    "        # 최종 분류를 위한 레이어\n",
    "        self.classifier = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, features): # features shape: [batch, seq_len, hidden_size]\n",
    "        # 1. 각 시간 단계별 중요도(attention score) 계산\n",
    "        attention_scores = self.attention_weights(features).squeeze(-1)\n",
    "        \n",
    "        # 2. Softmax를 통해 확률적인 가중치로 변환\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)\n",
    "        \n",
    "        # 3. 계산된 가중치를 원래 특징에 곱하여 가중 평균 계산 (어텐션 풀링)\n",
    "        #    -> 중요한 부분의 특징은 강조되고, 중요하지 않은 부분은 억제됨\n",
    "        weighted_features = torch.sum(features * attention_weights.unsqueeze(-1), dim=1)\n",
    "        \n",
    "        # 4. 최종적으로 가중 평균된 특징을 사용하여 감정 분류\n",
    "        logits = self.classifier(weighted_features)\n",
    "        return logits\n",
    "    \n",
    "# 커스텀 분류기 헤드 정의\n",
    "class CustomClassificationHead(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_size, input_size // 2)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.out_proj = nn.Linear(input_size // 2, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = self.dropout(features)\n",
    "        x = self.dense(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "# HuBERT 몸통과 커스텀 헤드를 결합한 최종 모델을 정의.\n",
    "class EmotionFineTuningModel(nn.Module):\n",
    "    def __init__(self, model_id, num_labels):\n",
    "        super().__init__()\n",
    "        # '몸통' 부분인 기본 HuBERT 모델을 로드\n",
    "        self.base_model = AutoModel.from_pretrained(model_id)\n",
    "        \n",
    "        # 커스텀 헤드를 AttentionHead로 교체\n",
    "        self.classifier = AttentionHead(self.base_model.config.hidden_size, num_labels)\n",
    "        self.base_model_prefix = \"base_model\"\n",
    "        '''\n",
    "        # '머리' 부분인 커스텀 분류기 생성\n",
    "        self.classifier = CustomClassificationHead(self.base_model.config.hidden_size, num_labels)\n",
    "        # 나중에 파라미터 분리를 위해 몸통의 이름을 저장\n",
    "        self.base_model_prefix = \"base_model\"\n",
    "        '''\n",
    "    def forward(self, input_values, attention_mask=None):\n",
    "        outputs = self.base_model(input_values=input_values, attention_mask=attention_mask)\n",
    "        # torch.mean을 사용한 평균 풀링을 제거\n",
    "        # pooled_features = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "        \n",
    "        # 시퀀스 전체를 AttentionHead에 전달\n",
    "        logits = self.classifier(outputs.last_hidden_state)\n",
    "        return logits  \n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Optuna가 최적화할 목표 함수 (단일 실행)\"\"\"\n",
    "    now_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # MLflow는 Optuna의 Trial ID와 연동하여 각 실행을 기록\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}_{now_date}\"):\n",
    "        # 하이퍼파라미터 및 설정 \n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "        SAMPLING_PERCENT = 50\n",
    "        \n",
    "        # 1단계와 2단계의 에폭 수를 명확히 분리하여 정의\n",
    "        HEAD_TUNE_EPOCHS = 15   # 1단계에서 '머리'만 훈련시킬 에폭 수\n",
    "        FULL_TUNE_EPOCHS = 35   # 2단계에서 전체 모델을 훈련시킬 에폭 수\n",
    "        PATIENCE = 10           # 조기 종료 '인내심'도 충분히 늘려줌\n",
    "        \n",
    "        # if model_name == \"wav2vec2\":\n",
    "        # model_id = \"inseong00/wav2vec2-large-xlsr-korean-autumn\"\n",
    "        \n",
    "        MODEL_NAME = trial.suggest_categorical(\"model_name\", [\"hubert-base\"])\n",
    "        # 초기 학습 불안정성을 줄이기 위해 학습률 범위를 약간 낮춤\n",
    "        EARLY_LR = trial.suggest_float(\"lr\", 1e-6, 2e-5, log=True)\n",
    "        #EARLY_LR = trial.suggest_float(\"lr\", 1e-5, 5e-5, log=True)\n",
    "        #LATE_LR = trial.suggest_float(\"lr\", 5e-6, 5e-5, log=True)\n",
    "        #EARLY_LR = trial.suggest_float(\"lr\", 1e-5, 1e-4, log=True)\n",
    "        BACKBONE_LR_SCALE = trial.suggest_float(\"backbone_lr_scale\", 0.05, 0.2, log=True)\n",
    "        BATCH_SIZE = trial.suggest_categorical(\"batch_size\", [4, 8])\n",
    "        ACCUMULATION_STEPS = trial.suggest_int(\"accumulation_steps\", 1, 4)\n",
    "        \n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_param(\"sampling_percent\", SAMPLING_PERCENT)\n",
    "        \n",
    "        \n",
    "        # 데이터 준비\n",
    "        DATA_DIR = Path(f\"./datasets/audio_sampling_sets/dataset_{SAMPLING_PERCENT}_percent\")\n",
    "        \n",
    "        # 소수/다수 클래스 정의 (분석 결과 기반)\n",
    "        minority_classes = ['surprise', 'disgust', 'fear']\n",
    "        \n",
    "        # 소수 클래스에 적용할 강력한 증강 파이프라인\n",
    "        strong_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "            A.TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            A.PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        ])\n",
    "\n",
    "        # 다수 클래스에 적용할 약한 증강 파이프라인 (또는 A.Compose([])로 비워둘 수 있음)\n",
    "        weak_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.005, p=0.2),\n",
    "        ])\n",
    "\n",
    "        # 차등 증강 적용기 생성\n",
    "        train_augmenter = ClassAwareAugment(\n",
    "            minority_classes=minority_classes,\n",
    "            strong_augment=strong_augment,\n",
    "            weak_augment=weak_augment\n",
    "        )\n",
    "\n",
    "        # 훈련셋에는 차등 증강 적용, 검증셋에는 미적용\n",
    "        train_dataset = AudioDataset(metadata_path=DATA_DIR / \"train.csv\", audio_dir=DATA_DIR / \"train\", transform=train_augmenter)\n",
    "        val_dataset = AudioDataset(metadata_path=DATA_DIR / \"val.csv\", audio_dir=DATA_DIR / \"val\", transform=None)\n",
    "        \n",
    "        \n",
    "        # 새로운 EmotionFineTuningModel을 생성\n",
    "        model_id = f\"team-lucid/{MODEL_NAME}-korean\"\n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "        model = EmotionFineTuningModel(model_id, num_labels=len(train_dataset.classes)).to(DEVICE)\n",
    "    \n",
    "        # 클래스 가중치 및 데이터로더\n",
    "        # 훈련 데이터셋의 라벨 분포를 기반으로 가중치 계산\n",
    "        class_names = train_dataset.classes\n",
    "        labels = [train_dataset.class_to_idx[emotion] for emotion in train_dataset.df['emotion']]\n",
    "        \n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "        \n",
    "        print(f\"클래스 가중치 적용: { {name: f'{w:.2f}' for name, w in zip(class_names, class_weights)} }\")\n",
    "        \n",
    "        # 데이터 콜레이터 및 로더\n",
    "        data_collator = DataCollatorForAudio(feature_extractor=feature_extractor, padding=True)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator, num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, num_workers=2, pin_memory=True)\n",
    "        \n",
    "        # 손실 함수에 클래스 가중치 적용\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        '''\n",
    "        # Optuna를 사용할 땐 필요없음.\n",
    "        if trial.number == 0: \n",
    "            # 체크포인트 로드\n",
    "            CHECKPOINT_DIR = Path(\"./checkpoints\")\n",
    "            CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "            CHECKPOINT_PATH = CHECKPOINT_DIR / f'{MODEL_NAME}_{SAMPLING_PERCENT}_percent_best.pth'\n",
    "            start_epoch = 0\n",
    "            \n",
    "            if CHECKPOINT_PATH.exists():\n",
    "                print(f\"체크포인트를 불러옵니다: {CHECKPOINT_PATH}\")\n",
    "                checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                start_epoch = checkpoint['epoch'] + 1\n",
    "                print(f\"체크포인트 로드 완료! {start_epoch} 에폭부터 훈련을 재개합니다.\")\n",
    "            else:\n",
    "                print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "        '''\n",
    "        # =================================================================\n",
    "        # === 1단계: 커스텀 헤드 훈련 ===\n",
    "        # =================================================================\n",
    "        print(f\"\\n--- Trial {trial.number}, 파인튜닝 1단계 시작: 커스텀 헤드 훈련 ---\")\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith(model.base_model_prefix):\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        head_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer_head = optim.AdamW(head_params, lr=EARLY_LR)\n",
    "        # 1단계는 간단한 스케줄러 사용\n",
    "        scheduler_head = torch.optim.lr_scheduler.LinearLR(optimizer_head, start_factor=1.0, end_factor=0.1, total_iters=HEAD_TUNE_EPOCHS)\n",
    "        train_model(\n",
    "            model, train_loader, val_loader, criterion, optimizer_head, scheduler_head, DEVICE,\n",
    "            num_epochs=HEAD_TUNE_EPOCHS, patience=5, accumulation_steps=ACCUMULATION_STEPS\n",
    "        )\n",
    "        \n",
    "        # =================================================================\n",
    "        # === 2단계: 전체 모델 미세 조정 ===\n",
    "        # =================================================================\n",
    "        print(f\"\\n--- Trial {trial.number}, 파인튜닝 2단계 시작: 전체 모델 미세 조정 ---\")\n",
    "        \n",
    "        # 동결했던 '몸통' 파라미터를 모두 학습 가능하도록 해동\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        # 차등 학습률을 적용한 전체 모델용 옵티마이저 생성\n",
    "        backbone_params = model.base_model.parameters()\n",
    "        classifier_params = model.classifier.parameters()\n",
    "        \n",
    "        optimizer_full = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': EARLY_LR * BACKBONE_LR_SCALE},\n",
    "            {'params': classifier_params, 'lr': EARLY_LR}\n",
    "        ])\n",
    "        \n",
    "        # Warmup을 포함한 스케줄러 생성\n",
    "        num_training_steps = len(train_loader) * FULL_TUNE_EPOCHS\n",
    "        num_warmup_steps = int(num_training_steps * 0.1) # 첫 10% 스텝 동안 워밍업\n",
    "        \n",
    "        scheduler_full = get_linear_schedule_with_warmup(\n",
    "            optimizer_full,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        #scheduler_full = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_full, T_max=FULL_TUNE_EPOCHS)\n",
    "        \n",
    "        best_model, best_metrics = train_model(\n",
    "            model, train_loader, val_loader, criterion, optimizer_full, scheduler_full, DEVICE,\n",
    "            num_epochs=FULL_TUNE_EPOCHS,\n",
    "            patience=PATIENCE, \n",
    "            start_epoch=0,\n",
    "            accumulation_steps=ACCUMULATION_STEPS\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        # 훈련된 모델은 MLflow에 아티팩트로 저장 (추후에 결과가 좋아지면 저장)\n",
    "        if best_wts_model:\n",
    "            CHECKPOINT_DIR = Path(\"./checkpoints\")\n",
    "            CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "            BEST_MODEL_PATH = CHECKPOINT_DIR / f\"trial_{trial.number}_best_model.pth\"\n",
    "            \n",
    "            torch.save({'model_state_dict': best_wts_model.state_dict(),\n",
    "                     'optimizer_state_dict': optimizer_full.state_dict(),\n",
    "                     'scheduler_state_dict': scheduler_full.state_dict()}, BEST_MODEL_PATH)\n",
    "            \n",
    "            mlflow.log_artifact(BEST_MODEL_PATH, artifact_path=\"model\")\n",
    "        '''            \n",
    "        # --- 8. 결과 기록 ---\n",
    "        if best_metrics:\n",
    "            REPORT_DIR = Path(\"./reports\")\n",
    "            REPORT_DIR.mkdir(exist_ok=True)\n",
    "            mlflow.log_metrics({\n",
    "                \"best_train_loss\": float(best_metrics['train_loss']),\n",
    "                \"best_train_accuracy\": float(best_metrics['train_accuracy']),\n",
    "                \"best_val_loss\": float(best_metrics['val_loss']),\n",
    "                \"best_val_accuracy\": float(best_metrics['val_accuracy']),\n",
    "                \"best_macro_f1\": float(best_metrics['macro_f1_score']),\n",
    "            })\n",
    "            REPORT_PATH = REPORT_DIR / f\"{MODEL_NAME}_{SAMPLING_PERCENT}_percent_report_trial_{trial.number}_{now_date}.json\"\n",
    "            with open(REPORT_PATH, 'w', encoding='utf-8') as f:\n",
    "                json.dump(best_metrics, f, ensure_ascii=False, indent=4)\n",
    "            mlflow.log_artifact(REPORT_PATH, artifact_path=\"reports\")\n",
    "\n",
    "        return float(best_metrics.get('val_accuracy', 0))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5003\")\n",
    "    mlflow.set_experiment(\"Audio Emotion Finetuning\")\n",
    "    \n",
    "    # 연구 기록을 저장할 데이터베이스 파일과 연구 이름을 정의\n",
    "    STUDY_NAME = \"audio-finetune-study-v1\" # 연구에 고유한 이름을 부여\n",
    "    STORAGE_NAME = f\"sqlite:///{STUDY_NAME}.db\" # SQLite 데이터베이스 파일로 저장\n",
    "    \n",
    "    # storage와 study_name을 지정하고, load_if_exists=True로 설정\n",
    "    # 기존 연구가 있으면 불러오고, 없으면 새로 생성\n",
    "    study = optuna.create_study(\n",
    "        study_name=STUDY_NAME,\n",
    "        storage=STORAGE_NAME,\n",
    "        direction=\"maximize\",\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=1) # n번의 다른 조합으로 실험\n",
    "    \n",
    "    print(\"\\n--- Hyperparameter Optimization Finished ---\")\n",
    "    print(f\"Total trials in this study: {len(study.trials)}\")\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value (Best Val Accuracy): {trial.value}\")\n",
    "    print(f\"  Params: {trial.params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feellog-project (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
