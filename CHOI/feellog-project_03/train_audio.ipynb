{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39942da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 21:00:20,230] A new study created in memory with name: no-name-d7bb6861-3b08-4e60-80b2-6e7d51d2c13a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 2.0737 Acc: 0.0000\n",
      "  [Batch 1870/1870] Train Loss: 1.7358 Acc: 0.2857\n",
      "Train Loss: 1.6944 Acc: 0.4188\n",
      "Val Loss: 1.6668 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6668) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.1591 Acc: 0.7500\n",
      "  [Batch 1870/1870] Train Loss: 1.4253 Acc: 0.5714\n",
      "Train Loss: 1.6458 Acc: 0.4324\n",
      "Val Loss: 1.6391 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6391) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7404 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 2.2370 Acc: 0.1429\n",
      "Train Loss: 1.6412 Acc: 0.4324\n",
      "Val Loss: 1.6452 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/5\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.6329 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.4260 Acc: 0.5714\n",
      "Train Loss: 1.6430 Acc: 0.4324\n",
      "Val Loss: 1.6319 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6319) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 5/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7423 Acc: 0.2500\n",
      "  [Batch 1870/1870] Train Loss: 1.7676 Acc: 0.4286\n",
      "Train Loss: 1.6410 Acc: 0.4324\n",
      "Val Loss: 1.6327 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/5\n",
      "Epoch 6/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.3448 Acc: 0.6250\n",
      "  [Batch 1870/1870] Train Loss: 1.2467 Acc: 0.7143\n",
      "Train Loss: 1.6425 Acc: 0.4317\n",
      "Val Loss: 1.6421 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 2/5\n",
      "Epoch 7/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7580 Acc: 0.2500\n",
      "  [Batch 1870/1870] Train Loss: 1.7785 Acc: 0.4286\n",
      "Train Loss: 1.6383 Acc: 0.4324\n",
      "Val Loss: 1.6312 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6312) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 8/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.5959 Acc: 0.5000\n",
      "  [Batch 1870/1870] Train Loss: 1.3924 Acc: 0.5714\n",
      "Train Loss: 1.6371 Acc: 0.4324\n",
      "Val Loss: 1.6357 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/5\n",
      "Epoch 9/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.9589 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.2959 Acc: 0.5714\n",
      "Train Loss: 1.6402 Acc: 0.4321\n",
      "Val Loss: 1.6364 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 2/5\n",
      "Epoch 10/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.4398 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 2.1870 Acc: 0.1429\n",
      "Train Loss: 1.6566 Acc: 0.4282\n",
      "Val Loss: 1.6351 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 3/5\n",
      "Epoch 11/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 2.2117 Acc: 0.2500\n",
      "  [Batch 1870/1870] Train Loss: 1.3607 Acc: 0.5714\n",
      "Train Loss: 1.6362 Acc: 0.4324\n",
      "Val Loss: 1.6307 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6307) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 12/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.4973 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.2522 Acc: 0.7143\n",
      "Train Loss: 1.6362 Acc: 0.4324\n",
      "Val Loss: 1.6313 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 1/5\n",
      "Epoch 13/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.6025 Acc: 0.3750\n",
      "  [Batch 1870/1870] Train Loss: 1.6634 Acc: 0.4286\n",
      "Train Loss: 1.6564 Acc: 0.4276\n",
      "Val Loss: 1.6487 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 2/5\n",
      "Epoch 14/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.6084 Acc: 0.5000\n",
      "  [Batch 1870/1870] Train Loss: 1.5136 Acc: 0.4286\n",
      "Train Loss: 1.6410 Acc: 0.4322\n",
      "Val Loss: 1.6488 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 3/5\n",
      "Epoch 15/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.7850 Acc: 0.5000\n",
      "  [Batch 1870/1870] Train Loss: 1.6591 Acc: 0.4286\n",
      "Train Loss: 1.6379 Acc: 0.4322\n",
      "Val Loss: 1.6322 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 4/5\n",
      "Epoch 16/100\n",
      "----------\n",
      "  [Batch 20/1870] Train Loss: 1.4448 Acc: 0.6250\n",
      "  [Batch 1870/1870] Train Loss: 1.6384 Acc: 0.4286\n",
      "Train Loss: 1.6337 Acc: 0.4324\n",
      "Val Loss: 1.6318 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë˜ì§€ ì•ŠìŒ. EarlyStopping Counter: 5/5\n",
      "\n",
      "Early stopping! 5 ì—í­ ë™ì•ˆ ì„±ëŠ¥ ê°œì„ ì´ ì—†ì—ˆìŠµë‹ˆë‹¤.\n",
      "--------------------------------------------------\n",
      "Training complete in 191m 38s\n",
      "Saved Epoch: 11\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 1.6362\n",
      "Saved Train Acc: 0.4324\n",
      "Saved Val Loss: 1.6307\n",
      "Saved Val Acc: 0.4324\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 1.6362\n",
      "Best Train Acc: 0.4324\n",
      "Best Val Loss: 1.6307\n",
      "Best Val Acc: 0.4324\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 00:12:01,138] Trial 0 finished with value: 0.4324 and parameters: {'lr': 0.0006796187214702883, 'optimizer': 'AdamW', 'scheduler': 'CosineAnnealingLR', 'batch_size': 8, 'accumulation_steps': 3}. Best is trial 0 with value: 0.4324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: infrastructure/models/weights/checkpoints/hubert-base_50_percent_trained_metrics_20250824_001159.json\n",
      "ğŸƒ View run colorful-lamb-118 at: http://127.0.0.1:5003/#/experiments/971624972587108480/runs/35fed3acc28f495f9150e077398eaf22\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5003/#/experiments/971624972587108480\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\n",
      "ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 2.3232 Acc: 0.0000\n",
      "  [Batch 3740/3740] Train Loss: 2.4303 Acc: 0.0000\n",
      "Train Loss: 1.6320 Acc: 0.4324\n",
      "Val Loss: 1.6309 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6309) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 1.9036 Acc: 0.2500\n",
      "  [Batch 3740/3740] Train Loss: 1.5828 Acc: 0.3333\n",
      "Train Loss: 1.6311 Acc: 0.4323\n",
      "Val Loss: 1.6307 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6307) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 1.9386 Acc: 0.2500\n",
      "  [Batch 3740/3740] Train Loss: 2.0365 Acc: 0.0000\n",
      "Train Loss: 1.6315 Acc: 0.4319\n",
      "Val Loss: 1.6307 Acc: 0.4324 Macro-F1: 0.0862\n",
      "  -> Val Loss ê°œì„ ë¨! (1.6307) ëª¨ë¸ ì €ì¥.\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/3740] Train Loss: 1.2489 Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-24 00:55:59,500] Trial 1 failed with parameters: {'lr': 1.3067644672977184e-05, 'optimizer': 'AdamW', 'scheduler': 'CosineAnnealingLR', 'batch_size': 4, 'accumulation_steps': 3} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_765512/2772290466.py\", line 155, in objective\n",
      "    trained_model, saved_metrics = train_model(model,\n",
      "  File \"/root/feellog_02/core/training/trainer.py\", line 102, in train_model\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/torch/_tensor.py\", line 648, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 353, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/graph.py\", line 824, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-24 00:55:59,504] Trial 1 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run awesome-wren-751 at: http://127.0.0.1:5003/#/experiments/971624972587108480/runs/ac40582e492a42f986f99ad6b3dea335\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5003/#/experiments/971624972587108480\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 210\u001b[0m\n\u001b[1;32m    207\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVoice Emotion Classification Tuning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# në²ˆì˜ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[2], line 155\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m trained_model, saved_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEARLY_STOPPING_PATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# MLflowì— ê²°ê³¼ ê¸°ë¡ ---\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# ìµœê³  ê²€ì¦ ì†ì‹¤ê³¼ ì •í™•ë„, F1 Score ë“±ì„ ê¸°ë¡\u001b[39;00m\n\u001b[1;32m    168\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metrics({\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_train_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(saved_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_train_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(saved_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_macro_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(saved_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro_f1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    174\u001b[0m })\n",
      "File \u001b[0;32m~/feellog_02/core/training/trainer.py:102\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, patience, log_interval, steps_per_epoch, misclassified_dir, start_epoch, accumulation_steps)\u001b[0m\n\u001b[1;32m     99\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    100\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\n\u001b[0;32m--> 102\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Update every N steps\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)  \u001b[38;5;66;03m# Or optimizer.step() without AMP\u001b[39;00m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ./train_audio.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification, DataCollatorWithPadding\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import audiomentations as A\n",
    "\n",
    "from core.data.audio_dataset import AudioDataset\n",
    "from core.training.trainer import train_model\n",
    "from core.data.DataCollatorForAudio import DataCollatorForAudio\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ë¼ë²¨ì— ë”°ë¼ ë‹¤ë¥¸ ì¦ê°•ì„ ì ìš©í•˜ëŠ” ë˜í¼(wrapper) í´ë˜ìŠ¤\n",
    "class ClassAwareAugment:\n",
    "    def __init__(self, minority_classes, strong_augment, weak_augment):\n",
    "        self.minority_classes = minority_classes\n",
    "        self.strong_augment = strong_augment\n",
    "        self.weak_augment = weak_augment\n",
    "\n",
    "    def __call__(self, samples: np.ndarray, sample_rate: int, emotion: str):\n",
    "        if emotion in self.minority_classes:\n",
    "            return self.strong_augment(samples=samples, sample_rate=sample_rate)\n",
    "        else:\n",
    "            return self.weak_augment(samples=samples, sample_rate=sample_rate)\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Optunaê°€ ìµœì í™”í•  ëª©í‘œ í•¨ìˆ˜\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        # --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ëª¨ë¸ ì œì•ˆ ---\n",
    "        #model_id = \"team-lucid/hubert-large-korean\"\n",
    "        #model_name = \"hubert-large\"\n",
    "\n",
    "        #model_id = \"team-lucid/hubert-base-korean\"\n",
    "        #model_name = \"hubert-base\"\n",
    "        #model_name = \"wav2vec2\"\n",
    "        #model_name = trial.suggest_categorical(\"model_name\", [\"wav2vec2\", \"hubert-large\"])\n",
    "        \n",
    "        '''\n",
    "        # Optunaê°€ ì´ ë²”ìœ„ ë‚´ì—ì„œ ìµœì ì˜ ê°’ì„ ì°¾ì•„ ì œì•ˆí•©ë‹ˆë‹¤.\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\"])\n",
    "        scheduler_name = trial.suggest_categorical(\"scheduler\", [\"StepLR\", \"CosineAnnealingLR\", \"ReduceLROnPlateau\"])\n",
    "        BATCH_SIZE = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "        accumulation_steps = trial.suggest_int(\"accumulation_steps\", 1, 4)\n",
    "        mlflow.log_params(trial.params)\n",
    "        '''\n",
    "        \n",
    "        model_name = trial.suggest_categorical(\"model_name\", [\"hubert-base\"])\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\"])\n",
    "        \n",
    "        # 'ë¨¸ë¦¬' ë¶€ë¶„ í•™ìŠµë¥  ëŒ€ë¹„ 'ëª¸í†µ' ë¶€ë¶„ í•™ìŠµë¥ ì˜ ë¹„ìœ¨ì„ Optunaê°€ ì°¾ë„ë¡ í•¨\n",
    "        # ì˜ˆ: lr=1e-4, backbone_lr_scale=0.1 ì´ë©´, ëª¸í†µì˜ í•™ìŠµë¥ ì€ 1e-5ê°€ ë¨\n",
    "        backbone_lr_scale = trial.suggest_float(\"backbone_lr_scale\", 0.01, 0.5, log=True)\n",
    "        \n",
    "        mlflow.log_params(trial.params)\n",
    "        \n",
    "        # CUDA ì„±ëŠ¥ í”Œë˜ê·¸ ìµœì í™”\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        # TF32 í…ì„œ ì½”ì–´ ì‚¬ìš©ì„ í—ˆìš©í•˜ì—¬ Ampere ì•„í‚¤í…ì²˜ ì´ìƒ GPUì—ì„œ ì—°ì‚° ì†ë„ í–¥ìƒ\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        \n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "        # --- ë°ì´í„° ì¤€ë¹„ ---\n",
    "        sampling_percent = 50\n",
    "        mlflow.log_param(\"sampling_percent\", sampling_percent)\n",
    "        mlflow.set_tag(\"dataset_description\", f\"{sampling_percent} ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨\")\n",
    "        \n",
    "        NUM_EPOCHS = 100\n",
    "        EARLY_STOPPING_PATIENCE = 5\n",
    "\n",
    "        # --- ë°ì´í„° ì¤€ë¹„ ---\n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        DATA_DIR = Path(f\"./datasets/audio_sampling_sets/dataset_{sampling_percent}_percent\")\n",
    "        \n",
    "        # ì†Œìˆ˜/ë‹¤ìˆ˜ í´ë˜ìŠ¤ ì •ì˜ (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)\n",
    "        minority_classes = ['surprise', 'disgust', 'fear']\n",
    "        \n",
    "        # ì†Œìˆ˜ í´ë˜ìŠ¤ì— ì ìš©í•  ê°•ë ¥í•œ ì¦ê°• íŒŒì´í”„ë¼ì¸\n",
    "        strong_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "            A.TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            A.PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        ])\n",
    "\n",
    "        # ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— ì ìš©í•  ì•½í•œ ì¦ê°• íŒŒì´í”„ë¼ì¸ (ë˜ëŠ” A.Compose([])ë¡œ ë¹„ì›Œë‘˜ ìˆ˜ ìˆìŒ)\n",
    "        weak_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.005, p=0.2),\n",
    "        ])\n",
    "\n",
    "        # ì°¨ë“± ì¦ê°• ì ìš©ê¸° ìƒì„±\n",
    "        train_augmenter = ClassAwareAugment(\n",
    "            minority_classes=minority_classes,\n",
    "            strong_augment=strong_augment,\n",
    "            weak_augment=weak_augment\n",
    "        )\n",
    "\n",
    "        # í›ˆë ¨ì…‹ì—ëŠ” ì°¨ë“± ì¦ê°• ì ìš©, ê²€ì¦ì…‹ì—ëŠ” ë¯¸ì ìš©\n",
    "        train_dataset = AudioDataset(metadata_path=DATA_DIR / \"train.csv\", audio_dir=DATA_DIR / \"train\", transform=train_augmenter)\n",
    "        val_dataset = AudioDataset(metadata_path=DATA_DIR / \"val.csv\", audio_dir=DATA_DIR / \"val\", transform=None)\n",
    "\n",
    "        # --- ëª¨ë¸ ë° Feature Extractor ë¡œë“œ ---\n",
    "        if model_name == \"wav2vec2\":\n",
    "            model_id = \"inseong00/wav2vec2-large-xlsr-korean-autumn\"\n",
    "        elif model_name == \"hubert-large\":\n",
    "            model_id = \"team-lucid/hubert-large-korean\"\n",
    "        elif model_name == \"hubert-base\":\n",
    "            model_id = \"team-lucid/hubert-base-korean\"\n",
    "        else:\n",
    "            raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì´ë¦„ì…ë‹ˆë‹¤.\")\n",
    "            \n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "        \n",
    "        model = AutoModelForAudioClassification.from_pretrained(\n",
    "            model_id,\n",
    "            num_labels=len(train_dataset.classes),\n",
    "            label2id=train_dataset.class_to_idx,\n",
    "            id2label=train_dataset.idx_to_class,\n",
    "            ignore_mismatched_sizes=True # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ë¶„ë¥˜ì¸µê³¼ í¬ê¸°ê°€ ë‹¬ë¼ë„ ì—ëŸ¬ ì—†ì´ ë¡œë“œ\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        # íŒŒë¼ë¯¸í„° ê·¸ë£¹ ë¶„ë¦¬ ---\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith(\"hubert.\"):\n",
    "                backbone_params.append(param)\n",
    "            else:\n",
    "                classifier_params.append(param)\n",
    "        \n",
    "        # ì°¨ë“± í•™ìŠµë¥ ì„ ì ìš©í•˜ì—¬ ì˜µí‹°ë§ˆì´ì € ìƒì„± ---\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': backbone_params, 'lr': lr * backbone_lr_scale},\n",
    "            {'params': classifier_params, 'lr': lr}\n",
    "        ]\n",
    "        \n",
    "        optimizer = getattr(optim, optimizer_name)(optimizer_grouped_parameters)\n",
    "\n",
    "        # --- í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ---\n",
    "        # í›ˆë ¨ ë°ì´í„°ì…‹ì˜ ë¼ë²¨ ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "        class_names = train_dataset.classes\n",
    "        labels = [train_dataset.class_to_idx[emotion] for emotion in train_dataset.df['emotion']]\n",
    "        \n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "        \n",
    "        print(f\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©: { {name: f'{w:.2f}' for name, w in zip(class_names, class_weights)} }\")\n",
    "        \n",
    "        # ë°ì´í„° ì½œë ˆì´í„° ë° ë¡œë”\n",
    "        # ìƒˆë¡œ ë§Œë“  DataCollator í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©\n",
    "        data_collator = DataCollatorForAudio(feature_extractor=feature_extractor, padding=True)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator, num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # ì†ì‹¤ í•¨ìˆ˜ì— í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "        checkpoint_dir = Path(\"./infrastructure/models/weights/checkpoints\")\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "        CHECKPOINT_PATH = checkpoint_dir / f'{model_name}_{sampling_percent}_trained.pth'\n",
    "        if CHECKPOINT_PATH.exists():\n",
    "            print(\"ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\")\n",
    "            checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(\"ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\")\n",
    "        else:\n",
    "            print(\"ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        trained_model, saved_metrics = train_model(model, \n",
    "                                                   train_loader, \n",
    "                                                   val_loader, \n",
    "                                                   criterion, \n",
    "                                                   optimizer, \n",
    "                                                   scheduler, \n",
    "                                                   DEVICE, \n",
    "                                                   num_epochs=NUM_EPOCHS, \n",
    "                                                   patience=EARLY_STOPPING_PATIENCE,\n",
    "                                                   accumulation_steps=accumulation_steps)\n",
    "\n",
    "        # MLflowì— ê²°ê³¼ ê¸°ë¡ ---\n",
    "        # ìµœê³  ê²€ì¦ ì†ì‹¤ê³¼ ì •í™•ë„, F1 Score ë“±ì„ ê¸°ë¡\n",
    "        mlflow.log_metrics({\n",
    "            \"best_train_loss\": float(saved_metrics['train_loss']),\n",
    "            \"best_train_accuracy\": float(saved_metrics['train_accuracy']),\n",
    "            \"best_val_loss\": float(saved_metrics['val_loss']),\n",
    "            \"best_val_accuracy\": float(saved_metrics['val_accuracy']),\n",
    "            \"best_macro_f1\": float(saved_metrics['macro_f1_score']),\n",
    "        })\n",
    "        \n",
    "        # í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥\n",
    "        torch.save(trained_model.state_dict(), CHECKPOINT_PATH)\n",
    "        \n",
    "        # MLflowì— ëª¨ë¸ ì €ì¥\n",
    "        now_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        trained_model_save = checkpoint_dir / f'{model_name}_{sampling_percent}_trained_{now_date}.pth'\n",
    "        torch.save(trained_model.state_dict(), trained_model_save)\n",
    "        mlflow.log_artifact(trained_model_save, artifact_path=\"model\")\n",
    "        print(\"í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        # ìµœê³  ì„±ëŠ¥ ì‹œì ì˜ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥\n",
    "        METRICS_PATH = checkpoint_dir / f'{model_name}_{sampling_percent}_percent_trained_metrics_{now_date}.json'\n",
    "        with open(METRICS_PATH, 'a', encoding='utf-8') as f:\n",
    "            json.dump(saved_metrics, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {METRICS_PATH}\")\n",
    "        mlflow.log_artifact(METRICS_PATH, artifact_path=\"metrics\")\n",
    "                \n",
    "        # --- 5. Optunaì— ëª©í‘œê°’ ë°˜í™˜ ---\n",
    "        # ìš°ë¦¬ëŠ” ê²€ì¦ ì†ì‹¤(val_loss)ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨\n",
    "        return float(saved_metrics['val_accuracy']) # OptunaëŠ” ìµœëŒ€í™”ë¥¼ ëª©í‘œë¡œ í•¨\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #ì½”ë“œ ì‹¤í–‰ ì „ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰\n",
    "    # mlflow ui\n",
    "    # ìœ„ì˜ ëª…ë ¹ì–´ë§Œ ë¨¼ì €í•´ë³´ê³  ì—ëŸ¬ MlflowException: When an mlflow-artifacts URI was supplied, the tracking URI must be a valid http or https URI ê°€ ë°œìƒí•˜ë©´ ì•„ë˜ ëª…ë ¹ì–´ ì‹¤í–‰.\n",
    "    # mlflow server --host 127.0.0.1 --port 5001\n",
    "    \n",
    "    # MLflow ì¶”ì  ì„œë²„ URI ì„¤ì •\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5003\")\n",
    "    \n",
    "    # MLflow ì‹¤í—˜ ì´ë¦„ ì„¤ì •, ëŒ€ì‰¬ë³´ë“œì—ì„œ í›ˆë ¨ì„ êµ¬ë¶„í•˜ì—¬ ë³´ê¸°ìœ„í•´ ì‚¬ìš©.\n",
    "    mlflow.set_experiment(\"Voice Emotion Classification Tuning\")\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=5) # në²ˆì˜ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value (Best Val Accuracy): {trial.value}\")\n",
    "    print(f\"  Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249d9a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\n",
      "odict_keys(['hubert.masked_spec_embed', 'hubert.feature_extractor.conv_layers.0.conv.weight', 'hubert.feature_extractor.conv_layers.0.layer_norm.weight', 'hubert.feature_extractor.conv_layers.0.layer_norm.bias', 'hubert.feature_extractor.conv_layers.1.conv.weight', 'hubert.feature_extractor.conv_layers.2.conv.weight', 'hubert.feature_extractor.conv_layers.3.conv.weight', 'hubert.feature_extractor.conv_layers.4.conv.weight', 'hubert.feature_extractor.conv_layers.5.conv.weight', 'hubert.feature_extractor.conv_layers.6.conv.weight', 'hubert.feature_projection.layer_norm.weight', 'hubert.feature_projection.layer_norm.bias', 'hubert.feature_projection.projection.weight', 'hubert.feature_projection.projection.bias', 'hubert.encoder.pos_conv_embed.conv.bias', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'hubert.encoder.layer_norm.weight', 'hubert.encoder.layer_norm.bias', 'hubert.encoder.layers.0.attention.k_proj.weight', 'hubert.encoder.layers.0.attention.k_proj.bias', 'hubert.encoder.layers.0.attention.v_proj.weight', 'hubert.encoder.layers.0.attention.v_proj.bias', 'hubert.encoder.layers.0.attention.q_proj.weight', 'hubert.encoder.layers.0.attention.q_proj.bias', 'hubert.encoder.layers.0.attention.out_proj.weight', 'hubert.encoder.layers.0.attention.out_proj.bias', 'hubert.encoder.layers.0.layer_norm.weight', 'hubert.encoder.layers.0.layer_norm.bias', 'hubert.encoder.layers.0.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.0.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.0.feed_forward.output_dense.weight', 'hubert.encoder.layers.0.feed_forward.output_dense.bias', 'hubert.encoder.layers.0.final_layer_norm.weight', 'hubert.encoder.layers.0.final_layer_norm.bias', 'hubert.encoder.layers.1.attention.k_proj.weight', 'hubert.encoder.layers.1.attention.k_proj.bias', 'hubert.encoder.layers.1.attention.v_proj.weight', 'hubert.encoder.layers.1.attention.v_proj.bias', 'hubert.encoder.layers.1.attention.q_proj.weight', 'hubert.encoder.layers.1.attention.q_proj.bias', 'hubert.encoder.layers.1.attention.out_proj.weight', 'hubert.encoder.layers.1.attention.out_proj.bias', 'hubert.encoder.layers.1.layer_norm.weight', 'hubert.encoder.layers.1.layer_norm.bias', 'hubert.encoder.layers.1.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.1.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.1.feed_forward.output_dense.weight', 'hubert.encoder.layers.1.feed_forward.output_dense.bias', 'hubert.encoder.layers.1.final_layer_norm.weight', 'hubert.encoder.layers.1.final_layer_norm.bias', 'hubert.encoder.layers.2.attention.k_proj.weight', 'hubert.encoder.layers.2.attention.k_proj.bias', 'hubert.encoder.layers.2.attention.v_proj.weight', 'hubert.encoder.layers.2.attention.v_proj.bias', 'hubert.encoder.layers.2.attention.q_proj.weight', 'hubert.encoder.layers.2.attention.q_proj.bias', 'hubert.encoder.layers.2.attention.out_proj.weight', 'hubert.encoder.layers.2.attention.out_proj.bias', 'hubert.encoder.layers.2.layer_norm.weight', 'hubert.encoder.layers.2.layer_norm.bias', 'hubert.encoder.layers.2.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.2.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.2.feed_forward.output_dense.weight', 'hubert.encoder.layers.2.feed_forward.output_dense.bias', 'hubert.encoder.layers.2.final_layer_norm.weight', 'hubert.encoder.layers.2.final_layer_norm.bias', 'hubert.encoder.layers.3.attention.k_proj.weight', 'hubert.encoder.layers.3.attention.k_proj.bias', 'hubert.encoder.layers.3.attention.v_proj.weight', 'hubert.encoder.layers.3.attention.v_proj.bias', 'hubert.encoder.layers.3.attention.q_proj.weight', 'hubert.encoder.layers.3.attention.q_proj.bias', 'hubert.encoder.layers.3.attention.out_proj.weight', 'hubert.encoder.layers.3.attention.out_proj.bias', 'hubert.encoder.layers.3.layer_norm.weight', 'hubert.encoder.layers.3.layer_norm.bias', 'hubert.encoder.layers.3.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.3.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.3.feed_forward.output_dense.weight', 'hubert.encoder.layers.3.feed_forward.output_dense.bias', 'hubert.encoder.layers.3.final_layer_norm.weight', 'hubert.encoder.layers.3.final_layer_norm.bias', 'hubert.encoder.layers.4.attention.k_proj.weight', 'hubert.encoder.layers.4.attention.k_proj.bias', 'hubert.encoder.layers.4.attention.v_proj.weight', 'hubert.encoder.layers.4.attention.v_proj.bias', 'hubert.encoder.layers.4.attention.q_proj.weight', 'hubert.encoder.layers.4.attention.q_proj.bias', 'hubert.encoder.layers.4.attention.out_proj.weight', 'hubert.encoder.layers.4.attention.out_proj.bias', 'hubert.encoder.layers.4.layer_norm.weight', 'hubert.encoder.layers.4.layer_norm.bias', 'hubert.encoder.layers.4.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.4.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.4.feed_forward.output_dense.weight', 'hubert.encoder.layers.4.feed_forward.output_dense.bias', 'hubert.encoder.layers.4.final_layer_norm.weight', 'hubert.encoder.layers.4.final_layer_norm.bias', 'hubert.encoder.layers.5.attention.k_proj.weight', 'hubert.encoder.layers.5.attention.k_proj.bias', 'hubert.encoder.layers.5.attention.v_proj.weight', 'hubert.encoder.layers.5.attention.v_proj.bias', 'hubert.encoder.layers.5.attention.q_proj.weight', 'hubert.encoder.layers.5.attention.q_proj.bias', 'hubert.encoder.layers.5.attention.out_proj.weight', 'hubert.encoder.layers.5.attention.out_proj.bias', 'hubert.encoder.layers.5.layer_norm.weight', 'hubert.encoder.layers.5.layer_norm.bias', 'hubert.encoder.layers.5.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.5.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.5.feed_forward.output_dense.weight', 'hubert.encoder.layers.5.feed_forward.output_dense.bias', 'hubert.encoder.layers.5.final_layer_norm.weight', 'hubert.encoder.layers.5.final_layer_norm.bias', 'hubert.encoder.layers.6.attention.k_proj.weight', 'hubert.encoder.layers.6.attention.k_proj.bias', 'hubert.encoder.layers.6.attention.v_proj.weight', 'hubert.encoder.layers.6.attention.v_proj.bias', 'hubert.encoder.layers.6.attention.q_proj.weight', 'hubert.encoder.layers.6.attention.q_proj.bias', 'hubert.encoder.layers.6.attention.out_proj.weight', 'hubert.encoder.layers.6.attention.out_proj.bias', 'hubert.encoder.layers.6.layer_norm.weight', 'hubert.encoder.layers.6.layer_norm.bias', 'hubert.encoder.layers.6.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.6.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.6.feed_forward.output_dense.weight', 'hubert.encoder.layers.6.feed_forward.output_dense.bias', 'hubert.encoder.layers.6.final_layer_norm.weight', 'hubert.encoder.layers.6.final_layer_norm.bias', 'hubert.encoder.layers.7.attention.k_proj.weight', 'hubert.encoder.layers.7.attention.k_proj.bias', 'hubert.encoder.layers.7.attention.v_proj.weight', 'hubert.encoder.layers.7.attention.v_proj.bias', 'hubert.encoder.layers.7.attention.q_proj.weight', 'hubert.encoder.layers.7.attention.q_proj.bias', 'hubert.encoder.layers.7.attention.out_proj.weight', 'hubert.encoder.layers.7.attention.out_proj.bias', 'hubert.encoder.layers.7.layer_norm.weight', 'hubert.encoder.layers.7.layer_norm.bias', 'hubert.encoder.layers.7.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.7.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.7.feed_forward.output_dense.weight', 'hubert.encoder.layers.7.feed_forward.output_dense.bias', 'hubert.encoder.layers.7.final_layer_norm.weight', 'hubert.encoder.layers.7.final_layer_norm.bias', 'hubert.encoder.layers.8.attention.k_proj.weight', 'hubert.encoder.layers.8.attention.k_proj.bias', 'hubert.encoder.layers.8.attention.v_proj.weight', 'hubert.encoder.layers.8.attention.v_proj.bias', 'hubert.encoder.layers.8.attention.q_proj.weight', 'hubert.encoder.layers.8.attention.q_proj.bias', 'hubert.encoder.layers.8.attention.out_proj.weight', 'hubert.encoder.layers.8.attention.out_proj.bias', 'hubert.encoder.layers.8.layer_norm.weight', 'hubert.encoder.layers.8.layer_norm.bias', 'hubert.encoder.layers.8.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.8.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.8.feed_forward.output_dense.weight', 'hubert.encoder.layers.8.feed_forward.output_dense.bias', 'hubert.encoder.layers.8.final_layer_norm.weight', 'hubert.encoder.layers.8.final_layer_norm.bias', 'hubert.encoder.layers.9.attention.k_proj.weight', 'hubert.encoder.layers.9.attention.k_proj.bias', 'hubert.encoder.layers.9.attention.v_proj.weight', 'hubert.encoder.layers.9.attention.v_proj.bias', 'hubert.encoder.layers.9.attention.q_proj.weight', 'hubert.encoder.layers.9.attention.q_proj.bias', 'hubert.encoder.layers.9.attention.out_proj.weight', 'hubert.encoder.layers.9.attention.out_proj.bias', 'hubert.encoder.layers.9.layer_norm.weight', 'hubert.encoder.layers.9.layer_norm.bias', 'hubert.encoder.layers.9.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.9.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.9.feed_forward.output_dense.weight', 'hubert.encoder.layers.9.feed_forward.output_dense.bias', 'hubert.encoder.layers.9.final_layer_norm.weight', 'hubert.encoder.layers.9.final_layer_norm.bias', 'hubert.encoder.layers.10.attention.k_proj.weight', 'hubert.encoder.layers.10.attention.k_proj.bias', 'hubert.encoder.layers.10.attention.v_proj.weight', 'hubert.encoder.layers.10.attention.v_proj.bias', 'hubert.encoder.layers.10.attention.q_proj.weight', 'hubert.encoder.layers.10.attention.q_proj.bias', 'hubert.encoder.layers.10.attention.out_proj.weight', 'hubert.encoder.layers.10.attention.out_proj.bias', 'hubert.encoder.layers.10.layer_norm.weight', 'hubert.encoder.layers.10.layer_norm.bias', 'hubert.encoder.layers.10.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.10.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.10.feed_forward.output_dense.weight', 'hubert.encoder.layers.10.feed_forward.output_dense.bias', 'hubert.encoder.layers.10.final_layer_norm.weight', 'hubert.encoder.layers.10.final_layer_norm.bias', 'hubert.encoder.layers.11.attention.k_proj.weight', 'hubert.encoder.layers.11.attention.k_proj.bias', 'hubert.encoder.layers.11.attention.v_proj.weight', 'hubert.encoder.layers.11.attention.v_proj.bias', 'hubert.encoder.layers.11.attention.q_proj.weight', 'hubert.encoder.layers.11.attention.q_proj.bias', 'hubert.encoder.layers.11.attention.out_proj.weight', 'hubert.encoder.layers.11.attention.out_proj.bias', 'hubert.encoder.layers.11.layer_norm.weight', 'hubert.encoder.layers.11.layer_norm.bias', 'hubert.encoder.layers.11.feed_forward.intermediate_dense.weight', 'hubert.encoder.layers.11.feed_forward.intermediate_dense.bias', 'hubert.encoder.layers.11.feed_forward.output_dense.weight', 'hubert.encoder.layers.11.feed_forward.output_dense.bias', 'hubert.encoder.layers.11.final_layer_norm.weight', 'hubert.encoder.layers.11.final_layer_norm.bias', 'projector.weight', 'projector.bias', 'classifier.weight', 'classifier.bias'])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "<generator object Module.parameters at 0x76a8a781ff90>\n"
     ]
    }
   ],
   "source": [
    "model_id = \"team-lucid/hubert-base-korean\"\n",
    "model_name = \"hubert-base\"\n",
    "sampling_percent = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = Path(f\"./datasets/audio_sampling_sets/dataset_{sampling_percent}_percent\")\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "train_dataset = AudioDataset(metadata_path=DATA_DIR / \"train.csv\", audio_dir=DATA_DIR / \"train\")        \n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(train_dataset.classes),\n",
    "    label2id=train_dataset.class_to_idx,\n",
    "    id2label=train_dataset.idx_to_class,\n",
    "    ignore_mismatched_sizes=True # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ë¶„ë¥˜ì¸µê³¼ í¬ê¸°ê°€ ë‹¬ë¼ë„ ì—ëŸ¬ ì—†ì´ ë¡œë“œ\n",
    ").to(DEVICE)      \n",
    "  \n",
    "checkpoint = torch.load(Path('./infrastructure/models/weights/checkpoints/hubert-base_50_trained.pth'))\n",
    "model.load_state_dict(checkpoint)\n",
    "print(\"ì²´í¬í¬ì¸íŠ¸(ëª¨ë¸ ê°€ì¤‘ì¹˜) ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(model.state_dict().keys())\n",
    "print(\"-\"*50)\n",
    "print(\"-\"*50)\n",
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62ab0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   1756 MiB |   1756 MiB |   1756 MiB | 496128 B   |\n",
      "|       from large pool |   1753 MiB |   1753 MiB |   1753 MiB |      0 B   |\n",
      "|       from small pool |      2 MiB |      2 MiB |      2 MiB | 496128 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   1756 MiB |   1756 MiB |   1756 MiB | 496128 B   |\n",
      "|       from large pool |   1753 MiB |   1753 MiB |   1753 MiB |      0 B   |\n",
      "|       from small pool |      2 MiB |      2 MiB |      2 MiB | 496128 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   1754 MiB |   1754 MiB |   1754 MiB | 386140 B   |\n",
      "|       from large pool |   1751 MiB |   1751 MiB |   1751 MiB |      0 B   |\n",
      "|       from small pool |      2 MiB |      2 MiB |      2 MiB | 386140 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   1824 MiB |   1824 MiB |   1824 MiB |      0 B   |\n",
      "|       from large pool |   1820 MiB |   1820 MiB |   1820 MiB |      0 B   |\n",
      "|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  69557 KiB |  83231 KiB | 527056 KiB | 457499 KiB |\n",
      "|       from large pool |  68048 KiB |  82944 KiB | 523264 KiB | 455216 KiB |\n",
      "|       from small pool |   1509 KiB |   2028 KiB |   3792 KiB |   2283 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     435    |     436    |     652    |     217    |\n",
      "|       from large pool |     163    |     163    |     163    |       0    |\n",
      "|       from small pool |     272    |     273    |     489    |     217    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     435    |     436    |     652    |     217    |\n",
      "|       from large pool |     163    |     163    |     163    |       0    |\n",
      "|       from small pool |     272    |     273    |     489    |     217    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      44    |      44    |      44    |       0    |\n",
      "|       from large pool |      42    |      42    |      42    |       0    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      36    |      36    |      40    |       4    |\n",
      "|       from large pool |      34    |      34    |      38    |       4    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e965a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 23:55:24,266] Using an existing study with name 'audio-finetune-study-v1' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at team-lucid/hubert-base-korean and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©: {'angry': '0.75', 'disgust': '2.09', 'fear': '2.00', 'happiness': '1.35', 'neutral': '1.47', 'sadness': '0.33', 'surprise': '4.11'}\n",
      "\n",
      "--- Trial 24, íŒŒì¸íŠœë‹ 1ë‹¨ê³„ ì‹œì‘: ì»¤ìŠ¤í…€ í—¤ë“œ í›ˆë ¨ ---\n",
      "Epoch 1/15\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-24 23:55:26,647] Trial 24 failed with parameters: {'model_name': 'hubert-base', 'lr': 1.5676995571651015e-05, 'backbone_lr_scale': 0.06049605839374828, 'batch_size': 8, 'accumulation_steps': 4} because of the following error: TypeError(\"unsupported operand type(s) for /: 'NoneType' and 'int'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_960283/1930072545.py\", line 237, in objective\n",
      "    train_model(\n",
      "  File \"/root/feellog_02/core/training/trainer.py\", line 104, in train_model\n",
      "    loss = loss / accumulation_steps\n",
      "TypeError: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "[W 2025-08-24 23:55:26,649] Trial 24 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run trial_24_20250824_235524 at: http://127.0.0.1:5003/#/experiments/200841879867459833/runs/6f2a922b4770404882f7c60c97f35897\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5003/#/experiments/200841879867459833\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 332\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# storageì™€ study_nameì„ ì§€ì •í•˜ê³ , load_if_exists=Trueë¡œ ì„¤ì •\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# ê¸°ì¡´ ì—°êµ¬ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\u001b[39;00m\n\u001b[1;32m    325\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    326\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mSTUDY_NAME,\n\u001b[1;32m    327\u001b[0m     storage\u001b[38;5;241m=\u001b[39mSTORAGE_NAME,\n\u001b[1;32m    328\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    329\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    330\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# në²ˆì˜ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Hyperparameter Optimization Finished ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal trials in this study: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/feellog_02/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[2], line 237\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# 1ë‹¨ê³„ëŠ” ê°„ë‹¨í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©\u001b[39;00m\n\u001b[1;32m    236\u001b[0m scheduler_head \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mLinearLR(optimizer_head, start_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, end_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, total_iters\u001b[38;5;241m=\u001b[39mHEAD_TUNE_EPOCHS)\n\u001b[0;32m--> 237\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEAD_TUNE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACCUMULATION_STEPS\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# =================================================================\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# === 2ë‹¨ê³„: ì „ì²´ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ===\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# =================================================================\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, íŒŒì¸íŠœë‹ 2ë‹¨ê³„ ì‹œì‘: ì „ì²´ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/feellog_02/core/training/trainer.py:104\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, patience, log_interval, steps_per_epoch, misclassified_dir, start_epoch, accumulation_steps)\u001b[0m\n\u001b[1;32m    101\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    102\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\n\u001b[0;32m--> 104\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\n\u001b[1;32m    106\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# accumulation_steps ë§ˆë‹¤ ëª¨ë¸ ì—…ë°ì´íŠ¸\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoFeatureExtractor, AutoModel \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import audiomentations as A\n",
    "\n",
    "from core.data.audio_dataset import AudioDataset\n",
    "from core.training.trainer import train_model\n",
    "from core.data.DataCollatorForAudio import DataCollatorForAudio\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ë¼ë²¨ì— ë”°ë¼ ë‹¤ë¥¸ ì¦ê°•ì„ ì ìš©í•˜ëŠ” ë˜í¼(wrapper) í´ë˜ìŠ¤\n",
    "class ClassAwareAugment:\n",
    "    def __init__(self, minority_classes, strong_augment, weak_augment):\n",
    "        self.minority_classes = minority_classes\n",
    "        self.strong_augment = strong_augment\n",
    "        self.weak_augment = weak_augment\n",
    "\n",
    "    def __call__(self, samples: np.ndarray, sample_rate: int, emotion: str):\n",
    "        if emotion in self.minority_classes:\n",
    "            return self.strong_augment(samples=samples, sample_rate=sample_rate)\n",
    "        else:\n",
    "            return self.weak_augment(samples=samples, sample_rate=sample_rate)\n",
    "\n",
    "# ì–´í…ì…˜ í’€ë§ì„ ìˆ˜í–‰í•˜ëŠ” í—¤ë“œ\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        # ê° ì‹œê°„ ë‹¨ê³„ì˜ \"ì¤‘ìš”ë„\"ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ë ˆì´ì–´\n",
    "        self.attention_weights = nn.Linear(input_size, 1)\n",
    "        # ìµœì¢… ë¶„ë¥˜ë¥¼ ìœ„í•œ ë ˆì´ì–´\n",
    "        self.classifier = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, features): # features shape: [batch, seq_len, hidden_size]\n",
    "        # 1. ê° ì‹œê°„ ë‹¨ê³„ë³„ ì¤‘ìš”ë„(attention score) ê³„ì‚°\n",
    "        attention_scores = self.attention_weights(features).squeeze(-1)\n",
    "        \n",
    "        # 2. Softmaxë¥¼ í†µí•´ í™•ë¥ ì ì¸ ê°€ì¤‘ì¹˜ë¡œ ë³€í™˜\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)\n",
    "        \n",
    "        # 3. ê³„ì‚°ëœ ê°€ì¤‘ì¹˜ë¥¼ ì›ë˜ íŠ¹ì§•ì— ê³±í•˜ì—¬ ê°€ì¤‘ í‰ê·  ê³„ì‚° (ì–´í…ì…˜ í’€ë§)\n",
    "        #    -> ì¤‘ìš”í•œ ë¶€ë¶„ì˜ íŠ¹ì§•ì€ ê°•ì¡°ë˜ê³ , ì¤‘ìš”í•˜ì§€ ì•Šì€ ë¶€ë¶„ì€ ì–µì œë¨\n",
    "        weighted_features = torch.sum(features * attention_weights.unsqueeze(-1), dim=1)\n",
    "        \n",
    "        # 4. ìµœì¢…ì ìœ¼ë¡œ ê°€ì¤‘ í‰ê· ëœ íŠ¹ì§•ì„ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ë¥˜\n",
    "        logits = self.classifier(weighted_features)\n",
    "        return logits\n",
    "    \n",
    "# ì»¤ìŠ¤í…€ ë¶„ë¥˜ê¸° í—¤ë“œ ì •ì˜\n",
    "class CustomClassificationHead(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_size, input_size // 2)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.out_proj = nn.Linear(input_size // 2, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = self.dropout(features)\n",
    "        x = self.dense(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "# HuBERT ëª¸í†µê³¼ ì»¤ìŠ¤í…€ í—¤ë“œë¥¼ ê²°í•©í•œ ìµœì¢… ëª¨ë¸ì„ ì •ì˜.\n",
    "class EmotionFineTuningModel(nn.Module):\n",
    "    def __init__(self, model_id, num_labels):\n",
    "        super().__init__()\n",
    "        # 'ëª¸í†µ' ë¶€ë¶„ì¸ ê¸°ë³¸ HuBERT ëª¨ë¸ì„ ë¡œë“œ\n",
    "        self.base_model = AutoModel.from_pretrained(model_id)\n",
    "        \n",
    "        # ì»¤ìŠ¤í…€ í—¤ë“œë¥¼ AttentionHeadë¡œ êµì²´\n",
    "        self.classifier = AttentionHead(self.base_model.config.hidden_size, num_labels)\n",
    "        self.base_model_prefix = \"base_model\"\n",
    "        '''\n",
    "        # 'ë¨¸ë¦¬' ë¶€ë¶„ì¸ ì»¤ìŠ¤í…€ ë¶„ë¥˜ê¸° ìƒì„±\n",
    "        self.classifier = CustomClassificationHead(self.base_model.config.hidden_size, num_labels)\n",
    "        # ë‚˜ì¤‘ì— íŒŒë¼ë¯¸í„° ë¶„ë¦¬ë¥¼ ìœ„í•´ ëª¸í†µì˜ ì´ë¦„ì„ ì €ì¥\n",
    "        self.base_model_prefix = \"base_model\"\n",
    "        '''\n",
    "    def forward(self, input_values, attention_mask=None):\n",
    "        outputs = self.base_model(input_values=input_values, attention_mask=attention_mask)\n",
    "        # torch.meanì„ ì‚¬ìš©í•œ í‰ê·  í’€ë§ì„ ì œê±°\n",
    "        # pooled_features = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "        \n",
    "        # ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ AttentionHeadì— ì „ë‹¬\n",
    "        logits = self.classifier(outputs.last_hidden_state)\n",
    "        return logits  \n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Optunaê°€ ìµœì í™”í•  ëª©í‘œ í•¨ìˆ˜ (ë‹¨ì¼ ì‹¤í–‰)\"\"\"\n",
    "    now_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # MLflowëŠ” Optunaì˜ Trial IDì™€ ì—°ë™í•˜ì—¬ ê° ì‹¤í–‰ì„ ê¸°ë¡\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}_{now_date}\"):\n",
    "        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì„¤ì • \n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "        SAMPLING_PERCENT = 50\n",
    "        \n",
    "        # 1ë‹¨ê³„ì™€ 2ë‹¨ê³„ì˜ ì—í­ ìˆ˜ë¥¼ ëª…í™•íˆ ë¶„ë¦¬í•˜ì—¬ ì •ì˜\n",
    "        HEAD_TUNE_EPOCHS = 15   # 1ë‹¨ê³„ì—ì„œ 'ë¨¸ë¦¬'ë§Œ í›ˆë ¨ì‹œí‚¬ ì—í­ ìˆ˜\n",
    "        FULL_TUNE_EPOCHS = 35   # 2ë‹¨ê³„ì—ì„œ ì „ì²´ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ì—í­ ìˆ˜\n",
    "        PATIENCE = 10           # ì¡°ê¸° ì¢…ë£Œ 'ì¸ë‚´ì‹¬'ë„ ì¶©ë¶„íˆ ëŠ˜ë ¤ì¤Œ\n",
    "        \n",
    "        # if model_name == \"wav2vec2\":\n",
    "        # model_id = \"inseong00/wav2vec2-large-xlsr-korean-autumn\"\n",
    "        \n",
    "        MODEL_NAME = trial.suggest_categorical(\"model_name\", [\"hubert-base\"])\n",
    "        # ì´ˆê¸° í•™ìŠµ ë¶ˆì•ˆì •ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ í•™ìŠµë¥  ë²”ìœ„ë¥¼ ì•½ê°„ ë‚®ì¶¤\n",
    "        EARLY_LR = trial.suggest_float(\"lr\", 1e-6, 2e-5, log=True)\n",
    "        #EARLY_LR = trial.suggest_float(\"lr\", 1e-5, 5e-5, log=True)\n",
    "        #LATE_LR = trial.suggest_float(\"lr\", 5e-6, 5e-5, log=True)\n",
    "        #EARLY_LR = trial.suggest_float(\"lr\", 1e-5, 1e-4, log=True)\n",
    "        BACKBONE_LR_SCALE = trial.suggest_float(\"backbone_lr_scale\", 0.05, 0.2, log=True)\n",
    "        BATCH_SIZE = trial.suggest_categorical(\"batch_size\", [4, 8])\n",
    "        ACCUMULATION_STEPS = trial.suggest_int(\"accumulation_steps\", 1, 4)\n",
    "        \n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_param(\"sampling_percent\", SAMPLING_PERCENT)\n",
    "        \n",
    "        \n",
    "        # ë°ì´í„° ì¤€ë¹„\n",
    "        DATA_DIR = Path(f\"./datasets/audio_sampling_sets/dataset_{SAMPLING_PERCENT}_percent\")\n",
    "        \n",
    "        # ì†Œìˆ˜/ë‹¤ìˆ˜ í´ë˜ìŠ¤ ì •ì˜ (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)\n",
    "        minority_classes = ['surprise', 'disgust', 'fear']\n",
    "        \n",
    "        # ì†Œìˆ˜ í´ë˜ìŠ¤ì— ì ìš©í•  ê°•ë ¥í•œ ì¦ê°• íŒŒì´í”„ë¼ì¸\n",
    "        strong_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "            A.TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            A.PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        ])\n",
    "\n",
    "        # ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— ì ìš©í•  ì•½í•œ ì¦ê°• íŒŒì´í”„ë¼ì¸ (ë˜ëŠ” A.Compose([])ë¡œ ë¹„ì›Œë‘˜ ìˆ˜ ìˆìŒ)\n",
    "        weak_augment = A.Compose([\n",
    "            A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.005, p=0.2),\n",
    "        ])\n",
    "\n",
    "        # ì°¨ë“± ì¦ê°• ì ìš©ê¸° ìƒì„±\n",
    "        train_augmenter = ClassAwareAugment(\n",
    "            minority_classes=minority_classes,\n",
    "            strong_augment=strong_augment,\n",
    "            weak_augment=weak_augment\n",
    "        )\n",
    "\n",
    "        # í›ˆë ¨ì…‹ì—ëŠ” ì°¨ë“± ì¦ê°• ì ìš©, ê²€ì¦ì…‹ì—ëŠ” ë¯¸ì ìš©\n",
    "        train_dataset = AudioDataset(metadata_path=DATA_DIR / \"train.csv\", audio_dir=DATA_DIR / \"train\", transform=train_augmenter)\n",
    "        val_dataset = AudioDataset(metadata_path=DATA_DIR / \"val.csv\", audio_dir=DATA_DIR / \"val\", transform=None)\n",
    "        \n",
    "        \n",
    "        # ìƒˆë¡œìš´ EmotionFineTuningModelì„ ìƒì„±\n",
    "        model_id = f\"team-lucid/{MODEL_NAME}-korean\"\n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "        model = EmotionFineTuningModel(model_id, num_labels=len(train_dataset.classes)).to(DEVICE)\n",
    "    \n",
    "        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ë° ë°ì´í„°ë¡œë”\n",
    "        # í›ˆë ¨ ë°ì´í„°ì…‹ì˜ ë¼ë²¨ ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "        class_names = train_dataset.classes\n",
    "        labels = [train_dataset.class_to_idx[emotion] for emotion in train_dataset.df['emotion']]\n",
    "        \n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "        \n",
    "        print(f\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©: { {name: f'{w:.2f}' for name, w in zip(class_names, class_weights)} }\")\n",
    "        \n",
    "        # ë°ì´í„° ì½œë ˆì´í„° ë° ë¡œë”\n",
    "        data_collator = DataCollatorForAudio(feature_extractor=feature_extractor, padding=True)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator, num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, num_workers=2, pin_memory=True)\n",
    "        \n",
    "        # ì†ì‹¤ í•¨ìˆ˜ì— í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        '''\n",
    "        # Optunaë¥¼ ì‚¬ìš©í•  ë• í•„ìš”ì—†ìŒ.\n",
    "        if trial.number == 0: \n",
    "            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
    "            CHECKPOINT_DIR = Path(\"./checkpoints\")\n",
    "            CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "            CHECKPOINT_PATH = CHECKPOINT_DIR / f'{MODEL_NAME}_{SAMPLING_PERCENT}_percent_best.pth'\n",
    "            start_epoch = 0\n",
    "            \n",
    "            if CHECKPOINT_PATH.exists():\n",
    "                print(f\"ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {CHECKPOINT_PATH}\")\n",
    "                checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                start_epoch = checkpoint['epoch'] + 1\n",
    "                print(f\"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ! {start_epoch} ì—í­ë¶€í„° í›ˆë ¨ì„ ì¬ê°œí•©ë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "        '''\n",
    "        # =================================================================\n",
    "        # === 1ë‹¨ê³„: ì»¤ìŠ¤í…€ í—¤ë“œ í›ˆë ¨ ===\n",
    "        # =================================================================\n",
    "        print(f\"\\n--- Trial {trial.number}, íŒŒì¸íŠœë‹ 1ë‹¨ê³„ ì‹œì‘: ì»¤ìŠ¤í…€ í—¤ë“œ í›ˆë ¨ ---\")\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith(model.base_model_prefix):\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        head_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer_head = optim.AdamW(head_params, lr=EARLY_LR)\n",
    "        # 1ë‹¨ê³„ëŠ” ê°„ë‹¨í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©\n",
    "        scheduler_head = torch.optim.lr_scheduler.LinearLR(optimizer_head, start_factor=1.0, end_factor=0.1, total_iters=HEAD_TUNE_EPOCHS)\n",
    "        train_model(\n",
    "            model, train_loader, val_loader, criterion, optimizer_head, scheduler_head, DEVICE,\n",
    "            num_epochs=HEAD_TUNE_EPOCHS, patience=5, accumulation_steps=ACCUMULATION_STEPS\n",
    "        )\n",
    "        \n",
    "        # =================================================================\n",
    "        # === 2ë‹¨ê³„: ì „ì²´ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ===\n",
    "        # =================================================================\n",
    "        print(f\"\\n--- Trial {trial.number}, íŒŒì¸íŠœë‹ 2ë‹¨ê³„ ì‹œì‘: ì „ì²´ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ---\")\n",
    "        \n",
    "        # ë™ê²°í–ˆë˜ 'ëª¸í†µ' íŒŒë¼ë¯¸í„°ë¥¼ ëª¨ë‘ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ í•´ë™\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        # ì°¨ë“± í•™ìŠµë¥ ì„ ì ìš©í•œ ì „ì²´ ëª¨ë¸ìš© ì˜µí‹°ë§ˆì´ì € ìƒì„±\n",
    "        backbone_params = model.base_model.parameters()\n",
    "        classifier_params = model.classifier.parameters()\n",
    "        \n",
    "        optimizer_full = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': EARLY_LR * BACKBONE_LR_SCALE},\n",
    "            {'params': classifier_params, 'lr': EARLY_LR}\n",
    "        ])\n",
    "        \n",
    "        # Warmupì„ í¬í•¨í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±\n",
    "        num_training_steps = len(train_loader) * FULL_TUNE_EPOCHS\n",
    "        num_warmup_steps = int(num_training_steps * 0.1) # ì²« 10% ìŠ¤í… ë™ì•ˆ ì›Œë°ì—…\n",
    "        \n",
    "        scheduler_full = get_linear_schedule_with_warmup(\n",
    "            optimizer_full,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        #scheduler_full = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_full, T_max=FULL_TUNE_EPOCHS)\n",
    "        \n",
    "        best_model, best_metrics = train_model(\n",
    "            model, train_loader, val_loader, criterion, optimizer_full, scheduler_full, DEVICE,\n",
    "            num_epochs=FULL_TUNE_EPOCHS,\n",
    "            patience=PATIENCE, \n",
    "            start_epoch=0,\n",
    "            accumulation_steps=ACCUMULATION_STEPS\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        # í›ˆë ¨ëœ ëª¨ë¸ì€ MLflowì— ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥ (ì¶”í›„ì— ê²°ê³¼ê°€ ì¢‹ì•„ì§€ë©´ ì €ì¥)\n",
    "        if best_wts_model:\n",
    "            CHECKPOINT_DIR = Path(\"./checkpoints\")\n",
    "            CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "            BEST_MODEL_PATH = CHECKPOINT_DIR / f\"trial_{trial.number}_best_model.pth\"\n",
    "            \n",
    "            torch.save({'model_state_dict': best_wts_model.state_dict(),\n",
    "                     'optimizer_state_dict': optimizer_full.state_dict(),\n",
    "                     'scheduler_state_dict': scheduler_full.state_dict()}, BEST_MODEL_PATH)\n",
    "            \n",
    "            mlflow.log_artifact(BEST_MODEL_PATH, artifact_path=\"model\")\n",
    "        '''            \n",
    "        # --- 8. ê²°ê³¼ ê¸°ë¡ ---\n",
    "        if best_metrics:\n",
    "            REPORT_DIR = Path(\"./reports\")\n",
    "            REPORT_DIR.mkdir(exist_ok=True)\n",
    "            mlflow.log_metrics({\n",
    "                \"best_train_loss\": float(best_metrics['train_loss']),\n",
    "                \"best_train_accuracy\": float(best_metrics['train_accuracy']),\n",
    "                \"best_val_loss\": float(best_metrics['val_loss']),\n",
    "                \"best_val_accuracy\": float(best_metrics['val_accuracy']),\n",
    "                \"best_macro_f1\": float(best_metrics['macro_f1_score']),\n",
    "            })\n",
    "            REPORT_PATH = REPORT_DIR / f\"{MODEL_NAME}_{SAMPLING_PERCENT}_percent_report_trial_{trial.number}_{now_date}.json\"\n",
    "            with open(REPORT_PATH, 'w', encoding='utf-8') as f:\n",
    "                json.dump(best_metrics, f, ensure_ascii=False, indent=4)\n",
    "            mlflow.log_artifact(REPORT_PATH, artifact_path=\"reports\")\n",
    "\n",
    "        return float(best_metrics.get('val_accuracy', 0))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5003\")\n",
    "    mlflow.set_experiment(\"Audio Emotion Finetuning\")\n",
    "    \n",
    "    # ì—°êµ¬ ê¸°ë¡ì„ ì €ì¥í•  ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ê³¼ ì—°êµ¬ ì´ë¦„ì„ ì •ì˜\n",
    "    STUDY_NAME = \"audio-finetune-study-v1\" # ì—°êµ¬ì— ê³ ìœ í•œ ì´ë¦„ì„ ë¶€ì—¬\n",
    "    STORAGE_NAME = f\"sqlite:///{STUDY_NAME}.db\" # SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ë¡œ ì €ì¥\n",
    "    \n",
    "    # storageì™€ study_nameì„ ì§€ì •í•˜ê³ , load_if_exists=Trueë¡œ ì„¤ì •\n",
    "    # ê¸°ì¡´ ì—°êµ¬ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
    "    study = optuna.create_study(\n",
    "        study_name=STUDY_NAME,\n",
    "        storage=STORAGE_NAME,\n",
    "        direction=\"maximize\",\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=1) # në²ˆì˜ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜\n",
    "    \n",
    "    print(\"\\n--- Hyperparameter Optimization Finished ---\")\n",
    "    print(f\"Total trials in this study: {len(study.trials)}\")\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value (Best Val Accuracy): {trial.value}\")\n",
    "    print(f\"  Params: {trial.params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feellog-project (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
