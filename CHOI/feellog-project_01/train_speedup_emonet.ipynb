{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d0d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "데이터 준비 완료!\n",
      "훈련 데이터셋 크기: 17975\n",
      "클래스 수: 7 -> ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
      "사전 훈련된 EmoNet 가중치를 불러옵니다 (Fine-tuning)...\n",
      "체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\n",
      "'emonet' 모델, 손실 함수, 옵티마이저 준비 완료!\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 8.9192 Acc: 0.1406\n",
      "  [Batch 280/280] Train Loss: 1.5303 Acc: 0.4219\n",
      "Train Loss: 3.2357 Acc: 0.3947\n",
      "Val Loss: 1.3066 Acc: 0.5539\n",
      "\n",
      "  -> Val Loss 개선됨! (1.3066) 모델 저장.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.4220 Acc: 0.5000\n",
      "  [Batch 280/280] Train Loss: 1.2241 Acc: 0.5000\n",
      "Train Loss: 1.3133 Acc: 0.5164\n",
      "Val Loss: 1.0647 Acc: 0.6044\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0647) 모델 저장.\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.2056 Acc: 0.4844\n",
      "  [Batch 280/280] Train Loss: 1.1451 Acc: 0.5938\n",
      "Train Loss: 1.1931 Acc: 0.5530\n",
      "Val Loss: 1.0221 Acc: 0.6246\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0221) 모델 저장.\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.1917 Acc: 0.5625\n",
      "  [Batch 280/280] Train Loss: 1.1341 Acc: 0.5312\n",
      "Train Loss: 1.1355 Acc: 0.5717\n",
      "Val Loss: 0.9676 Acc: 0.6410\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9676) 모델 저장.\n",
      "Epoch 5/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.0757 Acc: 0.5469\n",
      "  [Batch 280/280] Train Loss: 0.9323 Acc: 0.6875\n",
      "Train Loss: 1.0823 Acc: 0.5935\n",
      "Val Loss: 0.9381 Acc: 0.6498\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9381) 모델 저장.\n",
      "Epoch 6/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.0500 Acc: 0.5781\n",
      "  [Batch 280/280] Train Loss: 0.9931 Acc: 0.6406\n",
      "Train Loss: 1.0472 Acc: 0.6040\n",
      "Val Loss: 0.9813 Acc: 0.6505\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 7/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9863 Acc: 0.6406\n",
      "  [Batch 280/280] Train Loss: 0.8914 Acc: 0.6406\n",
      "Train Loss: 1.0160 Acc: 0.6177\n",
      "Val Loss: 0.9925 Acc: 0.6412\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 8/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9585 Acc: 0.5938\n",
      "  [Batch 280/280] Train Loss: 1.0140 Acc: 0.5625\n",
      "Train Loss: 0.9469 Acc: 0.6498\n",
      "Val Loss: 0.8650 Acc: 0.6854\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8650) 모델 저장.\n",
      "Epoch 9/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.7586 Acc: 0.7031\n",
      "  [Batch 280/280] Train Loss: 0.9598 Acc: 0.6250\n",
      "Train Loss: 0.9201 Acc: 0.6557\n",
      "Val Loss: 0.8595 Acc: 0.6893\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8595) 모델 저장.\n",
      "Epoch 10/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.8965 Acc: 0.6875\n",
      "  [Batch 280/280] Train Loss: 1.0173 Acc: 0.6562\n",
      "Train Loss: 0.9034 Acc: 0.6595\n",
      "Val Loss: 0.8542 Acc: 0.6881\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8542) 모델 저장.\n",
      "Epoch 11/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.0062 Acc: 0.5781\n",
      "  [Batch 280/280] Train Loss: 0.9595 Acc: 0.6250\n",
      "Train Loss: 0.8955 Acc: 0.6646\n",
      "Val Loss: 0.8566 Acc: 0.6897\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 12/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9928 Acc: 0.6562\n",
      "  [Batch 280/280] Train Loss: 0.7821 Acc: 0.7344\n",
      "Train Loss: 0.8905 Acc: 0.6634\n",
      "Val Loss: 0.8557 Acc: 0.6902\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 13/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9743 Acc: 0.6094\n",
      "  [Batch 280/280] Train Loss: 1.0539 Acc: 0.5469\n",
      "Train Loss: 0.8850 Acc: 0.6693\n",
      "Val Loss: 0.8474 Acc: 0.6895\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8474) 모델 저장.\n",
      "Epoch 14/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.0198 Acc: 0.5938\n",
      "  [Batch 280/280] Train Loss: 0.7214 Acc: 0.7656\n",
      "Train Loss: 0.8752 Acc: 0.6724\n",
      "Val Loss: 0.8586 Acc: 0.6940\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 15/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.6229 Acc: 0.8125\n",
      "  [Batch 280/280] Train Loss: 0.7578 Acc: 0.6875\n",
      "Train Loss: 0.8628 Acc: 0.6767\n",
      "Val Loss: 0.8485 Acc: 0.6911\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 16/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.7115 Acc: 0.7656\n",
      "  [Batch 280/280] Train Loss: 0.8067 Acc: 0.7656\n",
      "Train Loss: 0.8695 Acc: 0.6717\n",
      "Val Loss: 0.8539 Acc: 0.6936\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 17/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.7572 Acc: 0.7969\n",
      "  [Batch 280/280] Train Loss: 0.8334 Acc: 0.6562\n",
      "Train Loss: 0.8578 Acc: 0.6824\n",
      "Val Loss: 0.8448 Acc: 0.6920\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8448) 모델 저장.\n",
      "Epoch 18/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9389 Acc: 0.6250\n",
      "  [Batch 280/280] Train Loss: 0.8463 Acc: 0.6875\n",
      "Train Loss: 0.8616 Acc: 0.6795\n",
      "Val Loss: 0.8487 Acc: 0.6949\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 19/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9048 Acc: 0.6250\n",
      "  [Batch 280/280] Train Loss: 0.6814 Acc: 0.7188\n",
      "Train Loss: 0.8718 Acc: 0.6728\n",
      "Val Loss: 0.8453 Acc: 0.6929\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 20/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.8497 Acc: 0.6562\n",
      "  [Batch 280/280] Train Loss: 0.7589 Acc: 0.7344\n",
      "Train Loss: 0.8628 Acc: 0.6773\n",
      "Val Loss: 0.8473 Acc: 0.6934\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 21/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.7477 Acc: 0.7344\n",
      "  [Batch 280/280] Train Loss: 0.7578 Acc: 0.7031\n",
      "Train Loss: 0.8669 Acc: 0.6773\n",
      "Val Loss: 0.8445 Acc: 0.6915\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8445) 모델 저장.\n",
      "Epoch 22/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9498 Acc: 0.6406\n",
      "  [Batch 280/280] Train Loss: 0.7135 Acc: 0.7344\n",
      "Train Loss: 0.8608 Acc: 0.6771\n",
      "Val Loss: 0.8487 Acc: 0.6929\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 23/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.8706 Acc: 0.6875\n",
      "  [Batch 280/280] Train Loss: 0.9344 Acc: 0.5781\n",
      "Train Loss: 0.8671 Acc: 0.6780\n",
      "Val Loss: 0.8495 Acc: 0.6949\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 24/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.6057 Acc: 0.7969\n",
      "  [Batch 280/280] Train Loss: 0.9946 Acc: 0.6562\n",
      "Train Loss: 0.8603 Acc: 0.6812\n",
      "Val Loss: 0.8494 Acc: 0.6929\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 25/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.8075 Acc: 0.6719\n",
      "  [Batch 280/280] Train Loss: 0.9324 Acc: 0.6406\n",
      "Train Loss: 0.8543 Acc: 0.6819\n",
      "Val Loss: 0.8466 Acc: 0.6943\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 26/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 1.2311 Acc: 0.5938\n",
      "  [Batch 280/280] Train Loss: 0.7574 Acc: 0.7188\n",
      "Train Loss: 0.8584 Acc: 0.6795\n",
      "Val Loss: 0.8447 Acc: 0.6924\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/10\n",
      "Epoch 27/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9455 Acc: 0.6250\n",
      "  [Batch 280/280] Train Loss: 0.7520 Acc: 0.6562\n",
      "Train Loss: 0.8596 Acc: 0.6791\n",
      "Val Loss: 0.8467 Acc: 0.6945\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 6/10\n",
      "Epoch 28/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.6633 Acc: 0.7812\n",
      "  [Batch 280/280] Train Loss: 0.8723 Acc: 0.7031\n",
      "Train Loss: 0.8540 Acc: 0.6816\n",
      "Val Loss: 0.8469 Acc: 0.6938\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 7/10\n",
      "Epoch 29/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9412 Acc: 0.7188\n",
      "  [Batch 280/280] Train Loss: 1.1860 Acc: 0.5938\n",
      "Train Loss: 0.8642 Acc: 0.6776\n",
      "Val Loss: 0.8475 Acc: 0.6938\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 8/10\n",
      "Epoch 30/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.9685 Acc: 0.6406\n",
      "  [Batch 280/280] Train Loss: 0.7948 Acc: 0.7188\n",
      "Train Loss: 0.8645 Acc: 0.6789\n",
      "Val Loss: 0.8456 Acc: 0.6938\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 9/10\n",
      "Epoch 31/100\n",
      "----------\n",
      "  [Batch 20/280] Train Loss: 0.8218 Acc: 0.7188\n",
      "  [Batch 280/280] Train Loss: 0.8643 Acc: 0.6875\n",
      "Train Loss: 0.8632 Acc: 0.6773\n",
      "Val Loss: 0.8504 Acc: 0.6943\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 10/10\n",
      "\n",
      "Early stopping! 10 에폭 동안 성능 개선이 없었습니다.\n",
      "--------------------------------------------------\n",
      "Training complete in 71m 39s\n",
      "Saved Epoch: 21\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 0.8669\n",
      "Saved Train Acc: 0.6773\n",
      "Saved Val Loss: 0.8445\n",
      "Saved Val Acc: 0.6915\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 0.8540\n",
      "Best Train Acc: 0.6824\n",
      "Best Val Loss: 0.8445\n",
      "Best Val Acc: 0.6949\n",
      "--------------------------------------------------\n",
      "훈련된 모델 가중치가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # CUDA 성능 플래그 최적화\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # TF32 텐서 코어 사용을 허용하여 Ampere 아키텍처 이상 GPU에서 연산 속도 향상\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    \n",
    "    # 설정값 정의\n",
    "    # 장치 설정: 사용 가능한 경우 GPU(cuda)를, 그렇지 않으면 CPU를 사용\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    DATA_DIR = Path(\"./datasets/KECV_5_percent_FaceCrop\")\n",
    "    # 사용하고자 하는 모델 하나만 남기고 다른 MODEL_NAME 앞에 # 붙여서 주석처리\n",
    "    #MODEL_NAME = 'resnet18'             #철원\n",
    "    #MODEL_NAME = 'resnet50' \n",
    "    #MODEL_NAME = 'mobilenet_v3_small'  #승현님\n",
    "    #MODEL_NAME = 'shufflenet_v2'       #철원\n",
    "    #MODEL_NAME = 'efficientnet_v2_s'   #규진님\n",
    "    #MODEL_NAME = 'squeezenet'          #승희님\n",
    "    #MODEL_NAME = 'emotionnet'           # 감정 인식 전용 모델\n",
    "    MODEL_NAME = 'emonet'               # 경량화된 감정 인식 모델\n",
    "\n",
    "    NUM_CLASSES = 7  # 데이터셋의 클래스 수에 맞게 조정해야 합니다. ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
    "    BATCH_SIZE = 64  # 배치 크기를 늘려 GPU 메모리 사용 최적화\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 10 # 10번 연속 성능 개선이 없으면 조기 종료\n",
    "    STEPS_PER_EPOCH = None # 빠른 테스트를 위해 에폭당 배치 수를 제한하려면 숫자로 변경 (예: 100)\n",
    "    train_transform = None\n",
    "    val_transform = None\n",
    "    \n",
    "    if MODEL_NAME == 'emotionnet':\n",
    "        # 48x48 크기, 흑백(Grayscale), 정규화\n",
    "        # RandomResizedCrop + TrivialAugmentWide (강력한 데이터 증강 방법)\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((48, 48)),\n",
    "            # 원본 이미지의 80% ~ 100% 사이를 무작위로 잘라 48x48 크기로 만듦\n",
    "            transforms.RandomResizedCrop(size=48, scale=(0.8, 1.0)),\n",
    "            # 잘라낸 이미지에 최적의 증강 정책을 자동으로 적용\n",
    "            transforms.TrivialAugmentWide(),\n",
    "            # 흑백으로 변환\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지 정규화\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((48, 48)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지는 채널이 1개\n",
    "        ])\n",
    "\n",
    "    elif MODEL_NAME == 'emonet':\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((224, 224)),\n",
    "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((224, 224)),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    # 훈련용과 검증용 데이터셋을 각각 생성.\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # DataLoader I/O 튜닝\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        # CPU 코어를 최대한 활용하여 데이터를 미리 GPU 메모리로 올리는 작업을 병렬 처리\n",
    "        num_workers=min(8, os.cpu_count()), \n",
    "        pin_memory=True, # GPU로의 데이터 전송 속도 향상\n",
    "        persistent_workers=True, # 워커 프로세스를 계속 유지하여 오버헤드 감소\n",
    "        prefetch_factor=2, # 각 워커가 미리 로드할 배치 수\n",
    "        drop_last=True # 마지막 배치가 배치 사이즈보다 작을 경우 버려서 연산 일관성 유지\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=min(8, os.cpu_count()),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    \n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    # 모델을 지정된 장치로 이동\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        weight_decay=1e-4, #과적합 방지를 위한 정규화 기법(Weight Decay), 학습을 방해함으로서 과적합 방지.\n",
    "        lr=LEARNING_RATE \n",
    "        ) \n",
    "    START_EPOCH = 0\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.1)   # 7 에폭마다 학습률을 0.1배로 감소\n",
    "\n",
    "    CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_trained.pth'\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"체크포인트를 불러옵니다...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint['epoch'] + 1 # 다음 에폭부터 시작\n",
    "        print(f\"체크포인트 로드 완료! {START_EPOCH} 에폭부터 훈련을 재개합니다.\")\n",
    "    else:\n",
    "        print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "\n",
    "    # 모델 훈련 시작\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(model, \n",
    "                                train_loader, \n",
    "                                val_loader, \n",
    "                                criterion, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                DEVICE, \n",
    "                                num_epochs=NUM_EPOCHS,\n",
    "                                start_epoch=START_EPOCH,\n",
    "                                patience=EARLY_STOPPING_PATIENCE,\n",
    "                                steps_per_epoch=STEPS_PER_EPOCH\n",
    "                                )\n",
    "\n",
    "    # 훈련된 모델 저장 (옵션)\n",
    "    torch.save(trained_model.state_dict(), f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_trained.pth')\n",
    "    print(\"훈련된 모델 가중치가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15aedbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "데이터 준비 완료!\n",
      "훈련 데이터셋 크기: 32407\n",
      "클래스 수: 7 -> ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
      "사전 훈련된 EmoNet 가중치를 불러옵니다 (Fine-tuning)...\n",
      "체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\n",
      "'emonet' 모델, 손실 함수, 옵티마이저 준비 완료!\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 9.0024 Acc: 0.1875\n",
      "  [Batch 506/506] Train Loss: 1.3458 Acc: 0.4219\n",
      "Train Loss: 2.4183 Acc: 0.4340\n",
      "Val Loss: 1.1664 Acc: 0.5760\n",
      "\n",
      "  -> Val Loss 개선됨! (1.1664) 모델 저장.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 1.1362 Acc: 0.6094\n",
      "  [Batch 506/506] Train Loss: 1.0247 Acc: 0.5781\n",
      "Train Loss: 1.2104 Acc: 0.5411\n",
      "Val Loss: 1.1272 Acc: 0.5760\n",
      "\n",
      "  -> Val Loss 개선됨! (1.1272) 모델 저장.\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 1.2393 Acc: 0.4688\n",
      "  [Batch 506/506] Train Loss: 0.9746 Acc: 0.6250\n",
      "Train Loss: 1.1195 Acc: 0.5765\n",
      "Val Loss: 1.0920 Acc: 0.6045\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0920) 모델 저장.\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.9256 Acc: 0.6562\n",
      "  [Batch 506/506] Train Loss: 0.9048 Acc: 0.6250\n",
      "Train Loss: 1.0695 Acc: 0.5945\n",
      "Val Loss: 1.0198 Acc: 0.6217\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0198) 모델 저장.\n",
      "Epoch 5/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.9546 Acc: 0.6250\n",
      "  [Batch 506/506] Train Loss: 0.9119 Acc: 0.6719\n",
      "Train Loss: 1.0412 Acc: 0.6077\n",
      "Val Loss: 0.9657 Acc: 0.6373\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9657) 모델 저장.\n",
      "Epoch 6/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.8398 Acc: 0.7188\n",
      "  [Batch 506/506] Train Loss: 1.2755 Acc: 0.5156\n",
      "Train Loss: 1.0117 Acc: 0.6175\n",
      "Val Loss: 0.9020 Acc: 0.6614\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9020) 모델 저장.\n",
      "Epoch 7/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 1.0206 Acc: 0.5469\n",
      "  [Batch 506/506] Train Loss: 1.0278 Acc: 0.5469\n",
      "Train Loss: 0.9944 Acc: 0.6219\n",
      "Val Loss: 0.9489 Acc: 0.6417\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 8/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.9569 Acc: 0.6094\n",
      "  [Batch 506/506] Train Loss: 0.9747 Acc: 0.6719\n",
      "Train Loss: 0.9171 Acc: 0.6540\n",
      "Val Loss: 0.8479 Acc: 0.6861\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8479) 모델 저장.\n",
      "Epoch 9/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.9875 Acc: 0.6719\n",
      "  [Batch 506/506] Train Loss: 1.0531 Acc: 0.5469\n",
      "Train Loss: 0.8919 Acc: 0.6652\n",
      "Val Loss: 0.8379 Acc: 0.6886\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8379) 모델 저장.\n",
      "Epoch 10/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.8103 Acc: 0.7031\n",
      "  [Batch 506/506] Train Loss: 0.8365 Acc: 0.6406\n",
      "Train Loss: 0.8719 Acc: 0.6747\n",
      "Val Loss: 0.8328 Acc: 0.6951\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8328) 모델 저장.\n",
      "Epoch 11/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.6853 Acc: 0.7031\n",
      "  [Batch 506/506] Train Loss: 0.9344 Acc: 0.6406\n",
      "Train Loss: 0.8611 Acc: 0.6751\n",
      "Val Loss: 0.8316 Acc: 0.6957\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8316) 모델 저장.\n",
      "Epoch 12/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.8988 Acc: 0.6562\n",
      "  [Batch 506/506] Train Loss: 0.7338 Acc: 0.7188\n",
      "Train Loss: 0.8512 Acc: 0.6799\n",
      "Val Loss: 0.8297 Acc: 0.6941\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8297) 모델 저장.\n",
      "Epoch 13/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.9527 Acc: 0.6562\n",
      "  [Batch 506/506] Train Loss: 0.7065 Acc: 0.7188\n",
      "Train Loss: 0.8456 Acc: 0.6825\n",
      "Val Loss: 0.8295 Acc: 0.6980\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8295) 모델 저장.\n",
      "Epoch 14/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.9018 Acc: 0.7031\n",
      "  [Batch 506/506] Train Loss: 0.8515 Acc: 0.7188\n",
      "Train Loss: 0.8347 Acc: 0.6885\n",
      "Val Loss: 0.8279 Acc: 0.6970\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8279) 모델 저장.\n",
      "Epoch 15/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.7228 Acc: 0.7031\n",
      "  [Batch 506/506] Train Loss: 0.8278 Acc: 0.7500\n",
      "Train Loss: 0.8265 Acc: 0.6910\n",
      "Val Loss: 0.8246 Acc: 0.7008\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8246) 모델 저장.\n",
      "Epoch 16/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.8052 Acc: 0.6875\n",
      "  [Batch 506/506] Train Loss: 0.8036 Acc: 0.6875\n",
      "Train Loss: 0.8205 Acc: 0.6902\n",
      "Val Loss: 0.8202 Acc: 0.7000\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8202) 모델 저장.\n",
      "Epoch 17/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.8391 Acc: 0.6406\n",
      "  [Batch 506/506] Train Loss: 0.7645 Acc: 0.7031\n",
      "Train Loss: 0.8237 Acc: 0.6889\n",
      "Val Loss: 0.8219 Acc: 0.6975\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 18/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.6976 Acc: 0.7656\n",
      "  [Batch 506/506] Train Loss: 0.6376 Acc: 0.7188\n",
      "Train Loss: 0.8155 Acc: 0.6936\n",
      "Val Loss: 0.8279 Acc: 0.6987\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 19/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.7423 Acc: 0.7188\n",
      "  [Batch 506/506] Train Loss: 0.8650 Acc: 0.6562\n",
      "Train Loss: 0.8210 Acc: 0.6887\n",
      "Val Loss: 0.8233 Acc: 0.7015\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 20/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.7534 Acc: 0.6875\n",
      "  [Batch 506/506] Train Loss: 0.6438 Acc: 0.7656\n",
      "Train Loss: 0.8169 Acc: 0.6919\n",
      "Val Loss: 0.8272 Acc: 0.6970\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 21/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 1.1222 Acc: 0.5781\n",
      "  [Batch 506/506] Train Loss: 0.7909 Acc: 0.7344\n",
      "Train Loss: 0.8168 Acc: 0.6915\n",
      "Val Loss: 0.8223 Acc: 0.6983\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/10\n",
      "Epoch 22/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.9211 Acc: 0.6719\n",
      "  [Batch 506/506] Train Loss: 0.6986 Acc: 0.7188\n",
      "Train Loss: 0.8116 Acc: 0.6935\n",
      "Val Loss: 0.8214 Acc: 0.7002\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 6/10\n",
      "Epoch 23/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.7625 Acc: 0.7656\n",
      "  [Batch 506/506] Train Loss: 0.9274 Acc: 0.5938\n",
      "Train Loss: 0.8133 Acc: 0.6922\n",
      "Val Loss: 0.8205 Acc: 0.6992\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 7/10\n",
      "Epoch 24/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.8354 Acc: 0.6875\n",
      "  [Batch 506/506] Train Loss: 0.7124 Acc: 0.7188\n",
      "Train Loss: 0.8100 Acc: 0.6940\n",
      "Val Loss: 0.8213 Acc: 0.7012\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 8/10\n",
      "Epoch 25/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.5848 Acc: 0.7500\n",
      "  [Batch 506/506] Train Loss: 0.8471 Acc: 0.6406\n",
      "Train Loss: 0.8062 Acc: 0.6946\n",
      "Val Loss: 0.8223 Acc: 0.7002\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 9/10\n",
      "Epoch 26/100\n",
      "----------\n",
      "  [Batch 20/506] Train Loss: 0.8745 Acc: 0.6406\n",
      "  [Batch 506/506] Train Loss: 0.6863 Acc: 0.7500\n",
      "Train Loss: 0.8073 Acc: 0.6949\n",
      "Val Loss: 0.8213 Acc: 0.6997\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 10/10\n",
      "\n",
      "Early stopping! 10 에폭 동안 성능 개선이 없었습니다.\n",
      "--------------------------------------------------\n",
      "Training complete in 110m 37s\n",
      "Saved Epoch: 16\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 0.8205\n",
      "Saved Train Acc: 0.6902\n",
      "Saved Val Loss: 0.8202\n",
      "Saved Val Acc: 0.7000\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 0.8062\n",
      "Best Train Acc: 0.6946\n",
      "Best Val Loss: 0.8202\n",
      "Best Val Acc: 0.7015\n",
      "--------------------------------------------------\n",
      "훈련된 모델 가중치가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # CUDA 성능 플래그 최적화\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # TF32 텐서 코어 사용을 허용하여 Ampere 아키텍처 이상 GPU에서 연산 속도 향상\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    \n",
    "    # 설정값 정의\n",
    "    # 장치 설정: 사용 가능한 경우 GPU(cuda)를, 그렇지 않으면 CPU를 사용\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    sampling_percent = 10\n",
    "    DATA_DIR = Path(f\"./datasets/KECV_{sampling_percent}_percent_FaceCrop\")\n",
    "    # 사용하고자 하는 모델 하나만 남기고 다른 MODEL_NAME 앞에 # 붙여서 주석처리\n",
    "    #MODEL_NAME = 'resnet18'             #철원\n",
    "    #MODEL_NAME = 'resnet50' \n",
    "    #MODEL_NAME = 'mobilenet_v3_small'  #승현님\n",
    "    #MODEL_NAME = 'shufflenet_v2'       #철원\n",
    "    #MODEL_NAME = 'efficientnet_v2_s'   #규진님\n",
    "    #MODEL_NAME = 'squeezenet'          #승희님\n",
    "    #MODEL_NAME = 'emotionnet'           # 감정 인식 전용 모델\n",
    "    MODEL_NAME = 'emonet'               # 경량화된 감정 인식 모델\n",
    "\n",
    "    NUM_CLASSES = 7  # 데이터셋의 클래스 수에 맞게 조정해야 합니다. ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
    "    BATCH_SIZE = 64  # 배치 크기를 늘려 GPU 메모리 사용 최적화\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 10 # 10번 연속 성능 개선이 없으면 조기 종료\n",
    "    STEPS_PER_EPOCH = None # 빠른 테스트를 위해 에폭당 배치 수를 제한하려면 숫자로 변경 (예: 100)\n",
    "    train_transform = None\n",
    "    val_transform = None\n",
    "    \n",
    "    if MODEL_NAME == 'emotionnet':\n",
    "        # 48x48 크기, 흑백(Grayscale), 정규화\n",
    "        # RandomResizedCrop + TrivialAugmentWide (강력한 데이터 증강 방법)\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((48, 48)),\n",
    "            # 원본 이미지의 80% ~ 100% 사이를 무작위로 잘라 48x48 크기로 만듦\n",
    "            transforms.RandomResizedCrop(size=48, scale=(0.8, 1.0)),\n",
    "            # 잘라낸 이미지에 최적의 증강 정책을 자동으로 적용\n",
    "            transforms.TrivialAugmentWide(),\n",
    "            # 흑백으로 변환\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지 정규화\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((48, 48)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지는 채널이 1개\n",
    "        ])\n",
    "\n",
    "    elif MODEL_NAME == 'emonet':\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((224, 224)),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    # 훈련용과 검증용 데이터셋을 각각 생성.\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # DataLoader I/O 튜닝\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        # CPU 코어를 최대한 활용하여 데이터를 미리 GPU 메모리로 올리는 작업을 병렬 처리\n",
    "        num_workers=min(8, os.cpu_count()), \n",
    "        pin_memory=True, # GPU로의 데이터 전송 속도 향상\n",
    "        persistent_workers=True, # 워커 프로세스를 계속 유지하여 오버헤드 감소\n",
    "        prefetch_factor=2, # 각 워커가 미리 로드할 배치 수\n",
    "        drop_last=True # 마지막 배치가 배치 사이즈보다 작을 경우 버려서 연산 일관성 유지\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=min(8, os.cpu_count()),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    \n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    # 모델을 지정된 장치로 이동\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        weight_decay=1e-4, #과적합 방지를 위한 정규화 기법(Weight Decay), 학습을 방해함으로서 과적합 방지.\n",
    "        lr=LEARNING_RATE \n",
    "        ) \n",
    "    START_EPOCH = 0\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.1)   # 7 에폭마다 학습률을 0.1배로 감소\n",
    "\n",
    "    CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth'\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"체크포인트를 불러옵니다...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint['epoch'] + 1 # 다음 에폭부터 시작\n",
    "        print(f\"체크포인트 로드 완료! {START_EPOCH} 에폭부터 훈련을 재개합니다.\")\n",
    "    else:\n",
    "        print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "        \n",
    "    #model = torch.compile(model)   # Windows 환경에서 에러 발생\n",
    "    #print(\"모델 컴파일 완료!\")\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "    \n",
    "    # 모델 훈련 시작\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(model, \n",
    "                                train_loader, \n",
    "                                val_loader, \n",
    "                                criterion, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                DEVICE, \n",
    "                                num_epochs=NUM_EPOCHS,\n",
    "                                start_epoch=START_EPOCH,\n",
    "                                patience=EARLY_STOPPING_PATIENCE,\n",
    "                                steps_per_epoch=STEPS_PER_EPOCH\n",
    "                                )\n",
    "\n",
    "    # 훈련된 모델 저장 (옵션)\n",
    "    torch.save(trained_model.state_dict(), f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth')\n",
    "    print(\"훈련된 모델 가중치가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3d08d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "데이터 준비 완료!\n",
      "훈련 데이터셋 크기: 97313\n",
      "클래스 수: 7 -> ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
      "사전 훈련된 EmoNet 가중치를 불러옵니다 (Fine-tuning)...\n",
      "체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\n",
      "'emonet' 모델, 손실 함수, 옵티마이저 준비 완료!\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 9.4913 Acc: 0.1719\n",
      "  [Batch 1520/1520] Train Loss: 0.9691 Acc: 0.6094\n",
      "Train Loss: 1.6004 Acc: 0.5138\n",
      "Val Loss: 0.9596 Acc: 0.6376\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9596) 모델 저장.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 1.0442 Acc: 0.6562\n",
      "  [Batch 1520/1520] Train Loss: 0.9538 Acc: 0.6562\n",
      "Train Loss: 1.0715 Acc: 0.5957\n",
      "Val Loss: 0.9830 Acc: 0.6267\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.9631 Acc: 0.6250\n",
      "  [Batch 1520/1520] Train Loss: 1.0499 Acc: 0.6406\n",
      "Train Loss: 1.0107 Acc: 0.6183\n",
      "Val Loss: 0.9404 Acc: 0.6463\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9404) 모델 저장.\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.9370 Acc: 0.6250\n",
      "  [Batch 1520/1520] Train Loss: 0.8340 Acc: 0.7188\n",
      "Train Loss: 0.9766 Acc: 0.6321\n",
      "Val Loss: 0.8876 Acc: 0.6685\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8876) 모델 저장.\n",
      "Epoch 5/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.9602 Acc: 0.6250\n",
      "  [Batch 1520/1520] Train Loss: 0.9754 Acc: 0.6250\n",
      "Train Loss: 0.9565 Acc: 0.6401\n",
      "Val Loss: 0.8783 Acc: 0.6702\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8783) 모델 저장.\n",
      "Epoch 6/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 1.0346 Acc: 0.6250\n",
      "  [Batch 1520/1520] Train Loss: 0.8921 Acc: 0.6875\n",
      "Train Loss: 0.9380 Acc: 0.6484\n",
      "Val Loss: 0.8698 Acc: 0.6759\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8698) 모델 저장.\n",
      "Epoch 7/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.9611 Acc: 0.7031\n",
      "  [Batch 1520/1520] Train Loss: 0.9120 Acc: 0.6562\n",
      "Train Loss: 0.9221 Acc: 0.6541\n",
      "Val Loss: 0.8396 Acc: 0.6858\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8396) 모델 저장.\n",
      "Epoch 8/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 1.0250 Acc: 0.5938\n",
      "  [Batch 1520/1520] Train Loss: 0.9442 Acc: 0.5938\n",
      "Train Loss: 0.8447 Acc: 0.6799\n",
      "Val Loss: 0.7451 Acc: 0.7184\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7451) 모델 저장.\n",
      "Epoch 9/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.6904 Acc: 0.7188\n",
      "  [Batch 1520/1520] Train Loss: 0.8877 Acc: 0.6406\n",
      "Train Loss: 0.8171 Acc: 0.6936\n",
      "Val Loss: 0.7363 Acc: 0.7221\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7363) 모델 저장.\n",
      "Epoch 10/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.9268 Acc: 0.6406\n",
      "  [Batch 1520/1520] Train Loss: 0.6742 Acc: 0.7812\n",
      "Train Loss: 0.8015 Acc: 0.7004\n",
      "Val Loss: 0.7324 Acc: 0.7239\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7324) 모델 저장.\n",
      "Epoch 11/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 1.0682 Acc: 0.5625\n",
      "  [Batch 1520/1520] Train Loss: 0.9049 Acc: 0.6562\n",
      "Train Loss: 0.7899 Acc: 0.7022\n",
      "Val Loss: 0.7222 Acc: 0.7267\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7222) 모델 저장.\n",
      "Epoch 12/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.5966 Acc: 0.8281\n",
      "  [Batch 1520/1520] Train Loss: 0.9967 Acc: 0.6250\n",
      "Train Loss: 0.7774 Acc: 0.7080\n",
      "Val Loss: 0.7206 Acc: 0.7298\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7206) 모델 저장.\n",
      "Epoch 13/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7347 Acc: 0.7031\n",
      "  [Batch 1520/1520] Train Loss: 0.6733 Acc: 0.8125\n",
      "Train Loss: 0.7689 Acc: 0.7112\n",
      "Val Loss: 0.7162 Acc: 0.7312\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7162) 모델 저장.\n",
      "Epoch 14/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.8206 Acc: 0.7188\n",
      "  [Batch 1520/1520] Train Loss: 0.8086 Acc: 0.6875\n",
      "Train Loss: 0.7606 Acc: 0.7141\n",
      "Val Loss: 0.7115 Acc: 0.7349\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7115) 모델 저장.\n",
      "Epoch 15/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.8561 Acc: 0.6094\n",
      "  [Batch 1520/1520] Train Loss: 0.6284 Acc: 0.8125\n",
      "Train Loss: 0.7501 Acc: 0.7187\n",
      "Val Loss: 0.7042 Acc: 0.7372\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7042) 모델 저장.\n",
      "Epoch 16/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.6715 Acc: 0.7500\n",
      "  [Batch 1520/1520] Train Loss: 0.5588 Acc: 0.8438\n",
      "Train Loss: 0.7437 Acc: 0.7216\n",
      "Val Loss: 0.7058 Acc: 0.7366\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 17/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7215 Acc: 0.7344\n",
      "  [Batch 1520/1520] Train Loss: 0.7239 Acc: 0.7031\n",
      "Train Loss: 0.7392 Acc: 0.7220\n",
      "Val Loss: 0.7031 Acc: 0.7372\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7031) 모델 저장.\n",
      "Epoch 18/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7465 Acc: 0.6562\n",
      "  [Batch 1520/1520] Train Loss: 0.7422 Acc: 0.7656\n",
      "Train Loss: 0.7368 Acc: 0.7239\n",
      "Val Loss: 0.7033 Acc: 0.7375\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 19/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.8450 Acc: 0.6562\n",
      "  [Batch 1520/1520] Train Loss: 0.5545 Acc: 0.8125\n",
      "Train Loss: 0.7353 Acc: 0.7242\n",
      "Val Loss: 0.7013 Acc: 0.7381\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7013) 모델 저장.\n",
      "Epoch 20/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.9986 Acc: 0.6562\n",
      "  [Batch 1520/1520] Train Loss: 0.5485 Acc: 0.7812\n",
      "Train Loss: 0.7351 Acc: 0.7229\n",
      "Val Loss: 0.7006 Acc: 0.7386\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7006) 모델 저장.\n",
      "Epoch 21/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7948 Acc: 0.7188\n",
      "  [Batch 1520/1520] Train Loss: 0.7521 Acc: 0.7188\n",
      "Train Loss: 0.7321 Acc: 0.7246\n",
      "Val Loss: 0.7012 Acc: 0.7386\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 22/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.6496 Acc: 0.8125\n",
      "  [Batch 1520/1520] Train Loss: 0.8191 Acc: 0.7344\n",
      "Train Loss: 0.7322 Acc: 0.7254\n",
      "Val Loss: 0.7009 Acc: 0.7386\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 23/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7082 Acc: 0.7344\n",
      "  [Batch 1520/1520] Train Loss: 0.8026 Acc: 0.6875\n",
      "Train Loss: 0.7299 Acc: 0.7271\n",
      "Val Loss: 0.6995 Acc: 0.7382\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6995) 모델 저장.\n",
      "Epoch 24/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7877 Acc: 0.7031\n",
      "  [Batch 1520/1520] Train Loss: 1.0810 Acc: 0.5938\n",
      "Train Loss: 0.7284 Acc: 0.7258\n",
      "Val Loss: 0.7009 Acc: 0.7387\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 25/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7019 Acc: 0.7031\n",
      "  [Batch 1520/1520] Train Loss: 0.6811 Acc: 0.7656\n",
      "Train Loss: 0.7312 Acc: 0.7258\n",
      "Val Loss: 0.7010 Acc: 0.7381\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 26/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7756 Acc: 0.7500\n",
      "  [Batch 1520/1520] Train Loss: 0.7968 Acc: 0.6562\n",
      "Train Loss: 0.7271 Acc: 0.7280\n",
      "Val Loss: 0.7001 Acc: 0.7385\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 27/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.6931 Acc: 0.7188\n",
      "  [Batch 1520/1520] Train Loss: 0.7288 Acc: 0.7344\n",
      "Train Loss: 0.7301 Acc: 0.7281\n",
      "Val Loss: 0.7006 Acc: 0.7384\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 28/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7854 Acc: 0.7656\n",
      "  [Batch 1520/1520] Train Loss: 0.7881 Acc: 0.6719\n",
      "Train Loss: 0.7309 Acc: 0.7249\n",
      "Val Loss: 0.7016 Acc: 0.7376\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/10\n",
      "Epoch 29/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.8226 Acc: 0.7656\n",
      "  [Batch 1520/1520] Train Loss: 0.6433 Acc: 0.7969\n",
      "Train Loss: 0.7291 Acc: 0.7263\n",
      "Val Loss: 0.6999 Acc: 0.7388\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 6/10\n",
      "Epoch 30/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.8490 Acc: 0.6875\n",
      "  [Batch 1520/1520] Train Loss: 0.9054 Acc: 0.7031\n",
      "Train Loss: 0.7277 Acc: 0.7284\n",
      "Val Loss: 0.7006 Acc: 0.7383\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 7/10\n",
      "Epoch 31/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.8026 Acc: 0.7188\n",
      "  [Batch 1520/1520] Train Loss: 0.7730 Acc: 0.7500\n",
      "Train Loss: 0.7258 Acc: 0.7272\n",
      "Val Loss: 0.7003 Acc: 0.7383\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 8/10\n",
      "Epoch 32/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7423 Acc: 0.7344\n",
      "  [Batch 1520/1520] Train Loss: 0.6886 Acc: 0.7969\n",
      "Train Loss: 0.7306 Acc: 0.7268\n",
      "Val Loss: 0.7000 Acc: 0.7388\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 9/10\n",
      "Epoch 33/100\n",
      "----------\n",
      "  [Batch 20/1520] Train Loss: 0.7674 Acc: 0.7031\n",
      "  [Batch 1520/1520] Train Loss: 0.7388 Acc: 0.6406\n",
      "Train Loss: 0.7279 Acc: 0.7268\n",
      "Val Loss: 0.7005 Acc: 0.7380\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 10/10\n",
      "\n",
      "Early stopping! 10 에폭 동안 성능 개선이 없었습니다.\n",
      "--------------------------------------------------\n",
      "Training complete in 274m 3s\n",
      "Saved Epoch: 23\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 0.7299\n",
      "Saved Train Acc: 0.7271\n",
      "Saved Val Loss: 0.6995\n",
      "Saved Val Acc: 0.7382\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 0.7258\n",
      "Best Train Acc: 0.7284\n",
      "Best Val Loss: 0.6995\n",
      "Best Val Acc: 0.7388\n",
      "--------------------------------------------------\n",
      "훈련된 모델 가중치가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # CUDA 성능 플래그 최적화\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # TF32 텐서 코어 사용을 허용하여 Ampere 아키텍처 이상 GPU에서 연산 속도 향상\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    \n",
    "    # 설정값 정의\n",
    "    # 장치 설정: 사용 가능한 경우 GPU(cuda)를, 그렇지 않으면 CPU를 사용\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    sampling_percent = 30\n",
    "    DATA_DIR = Path(f\"./datasets/KECV_{sampling_percent}_percent_FaceCrop\")\n",
    "    # 사용하고자 하는 모델 하나만 남기고 다른 MODEL_NAME 앞에 # 붙여서 주석처리\n",
    "    #MODEL_NAME = 'resnet18'             #철원\n",
    "    #MODEL_NAME = 'resnet50' \n",
    "    #MODEL_NAME = 'mobilenet_v3_small'  #승현님\n",
    "    #MODEL_NAME = 'shufflenet_v2'       #철원\n",
    "    #MODEL_NAME = 'efficientnet_v2_s'   #규진님\n",
    "    #MODEL_NAME = 'squeezenet'          #승희님\n",
    "    #MODEL_NAME = 'emotionnet'           # 감정 인식 전용 모델\n",
    "    MODEL_NAME = 'emonet'               # 경량화된 감정 인식 모델\n",
    "\n",
    "    NUM_CLASSES = 7  # 데이터셋의 클래스 수에 맞게 조정해야 합니다. ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
    "    BATCH_SIZE = 64  # 배치 크기를 늘려 GPU 메모리 사용 최적화\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 10 # 10번 연속 성능 개선이 없으면 조기 종료\n",
    "    STEPS_PER_EPOCH = None # 빠른 테스트를 위해 에폭당 배치 수를 제한하려면 숫자로 변경 (예: 100)\n",
    "    train_transform = None\n",
    "    val_transform = None\n",
    "    \n",
    "    if MODEL_NAME == 'emotionnet':\n",
    "        # 48x48 크기, 흑백(Grayscale), 정규화\n",
    "        # RandomResizedCrop + TrivialAugmentWide (강력한 데이터 증강 방법)\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((48, 48)),\n",
    "            # 원본 이미지의 80% ~ 100% 사이를 무작위로 잘라 48x48 크기로 만듦\n",
    "            transforms.RandomResizedCrop(size=48, scale=(0.8, 1.0)),\n",
    "            # 잘라낸 이미지에 최적의 증강 정책을 자동으로 적용\n",
    "            transforms.TrivialAugmentWide(),\n",
    "            # 흑백으로 변환\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지 정규화\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((48, 48)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지는 채널이 1개\n",
    "        ])\n",
    "\n",
    "    elif MODEL_NAME == 'emonet':\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((224, 224)),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    # 훈련용과 검증용 데이터셋을 각각 생성.\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # DataLoader I/O 튜닝\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        # CPU 코어를 최대한 활용하여 데이터를 미리 GPU 메모리로 올리는 작업을 병렬 처리\n",
    "        num_workers=min(8, os.cpu_count()), \n",
    "        pin_memory=True, # GPU로의 데이터 전송 속도 향상\n",
    "        persistent_workers=True, # 워커 프로세스를 계속 유지하여 오버헤드 감소\n",
    "        prefetch_factor=2, # 각 워커가 미리 로드할 배치 수\n",
    "        drop_last=True # 마지막 배치가 배치 사이즈보다 작을 경우 버려서 연산 일관성 유지\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=min(8, os.cpu_count()),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    \n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    # 모델을 지정된 장치로 이동\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        weight_decay=1e-4, #과적합 방지를 위한 정규화 기법(Weight Decay), 학습을 방해함으로서 과적합 방지.\n",
    "        lr=LEARNING_RATE \n",
    "        ) \n",
    "    START_EPOCH = 0\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.1)   # 7 에폭마다 학습률을 0.1배로 감소\n",
    "\n",
    "    CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth'\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"체크포인트를 불러옵니다...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint['epoch'] + 1 # 다음 에폭부터 시작\n",
    "        print(f\"체크포인트 로드 완료! {START_EPOCH} 에폭부터 훈련을 재개합니다.\")\n",
    "    else:\n",
    "        print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "        \n",
    "    #model = torch.compile(model)   # Windows 환경에서 에러 발생\n",
    "    #print(\"모델 컴파일 완료!\")\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "\n",
    "    # 모델 훈련 시작\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(model, \n",
    "                                train_loader, \n",
    "                                val_loader, \n",
    "                                criterion, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                DEVICE, \n",
    "                                num_epochs=NUM_EPOCHS,\n",
    "                                start_epoch=START_EPOCH,\n",
    "                                patience=EARLY_STOPPING_PATIENCE,\n",
    "                                steps_per_epoch=STEPS_PER_EPOCH\n",
    "                                )\n",
    "\n",
    "    # 훈련된 모델 저장 (옵션)\n",
    "    torch.save(trained_model.state_dict(), f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth')\n",
    "    print(\"훈련된 모델 가중치가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "데이터 준비 완료!\n",
      "훈련 데이터셋 크기: 162173\n",
      "클래스 수: 7 -> ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
      "사전 훈련된 EmoNet 가중치를 불러옵니다 (Fine-tuning)...\n",
      "체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\n",
      "'emonet' 모델, 손실 함수, 옵티마이저 준비 완료!\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Epoch 1/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 10.3376 Acc: 0.1406\n",
      "  [Batch 2533/2533] Train Loss: 0.9927 Acc: 0.5781\n",
      "Train Loss: 1.4008 Acc: 0.5413\n",
      "Val Loss: 0.9587 Acc: 0.6353\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9587) 모델 저장.\n",
      "Epoch 2/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.9834 Acc: 0.6562\n",
      "  [Batch 2533/2533] Train Loss: 0.8182 Acc: 0.6406\n",
      "Train Loss: 1.0165 Acc: 0.6161\n",
      "Val Loss: 0.8758 Acc: 0.6720\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8758) 모델 저장.\n",
      "Epoch 3/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 1.0060 Acc: 0.5625\n",
      "  [Batch 2533/2533] Train Loss: 0.9492 Acc: 0.6406\n",
      "Train Loss: 0.9683 Acc: 0.6350\n",
      "Val Loss: 0.8348 Acc: 0.6857\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8348) 모델 저장.\n",
      "Epoch 4/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 1.1009 Acc: 0.5469\n",
      "  [Batch 2533/2533] Train Loss: 0.9776 Acc: 0.6250\n",
      "Train Loss: 0.9413 Acc: 0.6466\n",
      "Val Loss: 0.9581 Acc: 0.6472\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 5/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.8320 Acc: 0.6562\n",
      "  [Batch 2533/2533] Train Loss: 1.0466 Acc: 0.5938\n",
      "Train Loss: 0.9204 Acc: 0.6553\n",
      "Val Loss: 0.8487 Acc: 0.6870\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 6/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 1.0082 Acc: 0.6094\n",
      "  [Batch 2533/2533] Train Loss: 0.8649 Acc: 0.6406\n",
      "Train Loss: 0.9077 Acc: 0.6590\n",
      "Val Loss: 0.8281 Acc: 0.6886\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8281) 모델 저장.\n",
      "Epoch 7/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.8700 Acc: 0.6719\n",
      "  [Batch 2533/2533] Train Loss: 0.7884 Acc: 0.7031\n",
      "Train Loss: 0.8976 Acc: 0.6619\n",
      "Val Loss: 0.8067 Acc: 0.6999\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8067) 모델 저장.\n",
      "Epoch 8/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.9149 Acc: 0.5781\n",
      "  [Batch 2533/2533] Train Loss: 0.7144 Acc: 0.6875\n",
      "Train Loss: 0.8150 Acc: 0.6947\n",
      "Val Loss: 0.7241 Acc: 0.7306\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7241) 모델 저장.\n",
      "Epoch 9/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7818 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.7161 Acc: 0.7500\n",
      "Train Loss: 0.7901 Acc: 0.7043\n",
      "Val Loss: 0.7089 Acc: 0.7348\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7089) 모델 저장.\n",
      "Epoch 10/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.8418 Acc: 0.7031\n",
      "  [Batch 2533/2533] Train Loss: 0.7149 Acc: 0.7344\n",
      "Train Loss: 0.7762 Acc: 0.7093\n",
      "Val Loss: 0.7018 Acc: 0.7391\n",
      "\n",
      "  -> Val Loss 개선됨! (0.7018) 모델 저장.\n",
      "Epoch 11/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.6869 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.7517 Acc: 0.7188\n",
      "Train Loss: 0.7621 Acc: 0.7142\n",
      "Val Loss: 0.6983 Acc: 0.7405\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6983) 모델 저장.\n",
      "Epoch 12/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.8281 Acc: 0.6875\n",
      "  [Batch 2533/2533] Train Loss: 0.8745 Acc: 0.6719\n",
      "Train Loss: 0.7535 Acc: 0.7184\n",
      "Val Loss: 0.6906 Acc: 0.7449\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6906) 모델 저장.\n",
      "Epoch 13/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7592 Acc: 0.6719\n",
      "  [Batch 2533/2533] Train Loss: 0.7556 Acc: 0.6562\n",
      "Train Loss: 0.7450 Acc: 0.7203\n",
      "Val Loss: 0.6948 Acc: 0.7438\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 14/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.9494 Acc: 0.6719\n",
      "  [Batch 2533/2533] Train Loss: 0.5061 Acc: 0.8594\n",
      "Train Loss: 0.7339 Acc: 0.7248\n",
      "Val Loss: 0.6822 Acc: 0.7453\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6822) 모델 저장.\n",
      "Epoch 15/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.9251 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.5274 Acc: 0.7969\n",
      "Train Loss: 0.7206 Acc: 0.7307\n",
      "Val Loss: 0.6767 Acc: 0.7498\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6767) 모델 저장.\n",
      "Epoch 16/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.4778 Acc: 0.8750\n",
      "  [Batch 2533/2533] Train Loss: 0.8485 Acc: 0.6719\n",
      "Train Loss: 0.7149 Acc: 0.7325\n",
      "Val Loss: 0.6753 Acc: 0.7504\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6753) 모델 저장.\n",
      "Epoch 17/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.5977 Acc: 0.7812\n",
      "  [Batch 2533/2533] Train Loss: 0.7988 Acc: 0.7031\n",
      "Train Loss: 0.7163 Acc: 0.7325\n",
      "Val Loss: 0.6755 Acc: 0.7509\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 18/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.6112 Acc: 0.7969\n",
      "  [Batch 2533/2533] Train Loss: 0.7408 Acc: 0.7812\n",
      "Train Loss: 0.7134 Acc: 0.7334\n",
      "Val Loss: 0.6738 Acc: 0.7508\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6738) 모델 저장.\n",
      "Epoch 19/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7903 Acc: 0.6875\n",
      "  [Batch 2533/2533] Train Loss: 0.5999 Acc: 0.7812\n",
      "Train Loss: 0.7126 Acc: 0.7325\n",
      "Val Loss: 0.6735 Acc: 0.7507\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6735) 모델 저장.\n",
      "Epoch 20/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.6854 Acc: 0.7500\n",
      "  [Batch 2533/2533] Train Loss: 0.7722 Acc: 0.7188\n",
      "Train Loss: 0.7100 Acc: 0.7349\n",
      "Val Loss: 0.6738 Acc: 0.7510\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 21/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7806 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.5837 Acc: 0.7188\n",
      "Train Loss: 0.7090 Acc: 0.7350\n",
      "Val Loss: 0.6735 Acc: 0.7514\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 22/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.5262 Acc: 0.8438\n",
      "  [Batch 2533/2533] Train Loss: 0.6500 Acc: 0.7812\n",
      "Train Loss: 0.7061 Acc: 0.7368\n",
      "Val Loss: 0.6729 Acc: 0.7509\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6729) 모델 저장.\n",
      "Epoch 23/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.8493 Acc: 0.6562\n",
      "  [Batch 2533/2533] Train Loss: 0.8234 Acc: 0.6875\n",
      "Train Loss: 0.7072 Acc: 0.7346\n",
      "Val Loss: 0.6731 Acc: 0.7510\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 24/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.5832 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.5280 Acc: 0.7969\n",
      "Train Loss: 0.7072 Acc: 0.7354\n",
      "Val Loss: 0.6738 Acc: 0.7503\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 25/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7767 Acc: 0.7188\n",
      "  [Batch 2533/2533] Train Loss: 0.6304 Acc: 0.7344\n",
      "Train Loss: 0.7055 Acc: 0.7366\n",
      "Val Loss: 0.6720 Acc: 0.7514\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6720) 모델 저장.\n",
      "Epoch 26/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.6950 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.5987 Acc: 0.7656\n",
      "Train Loss: 0.7038 Acc: 0.7379\n",
      "Val Loss: 0.6711 Acc: 0.7520\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6711) 모델 저장.\n",
      "Epoch 27/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.6781 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.6167 Acc: 0.7031\n",
      "Train Loss: 0.7068 Acc: 0.7360\n",
      "Val Loss: 0.6712 Acc: 0.7523\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 28/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.6743 Acc: 0.7656\n",
      "  [Batch 2533/2533] Train Loss: 0.6443 Acc: 0.7656\n",
      "Train Loss: 0.7068 Acc: 0.7358\n",
      "Val Loss: 0.6719 Acc: 0.7520\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 29/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.8404 Acc: 0.7031\n",
      "  [Batch 2533/2533] Train Loss: 0.9110 Acc: 0.6719\n",
      "Train Loss: 0.7060 Acc: 0.7366\n",
      "Val Loss: 0.6730 Acc: 0.7509\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 30/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7205 Acc: 0.7031\n",
      "  [Batch 2533/2533] Train Loss: 0.8205 Acc: 0.7188\n",
      "Train Loss: 0.7041 Acc: 0.7370\n",
      "Val Loss: 0.6713 Acc: 0.7517\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 31/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7232 Acc: 0.7500\n",
      "  [Batch 2533/2533] Train Loss: 0.8946 Acc: 0.6719\n",
      "Train Loss: 0.7026 Acc: 0.7371\n",
      "Val Loss: 0.6718 Acc: 0.7517\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/10\n",
      "Epoch 32/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.6064 Acc: 0.7188\n",
      "  [Batch 2533/2533] Train Loss: 0.7225 Acc: 0.7500\n",
      "Train Loss: 0.7056 Acc: 0.7357\n",
      "Val Loss: 0.6718 Acc: 0.7520\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 6/10\n",
      "Epoch 33/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.9466 Acc: 0.6719\n",
      "  [Batch 2533/2533] Train Loss: 0.5228 Acc: 0.8594\n",
      "Train Loss: 0.7038 Acc: 0.7382\n",
      "Val Loss: 0.6710 Acc: 0.7522\n",
      "\n",
      "  -> Val Loss 개선됨! (0.6710) 모델 저장.\n",
      "Epoch 34/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.9648 Acc: 0.6562\n",
      "  [Batch 2533/2533] Train Loss: 0.6909 Acc: 0.7656\n",
      "Train Loss: 0.7055 Acc: 0.7367\n",
      "Val Loss: 0.6721 Acc: 0.7527\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 35/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7349 Acc: 0.6875\n",
      "  [Batch 2533/2533] Train Loss: 0.7642 Acc: 0.7656\n",
      "Train Loss: 0.7054 Acc: 0.7358\n",
      "Val Loss: 0.6732 Acc: 0.7520\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 36/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.8440 Acc: 0.6562\n",
      "  [Batch 2533/2533] Train Loss: 0.8206 Acc: 0.6875\n",
      "Train Loss: 0.7051 Acc: 0.7368\n",
      "Val Loss: 0.6712 Acc: 0.7518\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 37/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7840 Acc: 0.7344\n",
      "  [Batch 2533/2533] Train Loss: 0.5393 Acc: 0.7969\n",
      "Train Loss: 0.7043 Acc: 0.7368\n",
      "Val Loss: 0.6719 Acc: 0.7514\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 38/100\n",
      "----------\n",
      "  [Batch 20/2533] Train Loss: 0.7042 Acc: 0.7344\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # CUDA 성능 플래그 최적화\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # TF32 텐서 코어 사용을 허용하여 Ampere 아키텍처 이상 GPU에서 연산 속도 향상\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    \n",
    "    # 설정값 정의\n",
    "    # 장치 설정: 사용 가능한 경우 GPU(cuda)를, 그렇지 않으면 CPU를 사용\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    sampling_percent = 50\n",
    "    DATA_DIR = Path(f\"./datasets/KECV_{sampling_percent}_percent_FaceCrop\")\n",
    "    # 사용하고자 하는 모델 하나만 남기고 다른 MODEL_NAME 앞에 # 붙여서 주석처리\n",
    "    #MODEL_NAME = 'resnet18'             #철원\n",
    "    #MODEL_NAME = 'resnet50' \n",
    "    #MODEL_NAME = 'mobilenet_v3_small'  #승현님\n",
    "    #MODEL_NAME = 'shufflenet_v2'       #철원\n",
    "    #MODEL_NAME = 'efficientnet_v2_s'   #규진님\n",
    "    #MODEL_NAME = 'squeezenet'          #승희님\n",
    "    #MODEL_NAME = 'emotionnet'           # 감정 인식 전용 모델\n",
    "    MODEL_NAME = 'emonet'               # 경량화된 감정 인식 모델\n",
    "\n",
    "    NUM_CLASSES = 7  # 데이터셋의 클래스 수에 맞게 조정해야 합니다. ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
    "    BATCH_SIZE = 64  # 배치 크기를 늘려 GPU 메모리 사용 최적화\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 10 # 10번 연속 성능 개선이 없으면 조기 종료\n",
    "    STEPS_PER_EPOCH = None # 빠른 테스트를 위해 에폭당 배치 수를 제한하려면 숫자로 변경 (예: 100)\n",
    "    train_transform = None\n",
    "    val_transform = None\n",
    "    \n",
    "    if MODEL_NAME == 'emotionnet':\n",
    "        # 48x48 크기, 흑백(Grayscale), 정규화\n",
    "        # RandomResizedCrop + TrivialAugmentWide (강력한 데이터 증강 방법)\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((48, 48)),\n",
    "            # 원본 이미지의 80% ~ 100% 사이를 무작위로 잘라 48x48 크기로 만듦\n",
    "            transforms.RandomResizedCrop(size=48, scale=(0.8, 1.0)),\n",
    "            # 잘라낸 이미지에 최적의 증강 정책을 자동으로 적용\n",
    "            transforms.TrivialAugmentWide(),\n",
    "            # 흑백으로 변환\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지 정규화\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((48, 48)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지는 채널이 1개\n",
    "        ])\n",
    "\n",
    "    elif MODEL_NAME == 'emonet':\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((224, 224)),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    # 훈련용과 검증용 데이터셋을 각각 생성.\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # DataLoader I/O 튜닝\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        # CPU 코어를 최대한 활용하여 데이터를 미리 GPU 메모리로 올리는 작업을 병렬 처리\n",
    "        num_workers=min(8, os.cpu_count()), \n",
    "        pin_memory=True, # GPU로의 데이터 전송 속도 향상\n",
    "        persistent_workers=True, # 워커 프로세스를 계속 유지하여 오버헤드 감소\n",
    "        prefetch_factor=2, # 각 워커가 미리 로드할 배치 수\n",
    "        drop_last=True # 마지막 배치가 배치 사이즈보다 작을 경우 버려서 연산 일관성 유지\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=min(8, os.cpu_count()),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    \n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    # 모델을 지정된 장치로 이동\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        weight_decay=1e-4, #과적합 방지를 위한 정규화 기법(Weight Decay), 학습을 방해함으로서 과적합 방지.\n",
    "        lr=LEARNING_RATE \n",
    "        ) \n",
    "    START_EPOCH = 0\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.1)   # 7 에폭마다 학습률을 0.1배로 감소\n",
    "\n",
    "    CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth'\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"체크포인트를 불러옵니다...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint['epoch'] + 1 # 다음 에폭부터 시작\n",
    "        print(f\"체크포인트 로드 완료! {START_EPOCH} 에폭부터 훈련을 재개합니다.\")\n",
    "    else:\n",
    "        print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "    \n",
    "    #model = torch.compile(model)   # Windows 환경에서 에러 발생\n",
    "    #print(\"모델 컴파일 완료!\")\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "\n",
    "    # 모델 훈련 시작\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(model, \n",
    "                                train_loader, \n",
    "                                val_loader, \n",
    "                                criterion, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                DEVICE, \n",
    "                                num_epochs=NUM_EPOCHS,\n",
    "                                start_epoch=START_EPOCH,\n",
    "                                patience=EARLY_STOPPING_PATIENCE,\n",
    "                                steps_per_epoch=STEPS_PER_EPOCH\n",
    "                                )\n",
    "\n",
    "    # 훈련된 모델 저장 (옵션)\n",
    "    torch.save(trained_model.state_dict(), f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth')\n",
    "    print(\"훈련된 모델 가중치가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # CUDA 성능 플래그 최적화\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # TF32 텐서 코어 사용을 허용하여 Ampere 아키텍처 이상 GPU에서 연산 속도 향상\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    \n",
    "    # 설정값 정의\n",
    "    # 장치 설정: 사용 가능한 경우 GPU(cuda)를, 그렇지 않으면 CPU를 사용\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    sampling_percent = 100\n",
    "    DATA_DIR = Path(f\"./datasets/KECV_{sampling_percent}_percent_FaceCrop\")\n",
    "    # 사용하고자 하는 모델 하나만 남기고 다른 MODEL_NAME 앞에 # 붙여서 주석처리\n",
    "    #MODEL_NAME = 'resnet18'             #철원\n",
    "    #MODEL_NAME = 'resnet50' \n",
    "    #MODEL_NAME = 'mobilenet_v3_small'  #승현님\n",
    "    #MODEL_NAME = 'shufflenet_v2'       #철원\n",
    "    #MODEL_NAME = 'efficientnet_v2_s'   #규진님\n",
    "    #MODEL_NAME = 'squeezenet'          #승희님\n",
    "    #MODEL_NAME = 'emotionnet'           # 감정 인식 전용 모델\n",
    "    MODEL_NAME = 'emonet'               # 경량화된 감정 인식 모델\n",
    "\n",
    "    NUM_CLASSES = 7  # 데이터셋의 클래스 수에 맞게 조정해야 합니다. ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
    "    BATCH_SIZE = 64  # 배치 크기를 늘려 GPU 메모리 사용 최적화\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 10 # 10번 연속 성능 개선이 없으면 조기 종료\n",
    "    STEPS_PER_EPOCH = None # 빠른 테스트를 위해 에폭당 배치 수를 제한하려면 숫자로 변경 (예: 100)\n",
    "    train_transform = None\n",
    "    val_transform = None\n",
    "    \n",
    "    if MODEL_NAME == 'emotionnet':\n",
    "        # 48x48 크기, 흑백(Grayscale), 정규화\n",
    "        # RandomResizedCrop + TrivialAugmentWide (강력한 데이터 증강 방법)\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((48, 48)),\n",
    "            # 원본 이미지의 80% ~ 100% 사이를 무작위로 잘라 48x48 크기로 만듦\n",
    "            transforms.RandomResizedCrop(size=48, scale=(0.8, 1.0)),\n",
    "            # 잘라낸 이미지에 최적의 증강 정책을 자동으로 적용\n",
    "            transforms.TrivialAugmentWide(),\n",
    "            # 흑백으로 변환\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지 정규화\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((48, 48)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지는 채널이 1개\n",
    "        ])\n",
    "\n",
    "    elif MODEL_NAME == 'emonet':\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((224, 224)),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    # 훈련용과 검증용 데이터셋을 각각 생성.\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # DataLoader I/O 튜닝\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        # CPU 코어를 최대한 활용하여 데이터를 미리 GPU 메모리로 올리는 작업을 병렬 처리\n",
    "        num_workers=min(8, os.cpu_count()), \n",
    "        pin_memory=True, # GPU로의 데이터 전송 속도 향상\n",
    "        persistent_workers=True, # 워커 프로세스를 계속 유지하여 오버헤드 감소\n",
    "        prefetch_factor=2, # 각 워커가 미리 로드할 배치 수\n",
    "        drop_last=True # 마지막 배치가 배치 사이즈보다 작을 경우 버려서 연산 일관성 유지\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=min(8, os.cpu_count()),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    \n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    # 모델을 지정된 장치로 이동\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        weight_decay=1e-4, #과적합 방지를 위한 정규화 기법(Weight Decay), 학습을 방해함으로서 과적합 방지.\n",
    "        lr=LEARNING_RATE \n",
    "        ) \n",
    "    START_EPOCH = 0\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.1)   # 7 에폭마다 학습률을 0.1배로 감소\n",
    "\n",
    "    CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth'\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"체크포인트를 불러옵니다...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint['epoch'] + 1 # 다음 에폭부터 시작\n",
    "        print(f\"체크포인트 로드 완료! {START_EPOCH} 에폭부터 훈련을 재개합니다.\")\n",
    "    else:\n",
    "        print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "    \n",
    "    #model = torch.compile(model)   # Windows 환경에서 에러 발생\n",
    "    #print(\"모델 컴파일 완료!\")\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "\n",
    "    # 모델 훈련 시작\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(model, \n",
    "                                train_loader, \n",
    "                                val_loader, \n",
    "                                criterion, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                DEVICE, \n",
    "                                num_epochs=NUM_EPOCHS,\n",
    "                                start_epoch=START_EPOCH,\n",
    "                                patience=EARLY_STOPPING_PATIENCE,\n",
    "                                steps_per_epoch=STEPS_PER_EPOCH\n",
    "                                )\n",
    "\n",
    "    # 훈련된 모델 저장 (옵션)\n",
    "    torch.save(trained_model.state_dict(), f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth')\n",
    "    print(\"훈련된 모델 가중치가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 양을 늘려도 성능이 특정 수준에서 다시 정체된다면, 파인튜닝 세분화를 적용하여 모델의 학습 효율을 극대화\n",
    "# 새로 학습시킬 파라미터와 미세 조정할 파라미터를 분리\n",
    "new_classifier_params = model.emo_fc_3.parameters()\n",
    "pretrained_params = [p for name, p in model.named_parameters() if 'emo_fc_3' not in name]\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': pretrained_params, 'lr': LEARNING_RATE * 0.1}, # 기존 부분은 10분의 1로 미세 조정\n",
    "    {'params': new_classifier_params, 'lr': LEARNING_RATE}      # 새 부분은 원래 학습률로 학습\n",
    "], weight_decay=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feellog-project (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
