## 🎯 오디오 전처리 파이프라인 (최종 정리)
매번 데이터 품질의 부족함이 발견될때마다 기능 도입 -> 오류 해결 -> 직접 듣기 를 반복하던 끝에 과도하게 시간이 할애, 결국 mvp 탈락

1. **파일 로드 (torchaudio)**
   - wav 파일을 로드 → 스테레오라면 **모노 다운믹스**
   - sr이 다르면 **리샘플링(target\_sr=16kHz)**
2. **품질 검사 (EDA 단계에서만)**
   - duration, snr\_proxy, clipping 등 기본적인 품질 지표 산출
   - 존재하지 않는 파일(drop) 처리
3. **정규화 (Normalization)**
   - **Loudness normalize (LUFS 기준)** → 전체 데이터의 체감 볼륨 맞추기 (예: -23 LUFS)
   - **Peak normalize** → clipping 방지
   - **RMS normalize** → 화자별 음량 편차 줄이기
4. **무음 구간 처리 (VAD/Trim)**
   - **Head-tail VAD**: 앞뒤 무음 제거 (`top_db=45` 기본)
   - (옵션) **2차 VAD**: trim 후에도 20초 이상인 경우만 더 타이트하게(`top_db=30`)
5. **EDA 체크포인트**
   - 많이 잘린 샘플(trim\_ratio 낮음) 확인
   - 여전히 긴 샘플(trim\_duration>20s) 확인
   - 필요시 일부 샘플 저장해서 들어보기
6. **세그먼트 분할 (Segment Split)**
   - 7초 단위로 잘라서 저장
   - 남은 구간이 3.5초 이상이면 패딩해서 보존, 3.5초 미만이면 버림
   - **패딩은 학습 시 어텐션 마스크로 처리**하므로 전처리 단계에서는 불필요
7. **최종 산출물**
   - segment wav 파일들 (ex. `wav_id__seg_001.wav`)
   - 대응되는 라벨 정보 포함한 **filtered\_df (메타 CSV)**

---

## ✅ 키포인트

- **Normalize → VAD → Segment** 이 3단계가 핵심
- Loudness normalize를 반드시 선행해서 **화자/발화 간 볼륨 차이를 줄임**
- VAD는 **head-tail만** → 말소리 중간은 유지 (부스럭/까톡 같은 peak는 일부 남을 수 있지만 학습에서 robustness로 커버)
- Segment는 \*\*고정 길이(7초)\*\*로 맞추고, 너무 짧은 건 드랍
