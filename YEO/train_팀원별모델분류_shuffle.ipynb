{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21c18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 다운로드 받고 모델이 제대로 작동하는지 확인하는 명령어입니다.\n",
    "# 가상환경이 활성화된 터미널에서 아래 명령어를 실행하세요.\n",
    "# python -m unittest tests/test_model.py\n",
    "#-------------------------\n",
    "# Ran 1 test in 8.179s\n",
    "# OK\n",
    "#-------------------------\n",
    "# 위와 같은 결과를 얻었다면 모델이 정상적으로 작동하는 것입니다.\n",
    "# 코드 중 담당하신 MODEL_NAME에 해당하는 주석(#)을 제거하고 실행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66595eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "데이터 준비 완료!\n",
      "훈련 데이터셋 크기: 17975\n",
      "클래스 수: 7 -> ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
      "'shufflenet_v2' 모델, 손실 함수, 옵티마이저 준비 완료!\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Epoch 1/100\n",
      "----------\n",
      "Train Loss: 1.2805 Acc: 0.5204\n",
      "Val Loss: 1.1180 Acc: 0.5883\n",
      "\n",
      "  -> Val Loss 개선됨! (1.1180) 모델 저장.\n",
      "Epoch 2/100\n",
      "----------\n",
      "Train Loss: 1.0074 Acc: 0.6240\n",
      "Val Loss: 1.1538 Acc: 0.5768\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 3/100\n",
      "----------\n",
      "Train Loss: 0.9340 Acc: 0.6576\n",
      "Val Loss: 1.0002 Acc: 0.6289\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0002) 모델 저장.\n",
      "Epoch 4/100\n",
      "----------\n",
      "Train Loss: 0.8932 Acc: 0.6679\n",
      "Val Loss: 0.9371 Acc: 0.6489\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9371) 모델 저장.\n",
      "Epoch 5/100\n",
      "----------\n",
      "Train Loss: 0.8503 Acc: 0.6823\n",
      "Val Loss: 0.9090 Acc: 0.6666\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9090) 모델 저장.\n",
      "Epoch 6/100\n",
      "----------\n",
      "Train Loss: 0.8216 Acc: 0.6933\n",
      "Val Loss: 0.8855 Acc: 0.6741\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8855) 모델 저장.\n",
      "Epoch 7/100\n",
      "----------\n",
      "Train Loss: 0.7857 Acc: 0.7075\n",
      "Val Loss: 0.9257 Acc: 0.6553\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 8/100\n",
      "----------\n",
      "Train Loss: 0.7581 Acc: 0.7169\n",
      "Val Loss: 0.9086 Acc: 0.6639\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 9/100\n",
      "----------\n",
      "Train Loss: 0.7383 Acc: 0.7226\n",
      "Val Loss: 0.8797 Acc: 0.6748\n",
      "\n",
      "  -> Val Loss 개선됨! (0.8797) 모델 저장.\n",
      "Epoch 10/100\n",
      "----------\n",
      "Train Loss: 0.6989 Acc: 0.7429\n",
      "Val Loss: 0.9653 Acc: 0.6589\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 11/100\n",
      "----------\n",
      "Train Loss: 0.6836 Acc: 0.7434\n",
      "Val Loss: 0.9189 Acc: 0.6777\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 12/100\n",
      "----------\n",
      "Train Loss: 0.6592 Acc: 0.7525\n",
      "Val Loss: 0.9123 Acc: 0.6723\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 13/100\n",
      "----------\n",
      "Train Loss: 0.6355 Acc: 0.7599\n",
      "Val Loss: 0.8993 Acc: 0.6856\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 14/100\n",
      "----------\n",
      "Train Loss: 0.6158 Acc: 0.7680\n",
      "Val Loss: 0.9676 Acc: 0.6707\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/10\n",
      "Epoch 15/100\n",
      "----------\n",
      "Train Loss: 0.5859 Acc: 0.7830\n",
      "Val Loss: 0.9361 Acc: 0.6793\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 6/10\n",
      "Epoch 16/100\n",
      "----------\n",
      "Train Loss: 0.5684 Acc: 0.7845\n",
      "Val Loss: 0.9768 Acc: 0.6716\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 7/10\n",
      "Epoch 17/100\n",
      "----------\n",
      "Train Loss: 0.5416 Acc: 0.7972\n",
      "Val Loss: 0.9701 Acc: 0.6732\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 8/10\n",
      "Epoch 18/100\n",
      "----------\n",
      "Train Loss: 0.5170 Acc: 0.8063\n",
      "Val Loss: 0.9950 Acc: 0.6727\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 9/10\n",
      "Epoch 19/100\n",
      "----------\n",
      "Train Loss: 0.5083 Acc: 0.8095\n",
      "Val Loss: 1.0553 Acc: 0.6759\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 10/10\n",
      "\n",
      "Early stopping! 10 에폭 동안 성능 개선이 없었습니다.\n",
      "Training complete in 37m 4s\n",
      "Best Val Loss: 0.8797\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 설정값 정의\n",
    "    # 장치 설정: 사용 가능한 경우 GPU(cuda)를, 그렇지 않으면 CPU를 사용\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    DATA_DIR = Path(\"./datasets/korean_emotion_complex_vision_5_percent_verified_processed\")\n",
    "    # 사용하고자 하는 모델 하나만 남기고 다른 MODEL_NAME 앞에 # 붙여서 주석처리\n",
    "    #MODEL_NAME = 'resnet18'             #철원\n",
    "    #MODEL_NAME = 'resnet50' \n",
    "    # MODEL_NAME = 'mobilenet_v3_small'  #승현님\n",
    "    MODEL_NAME = 'shufflenet_v2'       #철원\n",
    "    #MODEL_NAME = 'efficientnet_v2_s'   #규진님\n",
    "    #MODEL_NAME = 'squeezenet'          #승희님\n",
    "    \n",
    "    NUM_CLASSES = 7  # 데이터셋의 클래스 수에 맞게 조정해야 합니다. ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 10 # 10번 연속 성능 개선이 없으면 조기 종료\n",
    "    \n",
    "    # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # 50% 확률로 좌우 반전\n",
    "        transforms.RandomRotation(15),           # -15도 ~ 15도 사이로 랜덤 회전\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # 밝기, 대비, 채도 조절\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # 증강이 없는 검증/테스트용 Transform 정의\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # 각 데이터셋에 맞는 Transform 적용\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # 훈련용과 검증용 데이터셋을 각각 생성. \n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # 데이터로더를 각각 생성. (검증용은 섞을 필요가 없음)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    \n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    # 모델을 지정된 장치로 이동\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        #weight_decay=1e-4, #과적합 방지를 위한 가중치 감쇠를 넣었으나 오히려 학습에 방해가 되고 있음.\n",
    "        lr=LEARNING_RATE \n",
    "        ) \n",
    "\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "\n",
    "    # 모델 훈련 시작\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(model, \n",
    "                                train_loader, \n",
    "                                val_loader, \n",
    "                                criterion, \n",
    "                                optimizer, \n",
    "                                DEVICE, \n",
    "                                num_epochs=NUM_EPOCHS, \n",
    "                                patience=EARLY_STOPPING_PATIENCE)\n",
    "\n",
    "    # 훈련된 모델 저장 (옵션)\n",
    "    # torch.save(trained_model.state_dict(), f'{MODEL_NAME}_trained.pth')\n",
    "    # print(\"훈련된 모델 가중치가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff955ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feellog-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
