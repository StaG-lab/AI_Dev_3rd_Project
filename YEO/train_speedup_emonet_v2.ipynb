{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15aedbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "데이터 준비 완료!\n",
      "훈련 데이터셋 크기: 86974\n",
      "클래스 수: 7 -> ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
      "사전 훈련된 EmoNet 가중치를 불러옵니다 (Fine-tuning)...\n",
      "체크포인트를 불러옵니다...\n",
      "'emonet' 모델, 손실 함수, 옵티마이저 준비 완료!\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Epoch 1/1\n",
      "----------\n",
      "  [Batch 20/1358] Train Loss: 0.6620 Acc: 0.7656\n",
      "  [Batch 1358/1358] Train Loss: 0.7950 Acc: 0.6562\n",
      "Train Loss: 0.7311 Acc: 0.7459\n",
      "Val Loss: 0.5993 Acc: 0.7906\n",
      "\n",
      "  -> Val Loss 개선됨! (0.5993) 모델 저장.\n",
      "--------------------------------------------------\n",
      "Training complete in 10m 27s\n",
      "Saved Epoch: 1\n",
      "--------------------------------------------------\n",
      "Saved Train Loss: 0.7311\n",
      "Saved Train Acc: 0.7459\n",
      "Saved Val Loss: 0.5993\n",
      "Saved Val Acc: 0.7906\n",
      "--------------------------------------------------\n",
      "Best Train Loss: 0.7311\n",
      "Best Train Acc: 0.7459\n",
      "Best Val Loss: 0.5993\n",
      "Best Val Acc: 0.7906\n",
      "--------------------------------------------------\n",
      "훈련된 모델 가중치가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "from core.training.trainer import train_model\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import csv, json, shutil, time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _resolve_dataset_paths(ds):\n",
    "    \"\"\"\n",
    "    데이터셋 객체에서 원본 이미지 경로 리스트를 최대한 호환되게 추출.\n",
    "    가능한 필드 우선순위: paths > image_paths > img_paths > samples/imgs ([(path, cls), ...])\n",
    "    찾지 못하면 None 반환.\n",
    "    \"\"\"\n",
    "    if hasattr(ds, \"paths\"): return list(getattr(ds, \"paths\"))\n",
    "    if hasattr(ds, \"image_paths\"): return list(getattr(ds, \"image_paths\"))\n",
    "    if hasattr(ds, \"img_paths\"): return list(getattr(ds, \"img_paths\"))\n",
    "    if hasattr(ds, \"samples\"): return [p for p, _ in getattr(ds, \"samples\")]\n",
    "    if hasattr(ds, \"imgs\"): return [p for p, _ in getattr(ds, \"imgs\")]\n",
    "    return None\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_and_dump(model, val_loader, classes, out_dir: Path, device,\n",
    "                      save_miscls=True, max_miscls_per_pair=200):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = out_dir / \"val_predictions.csv\"\n",
    "    cm_path  = out_dir / \"confusion_matrix.npy\"\n",
    "    per_class_path = out_dir / \"per_class_acc.json\"\n",
    "    miscls_dir = out_dir / \"misclassified\"\n",
    "\n",
    "    # 경로 복사를 위해 검증 데이터셋 원본 경로 추출\n",
    "    val_paths = _resolve_dataset_paths(val_loader.dataset)\n",
    "    copy_ok = (val_paths is not None)\n",
    "\n",
    "    all_preds, all_labels, all_confs = [], [], []\n",
    "    writer = csv.writer(open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\"))\n",
    "    writer.writerow([\"index\",\"path\",\"true\",\"pred\",\"conf\",\"correct\"])\n",
    "\n",
    "    model.eval()\n",
    "    idx_base = 0\n",
    "    # 클래스별 오분류 저장 상한 관리 (t->p 쌍별)\n",
    "    pair_counter = {}\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        # EmoNet은 dict 출력, 그 외는 텐서 출력\n",
    "        out = model(inputs)\n",
    "        logits = out[\"expression\"] if isinstance(out, dict) and \"expression\" in out else out\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        confs, preds = probs.max(dim=1)\n",
    "\n",
    "        B = inputs.size(0)\n",
    "        for b in range(B):\n",
    "            i = idx_base + b\n",
    "            t = int(labels[b].item())\n",
    "            p = int(preds[b].item())\n",
    "            c = float(confs[b].item())\n",
    "            all_labels.append(t); all_preds.append(p); all_confs.append(c)\n",
    "            path = val_paths[i] if copy_ok and i < len(val_paths) else \"\"\n",
    "            writer.writerow([i, path, classes[t], classes[p], f\"{c:.4f}\", int(t==p)])\n",
    "\n",
    "            # 오분류 이미지 복사\n",
    "            if save_miscls and copy_ok and t != p:\n",
    "                pair = (t, p)\n",
    "                if pair_counter.get(pair, 0) < max_miscls_per_pair:\n",
    "                    subdir = miscls_dir / f\"{classes[t]}_as_{classes[p]}\"\n",
    "                    subdir.mkdir(parents=True, exist_ok=True)\n",
    "                    # 파일명: [idx]_true-{t}_pred-{p}_{conf}.원확장자\n",
    "                    src = Path(path)\n",
    "                    dst = subdir / f\"{i:06d}_true-{classes[t]}_pred-{classes[p]}_{c:.3f}{src.suffix}\"\n",
    "                    try:\n",
    "                        shutil.copy2(src, dst)\n",
    "                        pair_counter[pair] = pair_counter.get(pair, 0) + 1\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        idx_base += B\n",
    "\n",
    "    # 혼동행렬 / 클래스별 정확도 저장\n",
    "    num_classes = len(classes)\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    for t, p in zip(all_labels, all_preds):\n",
    "        cm[t, p] += 1\n",
    "    np.save(cm_path, cm)\n",
    "\n",
    "    per_class = {}\n",
    "    for k in range(num_classes):\n",
    "        support = int((np.array(all_labels) == k).sum())\n",
    "        correct = int(((np.array(all_labels) == k) & (np.array(all_preds) == k)).sum())\n",
    "        acc = (correct / support) if support > 0 else None\n",
    "        per_class[classes[k]] = {\"acc\": acc, \"support\": support}\n",
    "    with open(per_class_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(per_class, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    overall = (np.array(all_labels) == np.array(all_preds)).mean()\n",
    "    print(f\"[EVAL] Overall Acc: {overall:.4f} | CM -> {cm_path.name} | per-class -> {per_class_path.name} | CSV -> {csv_path.name}\")\n",
    "    if save_miscls and copy_ok:\n",
    "        print(f\"[EVAL] Misclassified samples saved to: {miscls_dir}\")\n",
    "    elif save_miscls and not copy_ok:\n",
    "        print(\"[EVAL] Dataset 경로를 찾지 못해 오분류 복사를 건너뜀(EmotionDataset에 paths/samples 필드가 필요).\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # CUDA 성능 플래그 최적화\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # TF32 텐서 코어 사용을 허용하여 Ampere 아키텍처 이상 GPU에서 연산 속도 향상\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    \n",
    "    # 설정값 정의\n",
    "    # 장치 설정: 사용 가능한 경우 GPU(cuda)를, 그렇지 않으면 CPU를 사용\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    sampling_percent = 30\n",
    "    DATA_DIR = Path(\"D:/ex/최종프로젝트/AI_Dev_3rd_Project/YEO/datasets/30_pp_si\")\n",
    "    # 사용하고자 하는 모델 하나만 남기고 다른 MODEL_NAME 앞에 # 붙여서 주석처리\n",
    "    #MODEL_NAME = 'resnet18'             #철원\n",
    "    #MODEL_NAME = 'resnet50' \n",
    "    #MODEL_NAME = 'mobilenet_v3_small'  #승현님\n",
    "    #MODEL_NAME = 'shufflenet_v2'       #철원\n",
    "    #MODEL_NAME = 'efficientnet_v2_s'   #규진님\n",
    "    #MODEL_NAME = 'squeezenet'          #승희님\n",
    "    #MODEL_NAME = 'emotionnet'           # 감정 인식 전용 모델\n",
    "    MODEL_NAME = 'emonet'               # 경량화된 감정 인식 모델\n",
    "\n",
    "    NUM_CLASSES = 7  # 데이터셋의 클래스 수에 맞게 조정해야 합니다. ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
    "    BATCH_SIZE = 64  # 배치 크기를 늘려 GPU 메모리 사용 최적화\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 1\n",
    "    EARLY_STOPPING_PATIENCE = 10 # 10번 연속 성능 개선이 없으면 조기 종료\n",
    "    STEPS_PER_EPOCH = None # 빠른 테스트를 위해 에폭당 배치 수를 제한하려면 숫자로 변경 (예: 100)\n",
    "    train_transform = None\n",
    "    val_transform = None\n",
    "    \n",
    "    if MODEL_NAME == 'emotionnet':\n",
    "        # 48x48 크기, 흑백(Grayscale), 정규화\n",
    "        # RandomResizedCrop + TrivialAugmentWide (강력한 데이터 증강 방법)\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((48, 48)),\n",
    "            # 원본 이미지의 80% ~ 100% 사이를 무작위로 잘라 48x48 크기로 만듦\n",
    "            transforms.RandomResizedCrop(size=48, scale=(0.8, 1.0)),\n",
    "            # 잘라낸 이미지에 최적의 증강 정책을 자동으로 적용\n",
    "            transforms.TrivialAugmentWide(),\n",
    "            # 흑백으로 변환\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지 정규화\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((48, 48)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) # 흑백 이미지는 채널이 1개\n",
    "        ])\n",
    "\n",
    "    elif MODEL_NAME == 'emonet':\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "        # 데이터 증강을 포함한 훈련용 Transform 정의\n",
    "        train_transform = transforms.Compose([\n",
    "            #transforms.Resize((224, 224)),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "            transforms.TrivialAugmentWide(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        # 증강이 없는 검증/테스트용 Transform 정의\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    \n",
    "    # 훈련용과 검증용 데이터셋을 각각 생성.\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset = EmotionDataset(data_dir=DATA_DIR / \"val\", transform=val_transform)\n",
    "\n",
    "    # DataLoader I/O 튜닝\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        # CPU 코어를 최대한 활용하여 데이터를 미리 GPU 메모리로 올리는 작업을 병렬 처리\n",
    "        num_workers=min(8, os.cpu_count()), \n",
    "        pin_memory=True, # GPU로의 데이터 전송 속도 향상\n",
    "        persistent_workers=True, # 워커 프로세스를 계속 유지하여 오버헤드 감소\n",
    "        prefetch_factor=2, # 각 워커가 미리 로드할 배치 수\n",
    "        drop_last=True # 마지막 배치가 배치 사이즈보다 작을 경우 버려서 연산 일관성 유지\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=min(8, os.cpu_count()),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    \n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    # 모델을 지정된 장치로 이동\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        weight_decay=1e-4, #과적합 방지를 위한 정규화 기법(Weight Decay), 학습을 방해함으로서 과적합 방지.\n",
    "        lr=LEARNING_RATE \n",
    "        ) \n",
    "    START_EPOCH = 0\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.1)   # 7 에폭마다 학습률을 0.1배로 감소\n",
    "\n",
    "    CHECKPOINT_PATH = f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth'\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"체크포인트를 불러옵니다...\")\n",
    "        # checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        # model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        # START_EPOCH = checkpoint['epoch'] + 1 # 다음 에폭부터 시작\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint)   # 키 접근 없이 바로 넣기\n",
    "    else:\n",
    "        print(\"체크포인트가 존재하지 않습니다. 처음부터 훈련을 시작합니다.\")\n",
    "        \n",
    "    #model = torch.compile(model)   # Windows 환경에서 에러 발생\n",
    "    #print(\"모델 컴파일 완료!\")\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "    \n",
    "    # 모델 훈련 시작\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(model, \n",
    "                                train_loader, \n",
    "                                val_loader, \n",
    "                                criterion, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                DEVICE, \n",
    "                                num_epochs=NUM_EPOCHS,\n",
    "                                start_epoch=START_EPOCH,\n",
    "                                patience=EARLY_STOPPING_PATIENCE,\n",
    "                                steps_per_epoch=STEPS_PER_EPOCH\n",
    "                                )\n",
    "\n",
    "    # 훈련된 모델 저장 (옵션)\n",
    "    # torch.save(trained_model.state_dict(), f'./infrastructure/models/weights/checkpoints/{MODEL_NAME}_{sampling_percent}_percent_trained.pth')\n",
    "    print(\"훈련된 모델 가중치가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76c3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVAL] Overall Acc: 0.7906 | CM -> confusion_matrix.npy | per-class -> per_class_acc.json | CSV -> val_predictions.csv\n",
      "[EVAL] Misclassified samples saved to: runs\\emonet_20250820_025411\\misclassified\n"
     ]
    }
   ],
   "source": [
    "# === 재검증 & 산출물 저장 ===\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = Path(f\"./runs/{MODEL_NAME}_{stamp}\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 클래스 이름은 PM의 EmotionDataset가 보유 (예: dataset.classes)\n",
    "classes = train_dataset.classes  # 또는 val_dataset.classes\n",
    "evaluate_and_dump(trained_model, val_loader, classes, RUN_DIR, DEVICE,\n",
    "                save_miscls=True, max_miscls_per_pair=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 양을 늘려도 성능이 특정 수준에서 다시 정체된다면, 파인튜닝 세분화를 적용하여 모델의 학습 효율을 극대화\n",
    "# 새로 학습시킬 파라미터와 미세 조정할 파라미터를 분리\n",
    "new_classifier_params = model.emo_fc_3.parameters()\n",
    "pretrained_params = [p for name, p in model.named_parameters() if 'emo_fc_3' not in name]\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': pretrained_params, 'lr': LEARNING_RATE * 0.1}, # 기존 부분은 10분의 1로 미세 조정\n",
    "    {'params': new_classifier_params, 'lr': LEARNING_RATE}      # 새 부분은 원래 학습률로 학습\n",
    "], weight_decay=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feellog-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
