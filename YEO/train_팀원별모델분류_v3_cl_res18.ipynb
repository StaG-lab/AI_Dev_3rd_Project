{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21c18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 다운로드 받고 모델이 제대로 작동하는지 확인하는 명령어입니다.\n",
    "# 가상환경이 활성화된 터미널에서 아래 명령어를 실행하세요.\n",
    "# python -m unittest tests/test_model.py\n",
    "#-------------------------\n",
    "# Ran 1 test in 8.179s\n",
    "# OK\n",
    "#-------------------------\n",
    "# 위와 같은 결과를 얻었다면 모델이 정상적으로 작동하는 것입니다.\n",
    "# 코드 중 담당하신 MODEL_NAME에 해당하는 주석(#)을 제거하고 실행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66595eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch                                            # [S1]\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "\n",
    "from core.models.model_factory import create_model\n",
    "from core.data.dataset import EmotionDataset\n",
    "# from core.training.trainer import train_model              # [S2] 필요 시 주석 해제\n",
    "from core.training.trainer_v2 import train_model            # [S2] AMP/비동기/클리핑 지원\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff955ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "데이터 준비 완료!\n",
      "훈련 데이터셋 크기: 17975\n",
      "클래스 수: 7 -> ['기쁨', '당황', '분노', '불안', '상처', '슬픔', '중립']\n",
      "'resnet18' 모델, 손실 함수, 옵티마이저 준비 완료!\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Epoch 1/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ex\\최종프로젝트\\AI_Dev_3rd_Project\\YEO\\core\\training\\trainer_v2.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=amp_enabled)                 # [A9]\n",
      "d:\\ex\\최종프로젝트\\AI_Dev_3rd_Project\\YEO\\core\\training\\trainer_v2.py:72: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=amp_enabled):                         # [A14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1 B50] loss=1.5288 acc=0.417\n",
      "[E1 B100] loss=1.4011 acc=0.468\n",
      "[E1 B150] loss=1.3472 acc=0.489\n",
      "[E1 B200] loss=1.3011 acc=0.506\n",
      "[E1 B250] loss=1.2643 acc=0.523\n",
      "Train Loss: 1.2447 Acc: 0.5285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ex\\최종프로젝트\\AI_Dev_3rd_Project\\YEO\\core\\training\\trainer_v2.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=amp_enabled and amp_in_val):           # [A18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.2124 Acc: 0.5645\n",
      "\n",
      "  -> Val Loss 개선됨! (1.2124)\n",
      "Epoch 2/100\n",
      "----------\n",
      "[E2 B50] loss=1.0688 acc=0.606\n",
      "[E2 B100] loss=1.0871 acc=0.605\n",
      "[E2 B150] loss=1.0867 acc=0.604\n",
      "[E2 B200] loss=1.0792 acc=0.606\n",
      "[E2 B250] loss=1.0778 acc=0.604\n",
      "Train Loss: 1.0668 Acc: 0.6042\n",
      "Val Loss: 1.0434 Acc: 0.6196\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0434)\n",
      "Epoch 3/100\n",
      "----------\n",
      "[E3 B50] loss=0.9952 acc=0.627\n",
      "[E3 B100] loss=1.0134 acc=0.621\n",
      "[E3 B150] loss=1.0058 acc=0.624\n",
      "[E3 B200] loss=1.0028 acc=0.627\n",
      "[E3 B250] loss=0.9966 acc=0.631\n",
      "Train Loss: 0.9905 Acc: 0.6309\n",
      "Val Loss: 1.0426 Acc: 0.6203\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0426)\n",
      "Epoch 4/100\n",
      "----------\n",
      "[E4 B50] loss=0.9269 acc=0.657\n",
      "[E4 B100] loss=0.9448 acc=0.651\n",
      "[E4 B150] loss=0.9470 acc=0.648\n",
      "[E4 B200] loss=0.9461 acc=0.647\n",
      "[E4 B250] loss=0.9472 acc=0.649\n",
      "Train Loss: 0.9467 Acc: 0.6459\n",
      "Val Loss: 1.0313 Acc: 0.6337\n",
      "\n",
      "  -> Val Loss 개선됨! (1.0313)\n",
      "Epoch 5/100\n",
      "----------\n",
      "[E5 B50] loss=0.9377 acc=0.644\n",
      "[E5 B100] loss=0.9174 acc=0.656\n",
      "[E5 B150] loss=0.9106 acc=0.660\n",
      "[E5 B200] loss=0.9080 acc=0.663\n",
      "[E5 B250] loss=0.9064 acc=0.665\n",
      "Train Loss: 0.9062 Acc: 0.6619\n",
      "Val Loss: 0.9503 Acc: 0.6584\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9503)\n",
      "Epoch 6/100\n",
      "----------\n",
      "[E6 B50] loss=0.8637 acc=0.668\n",
      "[E6 B100] loss=0.8657 acc=0.672\n",
      "[E6 B150] loss=0.8670 acc=0.673\n",
      "[E6 B200] loss=0.8749 acc=0.672\n",
      "[E6 B250] loss=0.8814 acc=0.672\n",
      "Train Loss: 0.8778 Acc: 0.6705\n",
      "Val Loss: 0.9441 Acc: 0.6616\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9441)\n",
      "Epoch 7/100\n",
      "----------\n",
      "[E7 B50] loss=0.8607 acc=0.682\n",
      "[E7 B100] loss=0.8605 acc=0.686\n",
      "[E7 B150] loss=0.8582 acc=0.684\n",
      "[E7 B200] loss=0.8533 acc=0.686\n",
      "[E7 B250] loss=0.8518 acc=0.688\n",
      "Train Loss: 0.8504 Acc: 0.6854\n",
      "Val Loss: 0.9569 Acc: 0.6487\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 8/100\n",
      "----------\n",
      "[E8 B50] loss=0.8139 acc=0.703\n",
      "[E8 B100] loss=0.8181 acc=0.703\n",
      "[E8 B150] loss=0.8174 acc=0.704\n",
      "[E8 B200] loss=0.8199 acc=0.702\n",
      "[E8 B250] loss=0.8235 acc=0.700\n",
      "Train Loss: 0.8166 Acc: 0.7001\n",
      "Val Loss: 0.9237 Acc: 0.6652\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9237)\n",
      "Epoch 9/100\n",
      "----------\n",
      "[E9 B50] loss=0.7594 acc=0.714\n",
      "[E9 B100] loss=0.7800 acc=0.707\n",
      "[E9 B150] loss=0.7944 acc=0.704\n",
      "[E9 B200] loss=0.7899 acc=0.707\n",
      "[E9 B250] loss=0.7923 acc=0.707\n",
      "Train Loss: 0.7904 Acc: 0.7041\n",
      "Val Loss: 0.9193 Acc: 0.6636\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9193)\n",
      "Epoch 10/100\n",
      "----------\n",
      "[E10 B50] loss=0.7441 acc=0.731\n",
      "[E10 B100] loss=0.7596 acc=0.722\n",
      "[E10 B150] loss=0.7657 acc=0.719\n",
      "[E10 B200] loss=0.7714 acc=0.716\n",
      "[E10 B250] loss=0.7666 acc=0.719\n",
      "Train Loss: 0.7636 Acc: 0.7166\n",
      "Val Loss: 0.9237 Acc: 0.6757\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 11/100\n",
      "----------\n",
      "[E11 B50] loss=0.7354 acc=0.731\n",
      "[E11 B100] loss=0.7333 acc=0.728\n",
      "[E11 B150] loss=0.7327 acc=0.731\n",
      "[E11 B200] loss=0.7363 acc=0.729\n",
      "[E11 B250] loss=0.7402 acc=0.725\n",
      "Train Loss: 0.7403 Acc: 0.7220\n",
      "Val Loss: 0.9850 Acc: 0.6532\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 12/100\n",
      "----------\n",
      "[E12 B50] loss=0.6682 acc=0.752\n",
      "[E12 B100] loss=0.6918 acc=0.740\n",
      "[E12 B150] loss=0.6997 acc=0.741\n",
      "[E12 B200] loss=0.7067 acc=0.738\n",
      "[E12 B250] loss=0.7097 acc=0.737\n",
      "Train Loss: 0.7075 Acc: 0.7344\n",
      "Val Loss: 0.9857 Acc: 0.6702\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 13/100\n",
      "----------\n",
      "[E13 B50] loss=0.6766 acc=0.752\n",
      "[E13 B100] loss=0.6732 acc=0.751\n",
      "[E13 B150] loss=0.6827 acc=0.747\n",
      "[E13 B200] loss=0.6873 acc=0.747\n",
      "[E13 B250] loss=0.6894 acc=0.747\n",
      "Train Loss: 0.6910 Acc: 0.7428\n",
      "Val Loss: 0.9305 Acc: 0.6754\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 14/100\n",
      "----------\n",
      "[E14 B50] loss=0.6418 acc=0.763\n",
      "[E14 B100] loss=0.6373 acc=0.767\n",
      "[E14 B150] loss=0.6469 acc=0.762\n",
      "[E14 B200] loss=0.6493 acc=0.759\n",
      "[E14 B250] loss=0.6560 acc=0.758\n",
      "Train Loss: 0.6547 Acc: 0.7559\n",
      "Val Loss: 0.9504 Acc: 0.6809\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/10\n",
      "Epoch 15/100\n",
      "----------\n",
      "[E15 B50] loss=0.6399 acc=0.769\n",
      "[E15 B100] loss=0.6319 acc=0.768\n",
      "[E15 B150] loss=0.6238 acc=0.770\n",
      "[E15 B200] loss=0.6284 acc=0.766\n",
      "[E15 B250] loss=0.6292 acc=0.766\n",
      "Train Loss: 0.6309 Acc: 0.7624\n",
      "Val Loss: 0.9514 Acc: 0.6723\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 6/10\n",
      "Epoch 16/100\n",
      "----------\n",
      "[E16 B50] loss=0.5520 acc=0.796\n",
      "[E16 B100] loss=0.5548 acc=0.793\n",
      "[E16 B150] loss=0.5702 acc=0.788\n",
      "[E16 B200] loss=0.5800 acc=0.785\n",
      "[E16 B250] loss=0.5881 acc=0.781\n",
      "Train Loss: 0.5902 Acc: 0.7770\n",
      "Val Loss: 0.9017 Acc: 0.7004\n",
      "\n",
      "  -> Val Loss 개선됨! (0.9017)\n",
      "Epoch 17/100\n",
      "----------\n",
      "[E17 B50] loss=0.5570 acc=0.789\n",
      "[E17 B100] loss=0.5468 acc=0.792\n",
      "[E17 B150] loss=0.5651 acc=0.788\n",
      "[E17 B200] loss=0.5691 acc=0.788\n",
      "[E17 B250] loss=0.5683 acc=0.787\n",
      "Train Loss: 0.5710 Acc: 0.7829\n",
      "Val Loss: 0.9416 Acc: 0.6943\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 1/10\n",
      "Epoch 18/100\n",
      "----------\n",
      "[E18 B50] loss=0.5411 acc=0.797\n",
      "[E18 B100] loss=0.5347 acc=0.798\n",
      "[E18 B150] loss=0.5412 acc=0.797\n",
      "[E18 B200] loss=0.5403 acc=0.801\n",
      "[E18 B250] loss=0.5414 acc=0.801\n",
      "Train Loss: 0.5440 Acc: 0.7960\n",
      "Val Loss: 1.0513 Acc: 0.6868\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 2/10\n",
      "Epoch 19/100\n",
      "----------\n",
      "[E19 B50] loss=0.4821 acc=0.822\n",
      "[E19 B100] loss=0.5080 acc=0.811\n",
      "[E19 B150] loss=0.4978 acc=0.816\n",
      "[E19 B200] loss=0.5063 acc=0.811\n",
      "[E19 B250] loss=0.5108 acc=0.811\n",
      "Train Loss: 0.5080 Acc: 0.8086\n",
      "Val Loss: 1.0364 Acc: 0.6732\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 3/10\n",
      "Epoch 20/100\n",
      "----------\n",
      "[E20 B50] loss=0.4497 acc=0.830\n",
      "[E20 B100] loss=0.4632 acc=0.825\n",
      "[E20 B150] loss=0.4689 acc=0.825\n",
      "[E20 B200] loss=0.4705 acc=0.824\n",
      "[E20 B250] loss=0.4737 acc=0.822\n",
      "Train Loss: 0.4748 Acc: 0.8201\n",
      "Val Loss: 1.0661 Acc: 0.6906\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 4/10\n",
      "Epoch 21/100\n",
      "----------\n",
      "[E21 B50] loss=0.4147 acc=0.842\n",
      "[E21 B100] loss=0.4296 acc=0.843\n",
      "[E21 B150] loss=0.4325 acc=0.841\n",
      "[E21 B200] loss=0.4376 acc=0.837\n",
      "[E21 B250] loss=0.4472 acc=0.834\n",
      "Train Loss: 0.4500 Acc: 0.8290\n",
      "Val Loss: 1.0427 Acc: 0.6820\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 5/10\n",
      "Epoch 22/100\n",
      "----------\n",
      "[E22 B50] loss=0.3811 acc=0.860\n",
      "[E22 B100] loss=0.3909 acc=0.858\n",
      "[E22 B150] loss=0.3934 acc=0.856\n",
      "[E22 B200] loss=0.4000 acc=0.854\n",
      "[E22 B250] loss=0.4083 acc=0.850\n",
      "Train Loss: 0.4111 Acc: 0.8457\n",
      "Val Loss: 1.0668 Acc: 0.6766\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 6/10\n",
      "Epoch 23/100\n",
      "----------\n",
      "[E23 B50] loss=0.3465 acc=0.878\n",
      "[E23 B100] loss=0.3612 acc=0.870\n",
      "[E23 B150] loss=0.3788 acc=0.863\n",
      "[E23 B200] loss=0.3777 acc=0.864\n",
      "[E23 B250] loss=0.3882 acc=0.861\n",
      "Train Loss: 0.3876 Acc: 0.8566\n",
      "Val Loss: 1.1859 Acc: 0.6773\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 7/10\n",
      "Epoch 24/100\n",
      "----------\n",
      "[E24 B50] loss=0.3484 acc=0.874\n",
      "[E24 B100] loss=0.3538 acc=0.872\n",
      "[E24 B150] loss=0.3538 acc=0.871\n",
      "[E24 B200] loss=0.3657 acc=0.864\n",
      "[E24 B250] loss=0.3678 acc=0.865\n",
      "Train Loss: 0.3658 Acc: 0.8622\n",
      "Val Loss: 1.1787 Acc: 0.6938\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 8/10\n",
      "Epoch 25/100\n",
      "----------\n",
      "[E25 B50] loss=0.3197 acc=0.878\n",
      "[E25 B100] loss=0.3235 acc=0.880\n",
      "[E25 B150] loss=0.3276 acc=0.880\n",
      "[E25 B200] loss=0.3317 acc=0.878\n",
      "[E25 B250] loss=0.3364 acc=0.877\n",
      "Train Loss: 0.3368 Acc: 0.8732\n",
      "Val Loss: 1.1939 Acc: 0.6879\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 9/10\n",
      "Epoch 26/100\n",
      "----------\n",
      "[E26 B50] loss=0.3084 acc=0.890\n",
      "[E26 B100] loss=0.3150 acc=0.888\n",
      "[E26 B150] loss=0.3162 acc=0.886\n",
      "[E26 B200] loss=0.3145 acc=0.887\n",
      "[E26 B250] loss=0.3204 acc=0.884\n",
      "Train Loss: 0.3198 Acc: 0.8811\n",
      "Val Loss: 1.2890 Acc: 0.6782\n",
      "\n",
      "  -> Val Loss 개선되지 않음. EarlyStopping Counter: 10/10\n",
      "\n",
      "Early stopping! 10 에폭 동안 성능 개선이 없었습니다.\n",
      "Training complete in 13m 53s\n",
      "Best Val Loss: 0.9017\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 장치\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    # 전역 성능 플래그 (Ampere↑ 권장)                           # [S3]\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    if hasattr(torch.backends.cudnn, \"allow_tf32\"):\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')  # PyTorch 2.0+\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 데이터 경로/모델 선택\n",
    "    DATA_DIR = Path(\"./datasets/korean_emotion_complex_vision_5_percent_verified_processed_CLAHE\")\n",
    "    MODEL_NAME = 'resnet18'\n",
    "    # MODEL_NAME = 'resnet50'\n",
    "    # MODEL_NAME = 'mobilenet_v3_small'\n",
    "    # MODEL_NAME = 'shufflenet_v2'\n",
    "    # MODEL_NAME = 'efficientnet_v2_s'\n",
    "    # MODEL_NAME = 'squeezenet'\n",
    "\n",
    "    NUM_CLASSES = 7\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    # --- Epoch 슬라이더(가능 시) --------------------------------  # [S4]\n",
    "    NUM_EPOCHS_DEFAULT = 100\n",
    "    try:\n",
    "        from ipywidgets import IntSlider, display\n",
    "        _epoch_slider = IntSlider(description='Epochs', value=NUM_EPOCHS_DEFAULT, min=1, max=200, step=1)\n",
    "        display(_epoch_slider)\n",
    "        NUM_EPOCHS = _epoch_slider.value\n",
    "    except Exception:\n",
    "        NUM_EPOCHS = NUM_EPOCHS_DEFAULT\n",
    "\n",
    "    EARLY_STOPPING_PATIENCE = 10\n",
    "\n",
    "    # Transform\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # Dataset\n",
    "    train_dataset = EmotionDataset(data_dir=DATA_DIR / \"train\", transform=train_transform)\n",
    "    val_dataset   = EmotionDataset(data_dir=DATA_DIR / \"val\",   transform=val_transform)\n",
    "\n",
    "    # DataLoader I/O 튜닝                                         # [S5]\n",
    "    NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
    "    PIN_MEMORY = True\n",
    "    PERSISTENT = True if NUM_WORKERS > 0 else False\n",
    "    PREFETCH = 2 if NUM_WORKERS > 0 else None\n",
    "\n",
    "    def build_loader(ds, bs, shuffle):\n",
    "        return DataLoader(\n",
    "            ds, batch_size=bs, shuffle=shuffle,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=PIN_MEMORY,\n",
    "            persistent_workers=PERSISTENT,\n",
    "            prefetch_factor=PREFETCH,\n",
    "            drop_last=shuffle,  # train에서만 True → BN 안정화(선택)\n",
    "        )\n",
    "\n",
    "    train_loader = build_loader(train_dataset, BATCH_SIZE, True)\n",
    "    val_loader   = build_loader(val_dataset,   BATCH_SIZE, False)\n",
    "\n",
    "    # 클래스 수 동기화(폴더명 기반)                                # [S6]\n",
    "    NUM_CLASSES = len(train_dataset.classes)\n",
    "    print(\"데이터 준비 완료!\")\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"클래스 수: {NUM_CLASSES} -> {train_dataset.classes}\")\n",
    "\n",
    "    # 모델/손실/옵티마\n",
    "    model = create_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(f\"'{MODEL_NAME}' 모델, 손실 함수, 옵티마이저 준비 완료!\")\n",
    "\n",
    "    # 학습 실행 (AMP/클리핑/로깅/체크포인트/TF32·cudnn)              # [S7]\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    print(\"\\n모델 훈련을 시작합니다...\")\n",
    "    trained_model = train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        criterion, optimizer, DEVICE,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        patience=EARLY_STOPPING_PATIENCE,\n",
    "        use_amp=True, amp_in_val=True,\n",
    "        grad_clip=1.0, log_interval=50,\n",
    "        save_best_path=\"checkpoints/best.pt\",\n",
    "        set_tf32=True, cudnn_benchmark=True\n",
    "    )\n",
    "\n",
    "    # torch.save(trained_model.state_dict(), f'{MODEL_NAME}_trained.pth')\n",
    "    # print(\"훈련된 모델 가중치가 저장되었습니다.\")\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feellog-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
